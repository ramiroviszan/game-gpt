{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/frames"
      ],
      "metadata": {
        "id": "g9pS9tYmL5Ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8157586a-f1cc-40b6-e149-38d2c846740c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/frames': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jyEqfzegK77",
        "outputId": "02c2170e-9d11-4bb4-fd18-aafe2d31f3f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q drive/MyDrive/Colab\\ Notebooks/GameGPT/frames_3.zip -d \"/content/\""
      ],
      "metadata": {
        "id": "4wqzTHenKPlF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aO6Lsn_IyltG"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import numpy as np\n",
        "import json\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import math\n",
        "import os\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasetnames = ('frames_3', 'moves_3')"
      ],
      "metadata": {
        "id": "4HCiRINRsuMy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Movements on each frame"
      ],
      "metadata": {
        "id": "OT3hMSkZrHm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "moves_file_path = f'/content/drive/MyDrive/Colab Notebooks/GameGPT/{datasetnames[1]}.json'\n",
        "\n",
        "# Load moves from the JSON file\n",
        "with open(moves_file_path, 'r') as json_file:\n",
        "    moves = json.load(json_file)\n",
        "value_to_int_mapping = {'Q': 0}\n",
        "unique_values = [value for value in set(moves.values()) if value != 'Q']\n",
        "value_to_int_mapping.update({value: i + 1 for i, value in enumerate(unique_values)})\n",
        "\n",
        "# Create a new dictionary with integer values\n",
        "new_moves = {key: value_to_int_mapping[value] for key, value in moves.items()}\n",
        "# Reverse the key-value pairs to create int_to_value_mapping\n",
        "int_to_value_mapping = {v: k for k, v in value_to_int_mapping.items()}"
      ],
      "metadata": {
        "id": "kMWLVoTKMiTq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Train Dataset\n",
        "\n",
        "*  frames: list of previous {seq_len} frames\n",
        "*  moves: list of input keys, one for each frame\n",
        "*  target_frames: for every {seq_len} frames there will be a target_frame\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aqHbdZ3brQW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_folder, moves_dict, seq_len = 5, transform=None):\n",
        "        self.data_folder = data_folder\n",
        "        self.moves_dict = moves_dict\n",
        "        self.transform = transform\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        # Get a list of all image filenames in the data folder\n",
        "        self.image_filenames = [filename for filename in os.listdir(data_folder) if filename.endswith('.png')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames) - 2  # We subtract 5 for the sequence length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get 5 consecutive frames and their moves\n",
        "        frames = [Image.open(os.path.join(self.data_folder, f'frame_{idx + i}.png')) for i in range(self.seq_len) if idx + i < len(self.image_filenames) - 2]\n",
        "        moves = [self.moves_dict[f\"{idx + i}\"] for i in range(self.seq_len) if idx + i < len(self.image_filenames) - 2]\n",
        "\n",
        "        # Apply transformations to each frame\n",
        "        if self.transform is not None:\n",
        "            frames = [self.transform(frame) for frame in frames]\n",
        "\n",
        "        # Prepare the target frames for each frame in the sequence\n",
        "        target_frames = [Image.open(os.path.join(self.data_folder, f'frame_{idx + 1 + i}.png')) for i in range(self.seq_len) if idx + 1 + i < len(self.image_filenames) - 1]\n",
        "\n",
        "        # Apply transformations to the target frame\n",
        "        if self.transform is not None:\n",
        "            target_frames = [self.transform(frame) for frame in target_frames]\n",
        "\n",
        "        if len(frames) == self.seq_len and len(frames) == len(moves) == len(target_frames):\n",
        "          frames = torch.stack(frames).to('cuda')\n",
        "          moves = torch.tensor(moves).to('cuda')\n",
        "          target_frames = torch.stack(target_frames).to('cuda')\n",
        "        else:\n",
        "          return self.__getitem__(idx - 1)\n",
        "\n",
        "        return {'frames': frames, 'moves': moves, 'target_frames': target_frames}\n",
        "\n",
        "# Define a transform for preprocessing images\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "pSCxcIZ378oc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition\n",
        "Basic Image To Vector Encoder"
      ],
      "metadata": {
        "id": "OiDasFkHr1Rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageToVector(nn.Module):\n",
        "    def __init__(self, input_channels=3, image_size=128, conv_size=32, output_size=512):\n",
        "        super(ImageToVector, self).__init__()\n",
        "\n",
        "        # Convolutional layer with max pooling\n",
        "        self.conv1 = nn.Conv2d(input_channels, conv_size, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        ks = 2\n",
        "        st = 2\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=ks, stride=st)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(image_size * image_size * conv_size // (ks * st), output_size)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu(self.fc(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "C88B4tC7NUCZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input Vector Positional Encoding"
      ],
      "metadata": {
        "id": "pjDykk0Qr9yX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "I4NJCY_FgiJt"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model=512, max_len=1000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.encoding = torch.zeros(max_len, d_model).to('cuda')\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
        "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
        "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.encoding = self.encoding.unsqueeze(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.encoding[:, :x.size(1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self Attention Layer"
      ],
      "metadata": {
        "id": "GTFiOYZgsJYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, d_model, n_head, seq_len, dropout=0.2):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "        self.c_attn = nn.Linear(d_model, 3 * d_model, dtype=torch.float)\n",
        "\n",
        "        self.linear = nn.Linear(d_model, d_model, dtype=torch.float)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(seq_len, seq_len)))\n",
        "        self.d_model = d_model\n",
        "        self.n_head = n_head\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "\n",
        "        q, k, v  = self.c_attn(x).split(self.d_model, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "\n",
        "        #normal attention\n",
        "        qk = torch.matmul(q, k.transpose(-2,-1)) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
        "        qk = qk.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        qk = F.softmax(qk, dim=-1) # (B, T, T)\n",
        "        y = torch.matmul(qk, v) # (B, T, hs)\n",
        "\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        return y"
      ],
      "metadata": {
        "id": "SI01iVBHfLhA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic Vector To Image decoder"
      ],
      "metadata": {
        "id": "Lx7Nx49ysNri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorToImage(nn.Module):\n",
        "    def __init__(self, d_model=512, output_channels=3, image_size=128, conv_size=32):\n",
        "        super(VectorToImage, self).__init__()\n",
        "        self.output_channels = output_channels\n",
        "        self.image_size = image_size\n",
        "\n",
        "        # Adjust the output size of the linear layer to match the desired spatial dimensions\n",
        "        self.fc = nn.Linear(d_model, output_channels * image_size * image_size)\n",
        "        self.deconv1 = nn.Conv2d(3, conv_size, kernel_size=4, stride=2, padding=1)\n",
        "        self.deconv2 = nn.ConvTranspose2d(conv_size, conv_size//2, kernel_size=4, stride=2, padding=1)\n",
        "        self.deconv3 = nn.ConvTranspose2d(conv_size//2, output_channels, kernel_size=4, stride=2, padding=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, self.output_channels, self.image_size, self.image_size)  # Reshape to match the desired output size\n",
        "        x = self.relu(self.deconv1(x))\n",
        "        x = self.relu(self.deconv2(x))\n",
        "        x = self.deconv3(x)\n",
        "\n",
        "        # Resize to the desired output size (128x128)\n",
        "        x = F.interpolate(x, size=(self.image_size, self.image_size), mode='bilinear', align_corners=False)\n",
        "\n",
        "        # Apply sigmoid activation\n",
        "        x = F.sigmoid(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "25vKKTqPsu2V"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final model"
      ],
      "metadata": {
        "id": "M0I4k9qYsXuA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LAveIsArFoke"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GameModel(nn.Module):\n",
        "    def __init__(self, d_model=512, image_size=128, channels = 3, num_input_tokens=10, seq_len=5, n_head=1, conv_size = 32, dropout=0.2):\n",
        "        super(GameModel, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.seq_len = seq_len\n",
        "        self.n_head = n_head\n",
        "\n",
        "        self.input_token_embedding = nn.Embedding(num_input_tokens, d_model)\n",
        "        self.image_to_vector = ImageToVector(input_channels=channels, image_size=image_size, conv_size=conv_size, output_size=d_model)\n",
        "        self.positional_encoding = PositionalEncoding(self.d_model)\n",
        "\n",
        "        self.att = Attention(self.d_model, self.n_head, seq_len)\n",
        "        self.linear_a = nn.Linear(self.d_model, self.d_model, dtype=torch.float)\n",
        "        self.dropout_a = nn.Dropout(0.2)\n",
        "        self.layer_n = nn.LayerNorm(normalized_shape=(seq_len, self.d_model))\n",
        "\n",
        "        self.linear_k = nn.Linear(self.d_model, self.d_model, dtype=torch.float)\n",
        "        self.dropout_k = nn.Dropout(0.2)\n",
        "        self.vector_to_image = VectorToImage(d_model=d_model, output_channels=channels, image_size=image_size,  conv_size=conv_size)\n",
        "\n",
        "    def forward(self, k, x):\n",
        "        timesteps = x.size(1)\n",
        "        image_vectors = []\n",
        "        k_embeddings = []\n",
        "        for i in range(timesteps):\n",
        "            image_vector = self.image_to_vector(x[:, i])\n",
        "            image_vector = self.positional_encoding(image_vector.unsqueeze(1))\n",
        "            image_vectors.append(image_vector)\n",
        "            k_embeddings.append(self.input_token_embedding(k[:, i]))\n",
        "\n",
        "        res = torch.cat(image_vectors, dim=1)\n",
        "        y = self.att(res)\n",
        "        y = self.linear_a(y)\n",
        "        y = self.layer_n(y)\n",
        "        y = self.dropout_a(y)\n",
        "\n",
        "        k_embedding = torch.stack(k_embeddings, dim=1)\n",
        "\n",
        "        y = y + k_embedding\n",
        "        y = self.linear_k(y)\n",
        "        y = self.layer_n(y)\n",
        "        y = self.dropout_k(y)\n",
        "        y = res + y\n",
        "\n",
        "        generated_images = []\n",
        "        for i in range(timesteps):\n",
        "            current_timestep_data = y[:, i, :]  # Select data for the current timestep\n",
        "            current_generated_image = self.vector_to_image(current_timestep_data)\n",
        "            generated_images.append(current_generated_image.unsqueeze(1))  # Add an extra dimension for timestep\n",
        "\n",
        "        # Concatenate the generated images along the timestep dimension\n",
        "        y = torch.cat(generated_images, dim=1)\n",
        "\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YAw7LVFA_1Q1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30c8c2a-51f3-449e-a3b2-117dadee3d5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GameModel(\n",
              "  (input_token_embedding): Embedding(10, 768)\n",
              "  (image_to_vector): ImageToVector(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "    (fc): Linear(in_features=262144, out_features=768, bias=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (positional_encoding): PositionalEncoding()\n",
              "  (att): Attention(\n",
              "    (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
              "    (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "  )\n",
              "  (linear_a): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (dropout_a): Dropout(p=0.2, inplace=False)\n",
              "  (layer_n): LayerNorm((5, 768), eps=1e-05, elementwise_affine=True)\n",
              "  (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (dropout_k): Dropout(p=0.2, inplace=False)\n",
              "  (vector_to_image): VectorToImage(\n",
              "    (fc): Linear(in_features=768, out_features=49152, bias=True)\n",
              "    (deconv1): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (deconv2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (deconv3): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "model = GameModel(d_model=768, image_size=128, channels = 3, num_input_tokens=10, seq_len=5, n_head=2, conv_size=64)\n",
        "model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxjlpASvbqa1",
        "outputId": "b802fda0-a34c-4ae6-e2b9-116830af9037"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 242723427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preload Model"
      ],
      "metadata": {
        "id": "x0VxWm8Hsfsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"drive/MyDrive/Colab Notebooks/GameGPT/model_checkpoint_epoch1_batch3000.pth\""
      ],
      "metadata": {
        "id": "_3k9Uf3kvL7F"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(model_path))"
      ],
      "metadata": {
        "id": "pirJSWT1vK2n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5312bd06-958a-46d3-fcb3-ec945e070b8d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Setup"
      ],
      "metadata": {
        "id": "zkvm2kvCsnz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "R27AuEVb1bE7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_dataset = CustomDataset(datasetnames[0], new_moves, seq_len=5, transform=data_transform)\n",
        "dataloader = DataLoader(custom_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "IBSnP0aR_D9H"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XcDLDqNleBI",
        "outputId": "5050d9bc-bc46-43d9-f914-2f16c900ecb5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Loop\n",
        "\n",
        "TODO: Val Loss Monitoring"
      ],
      "metadata": {
        "id": "_DAOUHhptRqZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJXp9wLqpDcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7670be52-b650-4d06-da26-5e41ef25247b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Batch [1/3134], Loss: 0.01185270\n",
            "Epoch [1/1], Batch [2/3134], Loss: 0.01191490\n",
            "Epoch [1/1], Batch [3/3134], Loss: 0.01186055\n",
            "Epoch [1/1], Batch [4/3134], Loss: 0.01193250\n",
            "Epoch [1/1], Batch [5/3134], Loss: 0.01181572\n",
            "Epoch [1/1], Batch [6/3134], Loss: 0.01191542\n",
            "Epoch [1/1], Batch [7/3134], Loss: 0.01185301\n",
            "Epoch [1/1], Batch [8/3134], Loss: 0.01186045\n",
            "Epoch [1/1], Batch [9/3134], Loss: 0.01190295\n",
            "Epoch [1/1], Batch [10/3134], Loss: 0.01183663\n",
            "Epoch [1/1], Batch [11/3134], Loss: 0.01189891\n",
            "Epoch [1/1], Batch [12/3134], Loss: 0.01183889\n",
            "Epoch [1/1], Batch [13/3134], Loss: 0.01189708\n",
            "Epoch [1/1], Batch [14/3134], Loss: 0.01188967\n",
            "Epoch [1/1], Batch [15/3134], Loss: 0.01185144\n",
            "Epoch [1/1], Batch [16/3134], Loss: 0.01193429\n",
            "Epoch [1/1], Batch [17/3134], Loss: 0.01185230\n",
            "Epoch [1/1], Batch [18/3134], Loss: 0.01186028\n",
            "Epoch [1/1], Batch [19/3134], Loss: 0.01186654\n",
            "Epoch [1/1], Batch [20/3134], Loss: 0.01199055\n",
            "Epoch [1/1], Batch [21/3134], Loss: 0.01190450\n",
            "Epoch [1/1], Batch [22/3134], Loss: 0.01183483\n",
            "Epoch [1/1], Batch [23/3134], Loss: 0.01188197\n",
            "Epoch [1/1], Batch [24/3134], Loss: 0.01189368\n",
            "Epoch [1/1], Batch [25/3134], Loss: 0.01184603\n",
            "Epoch [1/1], Batch [26/3134], Loss: 0.01178918\n",
            "Epoch [1/1], Batch [27/3134], Loss: 0.01190665\n",
            "Epoch [1/1], Batch [28/3134], Loss: 0.01183267\n",
            "Epoch [1/1], Batch [29/3134], Loss: 0.01187232\n",
            "Epoch [1/1], Batch [30/3134], Loss: 0.01184065\n",
            "Epoch [1/1], Batch [31/3134], Loss: 0.01191147\n",
            "Epoch [1/1], Batch [32/3134], Loss: 0.01180711\n",
            "Epoch [1/1], Batch [33/3134], Loss: 0.01185160\n",
            "Epoch [1/1], Batch [34/3134], Loss: 0.01180972\n",
            "Epoch [1/1], Batch [35/3134], Loss: 0.01186752\n",
            "Epoch [1/1], Batch [36/3134], Loss: 0.01185326\n",
            "Epoch [1/1], Batch [37/3134], Loss: 0.01188603\n",
            "Epoch [1/1], Batch [38/3134], Loss: 0.01188140\n",
            "Epoch [1/1], Batch [39/3134], Loss: 0.01196385\n",
            "Epoch [1/1], Batch [40/3134], Loss: 0.01180167\n",
            "Epoch [1/1], Batch [41/3134], Loss: 0.01181977\n",
            "Epoch [1/1], Batch [42/3134], Loss: 0.01188304\n",
            "Epoch [1/1], Batch [43/3134], Loss: 0.01186837\n",
            "Epoch [1/1], Batch [44/3134], Loss: 0.01184713\n",
            "Epoch [1/1], Batch [45/3134], Loss: 0.01183046\n",
            "Epoch [1/1], Batch [46/3134], Loss: 0.01184920\n",
            "Epoch [1/1], Batch [47/3134], Loss: 0.01184955\n",
            "Epoch [1/1], Batch [48/3134], Loss: 0.01190607\n",
            "Epoch [1/1], Batch [49/3134], Loss: 0.01186732\n",
            "Epoch [1/1], Batch [50/3134], Loss: 0.01188929\n",
            "Epoch [1/1], Batch [51/3134], Loss: 0.01186985\n",
            "Epoch [1/1], Batch [52/3134], Loss: 0.01187322\n",
            "Epoch [1/1], Batch [53/3134], Loss: 0.01185440\n",
            "Epoch [1/1], Batch [54/3134], Loss: 0.01185912\n",
            "Epoch [1/1], Batch [55/3134], Loss: 0.01188235\n",
            "Epoch [1/1], Batch [56/3134], Loss: 0.01188842\n",
            "Epoch [1/1], Batch [57/3134], Loss: 0.01189512\n",
            "Epoch [1/1], Batch [58/3134], Loss: 0.01182845\n",
            "Epoch [1/1], Batch [59/3134], Loss: 0.01185320\n",
            "Epoch [1/1], Batch [60/3134], Loss: 0.01187280\n",
            "Epoch [1/1], Batch [61/3134], Loss: 0.01185910\n",
            "Epoch [1/1], Batch [62/3134], Loss: 0.01184284\n",
            "Epoch [1/1], Batch [63/3134], Loss: 0.01185988\n",
            "Epoch [1/1], Batch [64/3134], Loss: 0.01189895\n",
            "Epoch [1/1], Batch [65/3134], Loss: 0.01183826\n",
            "Epoch [1/1], Batch [66/3134], Loss: 0.01192232\n",
            "Epoch [1/1], Batch [67/3134], Loss: 0.01185040\n",
            "Epoch [1/1], Batch [68/3134], Loss: 0.01185925\n",
            "Epoch [1/1], Batch [69/3134], Loss: 0.01188007\n",
            "Epoch [1/1], Batch [70/3134], Loss: 0.01186805\n",
            "Epoch [1/1], Batch [71/3134], Loss: 0.01186765\n",
            "Epoch [1/1], Batch [72/3134], Loss: 0.01185247\n",
            "Epoch [1/1], Batch [73/3134], Loss: 0.01190539\n",
            "Epoch [1/1], Batch [74/3134], Loss: 0.01184038\n",
            "Epoch [1/1], Batch [75/3134], Loss: 0.01190456\n",
            "Epoch [1/1], Batch [76/3134], Loss: 0.01182370\n",
            "Epoch [1/1], Batch [77/3134], Loss: 0.01185748\n",
            "Epoch [1/1], Batch [78/3134], Loss: 0.01190400\n",
            "Epoch [1/1], Batch [79/3134], Loss: 0.01190200\n",
            "Epoch [1/1], Batch [80/3134], Loss: 0.01181633\n",
            "Epoch [1/1], Batch [81/3134], Loss: 0.01186376\n",
            "Epoch [1/1], Batch [82/3134], Loss: 0.01186238\n",
            "Epoch [1/1], Batch [83/3134], Loss: 0.01187407\n",
            "Epoch [1/1], Batch [84/3134], Loss: 0.01185910\n",
            "Epoch [1/1], Batch [85/3134], Loss: 0.01185515\n",
            "Epoch [1/1], Batch [86/3134], Loss: 0.01188387\n",
            "Epoch [1/1], Batch [87/3134], Loss: 0.01195274\n",
            "Epoch [1/1], Batch [88/3134], Loss: 0.01186217\n",
            "Epoch [1/1], Batch [89/3134], Loss: 0.01190796\n",
            "Epoch [1/1], Batch [90/3134], Loss: 0.01183725\n",
            "Epoch [1/1], Batch [91/3134], Loss: 0.01193290\n",
            "Epoch [1/1], Batch [92/3134], Loss: 0.01189360\n",
            "Epoch [1/1], Batch [93/3134], Loss: 0.01190787\n",
            "Epoch [1/1], Batch [94/3134], Loss: 0.01182283\n",
            "Epoch [1/1], Batch [95/3134], Loss: 0.01187477\n",
            "Epoch [1/1], Batch [96/3134], Loss: 0.01190799\n",
            "Epoch [1/1], Batch [97/3134], Loss: 0.01192403\n",
            "Epoch [1/1], Batch [98/3134], Loss: 0.01193626\n",
            "Epoch [1/1], Batch [99/3134], Loss: 0.01186818\n",
            "Epoch [1/1], Batch [100/3134], Loss: 0.01184429\n",
            "Epoch [1/1], Batch [101/3134], Loss: 0.01186846\n",
            "Epoch [1/1], Batch [102/3134], Loss: 0.01187804\n",
            "Epoch [1/1], Batch [103/3134], Loss: 0.01188426\n",
            "Epoch [1/1], Batch [104/3134], Loss: 0.01186636\n",
            "Epoch [1/1], Batch [105/3134], Loss: 0.01181326\n",
            "Epoch [1/1], Batch [106/3134], Loss: 0.01192418\n",
            "Epoch [1/1], Batch [107/3134], Loss: 0.01180484\n",
            "Epoch [1/1], Batch [108/3134], Loss: 0.01184962\n",
            "Epoch [1/1], Batch [109/3134], Loss: 0.01181874\n",
            "Epoch [1/1], Batch [110/3134], Loss: 0.01185050\n",
            "Epoch [1/1], Batch [111/3134], Loss: 0.01192470\n",
            "Epoch [1/1], Batch [112/3134], Loss: 0.01182737\n",
            "Epoch [1/1], Batch [113/3134], Loss: 0.01189905\n",
            "Epoch [1/1], Batch [114/3134], Loss: 0.01197129\n",
            "Epoch [1/1], Batch [115/3134], Loss: 0.01188328\n",
            "Epoch [1/1], Batch [116/3134], Loss: 0.01187866\n",
            "Epoch [1/1], Batch [117/3134], Loss: 0.01187038\n",
            "Epoch [1/1], Batch [118/3134], Loss: 0.01184117\n",
            "Epoch [1/1], Batch [119/3134], Loss: 0.01190285\n",
            "Epoch [1/1], Batch [120/3134], Loss: 0.01184501\n",
            "Epoch [1/1], Batch [121/3134], Loss: 0.01177028\n",
            "Epoch [1/1], Batch [122/3134], Loss: 0.01190824\n",
            "Epoch [1/1], Batch [123/3134], Loss: 0.01188554\n",
            "Epoch [1/1], Batch [124/3134], Loss: 0.01188904\n",
            "Epoch [1/1], Batch [125/3134], Loss: 0.01187821\n",
            "Epoch [1/1], Batch [126/3134], Loss: 0.01186336\n",
            "Epoch [1/1], Batch [127/3134], Loss: 0.01186813\n",
            "Epoch [1/1], Batch [128/3134], Loss: 0.01177911\n",
            "Epoch [1/1], Batch [129/3134], Loss: 0.01187760\n",
            "Epoch [1/1], Batch [130/3134], Loss: 0.01184741\n",
            "Epoch [1/1], Batch [131/3134], Loss: 0.01180520\n",
            "Epoch [1/1], Batch [132/3134], Loss: 0.01192608\n",
            "Epoch [1/1], Batch [133/3134], Loss: 0.01187966\n",
            "Epoch [1/1], Batch [134/3134], Loss: 0.01190718\n",
            "Epoch [1/1], Batch [135/3134], Loss: 0.01186719\n",
            "Epoch [1/1], Batch [136/3134], Loss: 0.01184637\n",
            "Epoch [1/1], Batch [137/3134], Loss: 0.01182204\n",
            "Epoch [1/1], Batch [138/3134], Loss: 0.01185570\n",
            "Epoch [1/1], Batch [139/3134], Loss: 0.01186458\n",
            "Epoch [1/1], Batch [140/3134], Loss: 0.01185031\n",
            "Epoch [1/1], Batch [141/3134], Loss: 0.01186547\n",
            "Epoch [1/1], Batch [142/3134], Loss: 0.01183609\n",
            "Epoch [1/1], Batch [143/3134], Loss: 0.01191872\n",
            "Epoch [1/1], Batch [144/3134], Loss: 0.01191851\n",
            "Epoch [1/1], Batch [145/3134], Loss: 0.01186066\n",
            "Epoch [1/1], Batch [146/3134], Loss: 0.01190811\n",
            "Epoch [1/1], Batch [147/3134], Loss: 0.01194813\n",
            "Epoch [1/1], Batch [148/3134], Loss: 0.01187846\n",
            "Epoch [1/1], Batch [149/3134], Loss: 0.01188592\n",
            "Epoch [1/1], Batch [150/3134], Loss: 0.01186408\n",
            "Epoch [1/1], Batch [151/3134], Loss: 0.01189428\n",
            "Epoch [1/1], Batch [152/3134], Loss: 0.01179198\n",
            "Epoch [1/1], Batch [153/3134], Loss: 0.01191407\n",
            "Epoch [1/1], Batch [154/3134], Loss: 0.01185614\n",
            "Epoch [1/1], Batch [155/3134], Loss: 0.01186375\n",
            "Epoch [1/1], Batch [156/3134], Loss: 0.01184857\n",
            "Epoch [1/1], Batch [157/3134], Loss: 0.01192219\n",
            "Epoch [1/1], Batch [158/3134], Loss: 0.01181946\n",
            "Epoch [1/1], Batch [159/3134], Loss: 0.01186862\n",
            "Epoch [1/1], Batch [160/3134], Loss: 0.01188079\n",
            "Epoch [1/1], Batch [161/3134], Loss: 0.01175791\n",
            "Epoch [1/1], Batch [162/3134], Loss: 0.01187630\n",
            "Epoch [1/1], Batch [163/3134], Loss: 0.01188625\n",
            "Epoch [1/1], Batch [164/3134], Loss: 0.01187129\n",
            "Epoch [1/1], Batch [165/3134], Loss: 0.01194980\n",
            "Epoch [1/1], Batch [166/3134], Loss: 0.01186416\n",
            "Epoch [1/1], Batch [167/3134], Loss: 0.01184385\n",
            "Epoch [1/1], Batch [168/3134], Loss: 0.01185714\n",
            "Epoch [1/1], Batch [169/3134], Loss: 0.01177705\n",
            "Epoch [1/1], Batch [170/3134], Loss: 0.01182672\n",
            "Epoch [1/1], Batch [171/3134], Loss: 0.01184186\n",
            "Epoch [1/1], Batch [172/3134], Loss: 0.01186263\n",
            "Epoch [1/1], Batch [173/3134], Loss: 0.01183217\n",
            "Epoch [1/1], Batch [174/3134], Loss: 0.01189316\n",
            "Epoch [1/1], Batch [175/3134], Loss: 0.01184968\n",
            "Epoch [1/1], Batch [176/3134], Loss: 0.01181857\n",
            "Epoch [1/1], Batch [177/3134], Loss: 0.01191305\n",
            "Epoch [1/1], Batch [178/3134], Loss: 0.01183980\n",
            "Epoch [1/1], Batch [179/3134], Loss: 0.01188996\n",
            "Epoch [1/1], Batch [180/3134], Loss: 0.01182851\n",
            "Epoch [1/1], Batch [181/3134], Loss: 0.01186598\n",
            "Epoch [1/1], Batch [182/3134], Loss: 0.01182957\n",
            "Epoch [1/1], Batch [183/3134], Loss: 0.01187495\n",
            "Epoch [1/1], Batch [184/3134], Loss: 0.01189867\n",
            "Epoch [1/1], Batch [185/3134], Loss: 0.01187590\n",
            "Epoch [1/1], Batch [186/3134], Loss: 0.01183920\n",
            "Epoch [1/1], Batch [187/3134], Loss: 0.01182796\n",
            "Epoch [1/1], Batch [188/3134], Loss: 0.01190837\n",
            "Epoch [1/1], Batch [189/3134], Loss: 0.01176741\n",
            "Epoch [1/1], Batch [190/3134], Loss: 0.01188062\n",
            "Epoch [1/1], Batch [191/3134], Loss: 0.01184568\n",
            "Epoch [1/1], Batch [192/3134], Loss: 0.01188904\n",
            "Epoch [1/1], Batch [193/3134], Loss: 0.01188152\n",
            "Epoch [1/1], Batch [194/3134], Loss: 0.01188041\n",
            "Epoch [1/1], Batch [195/3134], Loss: 0.01184262\n",
            "Epoch [1/1], Batch [196/3134], Loss: 0.01185432\n",
            "Epoch [1/1], Batch [197/3134], Loss: 0.01188468\n",
            "Epoch [1/1], Batch [198/3134], Loss: 0.01191787\n",
            "Epoch [1/1], Batch [199/3134], Loss: 0.01189142\n",
            "Epoch [1/1], Batch [200/3134], Loss: 0.01190049\n",
            "Epoch [1/1], Batch [201/3134], Loss: 0.01186955\n",
            "Epoch [1/1], Batch [202/3134], Loss: 0.01182078\n",
            "Epoch [1/1], Batch [203/3134], Loss: 0.01185298\n",
            "Epoch [1/1], Batch [204/3134], Loss: 0.01185322\n",
            "Epoch [1/1], Batch [205/3134], Loss: 0.01191895\n",
            "Epoch [1/1], Batch [206/3134], Loss: 0.01193572\n",
            "Epoch [1/1], Batch [207/3134], Loss: 0.01181483\n",
            "Epoch [1/1], Batch [208/3134], Loss: 0.01182120\n",
            "Epoch [1/1], Batch [209/3134], Loss: 0.01185514\n",
            "Epoch [1/1], Batch [210/3134], Loss: 0.01182515\n",
            "Epoch [1/1], Batch [211/3134], Loss: 0.01186224\n",
            "Epoch [1/1], Batch [212/3134], Loss: 0.01185231\n",
            "Epoch [1/1], Batch [213/3134], Loss: 0.01184887\n",
            "Epoch [1/1], Batch [214/3134], Loss: 0.01193233\n",
            "Epoch [1/1], Batch [215/3134], Loss: 0.01179659\n",
            "Epoch [1/1], Batch [216/3134], Loss: 0.01193856\n",
            "Epoch [1/1], Batch [217/3134], Loss: 0.01190743\n",
            "Epoch [1/1], Batch [218/3134], Loss: 0.01192278\n",
            "Epoch [1/1], Batch [219/3134], Loss: 0.01186592\n",
            "Epoch [1/1], Batch [220/3134], Loss: 0.01186771\n",
            "Epoch [1/1], Batch [221/3134], Loss: 0.01180989\n",
            "Epoch [1/1], Batch [222/3134], Loss: 0.01187407\n",
            "Epoch [1/1], Batch [223/3134], Loss: 0.01182216\n",
            "Epoch [1/1], Batch [224/3134], Loss: 0.01184431\n",
            "Epoch [1/1], Batch [225/3134], Loss: 0.01184649\n",
            "Epoch [1/1], Batch [226/3134], Loss: 0.01184212\n",
            "Epoch [1/1], Batch [227/3134], Loss: 0.01180443\n",
            "Epoch [1/1], Batch [228/3134], Loss: 0.01189863\n",
            "Epoch [1/1], Batch [229/3134], Loss: 0.01181551\n",
            "Epoch [1/1], Batch [230/3134], Loss: 0.01183530\n",
            "Epoch [1/1], Batch [231/3134], Loss: 0.01184610\n",
            "Epoch [1/1], Batch [232/3134], Loss: 0.01188681\n",
            "Epoch [1/1], Batch [233/3134], Loss: 0.01182720\n",
            "Epoch [1/1], Batch [234/3134], Loss: 0.01184388\n",
            "Epoch [1/1], Batch [235/3134], Loss: 0.01185107\n",
            "Epoch [1/1], Batch [236/3134], Loss: 0.01184084\n",
            "Epoch [1/1], Batch [237/3134], Loss: 0.01185482\n",
            "Epoch [1/1], Batch [238/3134], Loss: 0.01187365\n",
            "Epoch [1/1], Batch [239/3134], Loss: 0.01192996\n",
            "Epoch [1/1], Batch [240/3134], Loss: 0.01185557\n",
            "Epoch [1/1], Batch [241/3134], Loss: 0.01185488\n",
            "Epoch [1/1], Batch [242/3134], Loss: 0.01182877\n",
            "Epoch [1/1], Batch [243/3134], Loss: 0.01185908\n",
            "Epoch [1/1], Batch [244/3134], Loss: 0.01186616\n",
            "Epoch [1/1], Batch [245/3134], Loss: 0.01188908\n",
            "Epoch [1/1], Batch [246/3134], Loss: 0.01185350\n",
            "Epoch [1/1], Batch [247/3134], Loss: 0.01189616\n",
            "Epoch [1/1], Batch [248/3134], Loss: 0.01182252\n",
            "Epoch [1/1], Batch [249/3134], Loss: 0.01182031\n",
            "Epoch [1/1], Batch [250/3134], Loss: 0.01184288\n",
            "Epoch [1/1], Batch [251/3134], Loss: 0.01187606\n",
            "Epoch [1/1], Batch [252/3134], Loss: 0.01186879\n",
            "Epoch [1/1], Batch [253/3134], Loss: 0.01187099\n",
            "Epoch [1/1], Batch [254/3134], Loss: 0.01188736\n",
            "Epoch [1/1], Batch [255/3134], Loss: 0.01184248\n",
            "Epoch [1/1], Batch [256/3134], Loss: 0.01182121\n",
            "Epoch [1/1], Batch [257/3134], Loss: 0.01180036\n",
            "Epoch [1/1], Batch [258/3134], Loss: 0.01186458\n",
            "Epoch [1/1], Batch [259/3134], Loss: 0.01181430\n",
            "Epoch [1/1], Batch [260/3134], Loss: 0.01180313\n",
            "Epoch [1/1], Batch [261/3134], Loss: 0.01192371\n",
            "Epoch [1/1], Batch [262/3134], Loss: 0.01183128\n",
            "Epoch [1/1], Batch [263/3134], Loss: 0.01188138\n",
            "Epoch [1/1], Batch [264/3134], Loss: 0.01183194\n",
            "Epoch [1/1], Batch [265/3134], Loss: 0.01181685\n",
            "Epoch [1/1], Batch [266/3134], Loss: 0.01187343\n",
            "Epoch [1/1], Batch [267/3134], Loss: 0.01189060\n",
            "Epoch [1/1], Batch [268/3134], Loss: 0.01176727\n",
            "Epoch [1/1], Batch [269/3134], Loss: 0.01183723\n",
            "Epoch [1/1], Batch [270/3134], Loss: 0.01192534\n",
            "Epoch [1/1], Batch [271/3134], Loss: 0.01182902\n",
            "Epoch [1/1], Batch [272/3134], Loss: 0.01180080\n",
            "Epoch [1/1], Batch [273/3134], Loss: 0.01182288\n",
            "Epoch [1/1], Batch [274/3134], Loss: 0.01187102\n",
            "Epoch [1/1], Batch [275/3134], Loss: 0.01181619\n",
            "Epoch [1/1], Batch [276/3134], Loss: 0.01190330\n",
            "Epoch [1/1], Batch [277/3134], Loss: 0.01186829\n",
            "Epoch [1/1], Batch [278/3134], Loss: 0.01189564\n",
            "Epoch [1/1], Batch [279/3134], Loss: 0.01187256\n",
            "Epoch [1/1], Batch [280/3134], Loss: 0.01183518\n",
            "Epoch [1/1], Batch [281/3134], Loss: 0.01179367\n",
            "Epoch [1/1], Batch [282/3134], Loss: 0.01187418\n",
            "Epoch [1/1], Batch [283/3134], Loss: 0.01191648\n",
            "Epoch [1/1], Batch [284/3134], Loss: 0.01183266\n",
            "Epoch [1/1], Batch [285/3134], Loss: 0.01188128\n",
            "Epoch [1/1], Batch [286/3134], Loss: 0.01178272\n",
            "Epoch [1/1], Batch [287/3134], Loss: 0.01177883\n",
            "Epoch [1/1], Batch [288/3134], Loss: 0.01185495\n",
            "Epoch [1/1], Batch [289/3134], Loss: 0.01185647\n",
            "Epoch [1/1], Batch [290/3134], Loss: 0.01187625\n",
            "Epoch [1/1], Batch [291/3134], Loss: 0.01184114\n",
            "Epoch [1/1], Batch [292/3134], Loss: 0.01186982\n",
            "Epoch [1/1], Batch [293/3134], Loss: 0.01183494\n",
            "Epoch [1/1], Batch [294/3134], Loss: 0.01184474\n",
            "Epoch [1/1], Batch [295/3134], Loss: 0.01188911\n",
            "Epoch [1/1], Batch [296/3134], Loss: 0.01186241\n",
            "Epoch [1/1], Batch [297/3134], Loss: 0.01184624\n",
            "Epoch [1/1], Batch [298/3134], Loss: 0.01185217\n",
            "Epoch [1/1], Batch [299/3134], Loss: 0.01190053\n",
            "Epoch [1/1], Batch [300/3134], Loss: 0.01183492\n",
            "Epoch [1/1], Batch [301/3134], Loss: 0.01185368\n",
            "Epoch [1/1], Batch [302/3134], Loss: 0.01187105\n",
            "Epoch [1/1], Batch [303/3134], Loss: 0.01186733\n",
            "Epoch [1/1], Batch [304/3134], Loss: 0.01187556\n",
            "Epoch [1/1], Batch [305/3134], Loss: 0.01190890\n",
            "Epoch [1/1], Batch [306/3134], Loss: 0.01189122\n",
            "Epoch [1/1], Batch [307/3134], Loss: 0.01185997\n",
            "Epoch [1/1], Batch [308/3134], Loss: 0.01190671\n",
            "Epoch [1/1], Batch [309/3134], Loss: 0.01185476\n",
            "Epoch [1/1], Batch [310/3134], Loss: 0.01186645\n",
            "Epoch [1/1], Batch [311/3134], Loss: 0.01178869\n",
            "Epoch [1/1], Batch [312/3134], Loss: 0.01190407\n",
            "Epoch [1/1], Batch [313/3134], Loss: 0.01189122\n",
            "Epoch [1/1], Batch [314/3134], Loss: 0.01191781\n",
            "Epoch [1/1], Batch [315/3134], Loss: 0.01191380\n",
            "Epoch [1/1], Batch [316/3134], Loss: 0.01188838\n",
            "Epoch [1/1], Batch [317/3134], Loss: 0.01180710\n",
            "Epoch [1/1], Batch [318/3134], Loss: 0.01192100\n",
            "Epoch [1/1], Batch [319/3134], Loss: 0.01180576\n",
            "Epoch [1/1], Batch [320/3134], Loss: 0.01182609\n",
            "Epoch [1/1], Batch [321/3134], Loss: 0.01186660\n",
            "Epoch [1/1], Batch [322/3134], Loss: 0.01185387\n",
            "Epoch [1/1], Batch [323/3134], Loss: 0.01186184\n",
            "Epoch [1/1], Batch [324/3134], Loss: 0.01182068\n",
            "Epoch [1/1], Batch [325/3134], Loss: 0.01189151\n",
            "Epoch [1/1], Batch [326/3134], Loss: 0.01185147\n",
            "Epoch [1/1], Batch [327/3134], Loss: 0.01182713\n",
            "Epoch [1/1], Batch [328/3134], Loss: 0.01181205\n",
            "Epoch [1/1], Batch [329/3134], Loss: 0.01178835\n",
            "Epoch [1/1], Batch [330/3134], Loss: 0.01188120\n",
            "Epoch [1/1], Batch [331/3134], Loss: 0.01181000\n",
            "Epoch [1/1], Batch [332/3134], Loss: 0.01189435\n",
            "Epoch [1/1], Batch [333/3134], Loss: 0.01189673\n",
            "Epoch [1/1], Batch [334/3134], Loss: 0.01180277\n",
            "Epoch [1/1], Batch [335/3134], Loss: 0.01182333\n",
            "Epoch [1/1], Batch [336/3134], Loss: 0.01193384\n",
            "Epoch [1/1], Batch [337/3134], Loss: 0.01184142\n",
            "Epoch [1/1], Batch [338/3134], Loss: 0.01187548\n",
            "Epoch [1/1], Batch [339/3134], Loss: 0.01186154\n",
            "Epoch [1/1], Batch [340/3134], Loss: 0.01184012\n",
            "Epoch [1/1], Batch [341/3134], Loss: 0.01189416\n",
            "Epoch [1/1], Batch [342/3134], Loss: 0.01180092\n",
            "Epoch [1/1], Batch [343/3134], Loss: 0.01183988\n",
            "Epoch [1/1], Batch [344/3134], Loss: 0.01181497\n",
            "Epoch [1/1], Batch [345/3134], Loss: 0.01186437\n",
            "Epoch [1/1], Batch [346/3134], Loss: 0.01188051\n",
            "Epoch [1/1], Batch [347/3134], Loss: 0.01186887\n",
            "Epoch [1/1], Batch [348/3134], Loss: 0.01185541\n",
            "Epoch [1/1], Batch [349/3134], Loss: 0.01180869\n",
            "Epoch [1/1], Batch [350/3134], Loss: 0.01186623\n",
            "Epoch [1/1], Batch [351/3134], Loss: 0.01183727\n",
            "Epoch [1/1], Batch [352/3134], Loss: 0.01190002\n",
            "Epoch [1/1], Batch [353/3134], Loss: 0.01189153\n",
            "Epoch [1/1], Batch [354/3134], Loss: 0.01186268\n",
            "Epoch [1/1], Batch [355/3134], Loss: 0.01181225\n",
            "Epoch [1/1], Batch [356/3134], Loss: 0.01185072\n",
            "Epoch [1/1], Batch [357/3134], Loss: 0.01182685\n",
            "Epoch [1/1], Batch [358/3134], Loss: 0.01185323\n",
            "Epoch [1/1], Batch [359/3134], Loss: 0.01185735\n",
            "Epoch [1/1], Batch [360/3134], Loss: 0.01176768\n",
            "Epoch [1/1], Batch [361/3134], Loss: 0.01183372\n",
            "Epoch [1/1], Batch [362/3134], Loss: 0.01186938\n",
            "Epoch [1/1], Batch [363/3134], Loss: 0.01181627\n",
            "Epoch [1/1], Batch [364/3134], Loss: 0.01184638\n",
            "Epoch [1/1], Batch [365/3134], Loss: 0.01189345\n",
            "Epoch [1/1], Batch [366/3134], Loss: 0.01183727\n",
            "Epoch [1/1], Batch [367/3134], Loss: 0.01181371\n",
            "Epoch [1/1], Batch [368/3134], Loss: 0.01181976\n",
            "Epoch [1/1], Batch [369/3134], Loss: 0.01181029\n",
            "Epoch [1/1], Batch [370/3134], Loss: 0.01182474\n",
            "Epoch [1/1], Batch [371/3134], Loss: 0.01183445\n",
            "Epoch [1/1], Batch [372/3134], Loss: 0.01185836\n",
            "Epoch [1/1], Batch [373/3134], Loss: 0.01184600\n",
            "Epoch [1/1], Batch [374/3134], Loss: 0.01185431\n",
            "Epoch [1/1], Batch [375/3134], Loss: 0.01185933\n",
            "Epoch [1/1], Batch [376/3134], Loss: 0.01182315\n",
            "Epoch [1/1], Batch [377/3134], Loss: 0.01184444\n",
            "Epoch [1/1], Batch [378/3134], Loss: 0.01182670\n",
            "Epoch [1/1], Batch [379/3134], Loss: 0.01184902\n",
            "Epoch [1/1], Batch [380/3134], Loss: 0.01177971\n",
            "Epoch [1/1], Batch [381/3134], Loss: 0.01187603\n",
            "Epoch [1/1], Batch [382/3134], Loss: 0.01190402\n",
            "Epoch [1/1], Batch [383/3134], Loss: 0.01186422\n",
            "Epoch [1/1], Batch [384/3134], Loss: 0.01183759\n",
            "Epoch [1/1], Batch [385/3134], Loss: 0.01192834\n",
            "Epoch [1/1], Batch [386/3134], Loss: 0.01186556\n",
            "Epoch [1/1], Batch [387/3134], Loss: 0.01189351\n",
            "Epoch [1/1], Batch [388/3134], Loss: 0.01186646\n",
            "Epoch [1/1], Batch [389/3134], Loss: 0.01194459\n",
            "Epoch [1/1], Batch [390/3134], Loss: 0.01184535\n",
            "Epoch [1/1], Batch [391/3134], Loss: 0.01186036\n",
            "Epoch [1/1], Batch [392/3134], Loss: 0.01179623\n",
            "Epoch [1/1], Batch [393/3134], Loss: 0.01187853\n",
            "Epoch [1/1], Batch [394/3134], Loss: 0.01182931\n",
            "Epoch [1/1], Batch [395/3134], Loss: 0.01188692\n",
            "Epoch [1/1], Batch [396/3134], Loss: 0.01183709\n",
            "Epoch [1/1], Batch [397/3134], Loss: 0.01184509\n",
            "Epoch [1/1], Batch [398/3134], Loss: 0.01186084\n",
            "Epoch [1/1], Batch [399/3134], Loss: 0.01189150\n",
            "Epoch [1/1], Batch [400/3134], Loss: 0.01176620\n",
            "Epoch [1/1], Batch [401/3134], Loss: 0.01186742\n",
            "Epoch [1/1], Batch [402/3134], Loss: 0.01188210\n",
            "Epoch [1/1], Batch [403/3134], Loss: 0.01189595\n",
            "Epoch [1/1], Batch [404/3134], Loss: 0.01184075\n",
            "Epoch [1/1], Batch [405/3134], Loss: 0.01182244\n",
            "Epoch [1/1], Batch [406/3134], Loss: 0.01189073\n",
            "Epoch [1/1], Batch [407/3134], Loss: 0.01184907\n",
            "Epoch [1/1], Batch [408/3134], Loss: 0.01186187\n",
            "Epoch [1/1], Batch [409/3134], Loss: 0.01181569\n",
            "Epoch [1/1], Batch [410/3134], Loss: 0.01189753\n",
            "Epoch [1/1], Batch [411/3134], Loss: 0.01179294\n",
            "Epoch [1/1], Batch [412/3134], Loss: 0.01192249\n",
            "Epoch [1/1], Batch [413/3134], Loss: 0.01186435\n",
            "Epoch [1/1], Batch [414/3134], Loss: 0.01184901\n",
            "Epoch [1/1], Batch [415/3134], Loss: 0.01176591\n",
            "Epoch [1/1], Batch [416/3134], Loss: 0.01185007\n",
            "Epoch [1/1], Batch [417/3134], Loss: 0.01182961\n",
            "Epoch [1/1], Batch [418/3134], Loss: 0.01182675\n",
            "Epoch [1/1], Batch [419/3134], Loss: 0.01191869\n",
            "Epoch [1/1], Batch [420/3134], Loss: 0.01184093\n",
            "Epoch [1/1], Batch [421/3134], Loss: 0.01187728\n",
            "Epoch [1/1], Batch [422/3134], Loss: 0.01186886\n",
            "Epoch [1/1], Batch [423/3134], Loss: 0.01184168\n",
            "Epoch [1/1], Batch [424/3134], Loss: 0.01179800\n",
            "Epoch [1/1], Batch [425/3134], Loss: 0.01186055\n",
            "Epoch [1/1], Batch [426/3134], Loss: 0.01188214\n",
            "Epoch [1/1], Batch [427/3134], Loss: 0.01183740\n",
            "Epoch [1/1], Batch [428/3134], Loss: 0.01176189\n",
            "Epoch [1/1], Batch [429/3134], Loss: 0.01183729\n",
            "Epoch [1/1], Batch [430/3134], Loss: 0.01189957\n",
            "Epoch [1/1], Batch [431/3134], Loss: 0.01192582\n",
            "Epoch [1/1], Batch [432/3134], Loss: 0.01189775\n",
            "Epoch [1/1], Batch [433/3134], Loss: 0.01183391\n",
            "Epoch [1/1], Batch [434/3134], Loss: 0.01183992\n",
            "Epoch [1/1], Batch [435/3134], Loss: 0.01184868\n",
            "Epoch [1/1], Batch [436/3134], Loss: 0.01186877\n",
            "Epoch [1/1], Batch [437/3134], Loss: 0.01185172\n",
            "Epoch [1/1], Batch [438/3134], Loss: 0.01185359\n",
            "Epoch [1/1], Batch [439/3134], Loss: 0.01185689\n",
            "Epoch [1/1], Batch [440/3134], Loss: 0.01187256\n",
            "Epoch [1/1], Batch [441/3134], Loss: 0.01186727\n",
            "Epoch [1/1], Batch [442/3134], Loss: 0.01184309\n",
            "Epoch [1/1], Batch [443/3134], Loss: 0.01179165\n",
            "Epoch [1/1], Batch [444/3134], Loss: 0.01186394\n",
            "Epoch [1/1], Batch [445/3134], Loss: 0.01190646\n",
            "Epoch [1/1], Batch [446/3134], Loss: 0.01187309\n",
            "Epoch [1/1], Batch [447/3134], Loss: 0.01178921\n",
            "Epoch [1/1], Batch [448/3134], Loss: 0.01177243\n",
            "Epoch [1/1], Batch [449/3134], Loss: 0.01187618\n",
            "Epoch [1/1], Batch [450/3134], Loss: 0.01185534\n",
            "Epoch [1/1], Batch [451/3134], Loss: 0.01187541\n",
            "Epoch [1/1], Batch [452/3134], Loss: 0.01185114\n",
            "Epoch [1/1], Batch [453/3134], Loss: 0.01176787\n",
            "Epoch [1/1], Batch [454/3134], Loss: 0.01184939\n",
            "Epoch [1/1], Batch [455/3134], Loss: 0.01182454\n",
            "Epoch [1/1], Batch [456/3134], Loss: 0.01184402\n",
            "Epoch [1/1], Batch [457/3134], Loss: 0.01192034\n",
            "Epoch [1/1], Batch [458/3134], Loss: 0.01185360\n",
            "Epoch [1/1], Batch [459/3134], Loss: 0.01186202\n",
            "Epoch [1/1], Batch [460/3134], Loss: 0.01187127\n",
            "Epoch [1/1], Batch [461/3134], Loss: 0.01186202\n",
            "Epoch [1/1], Batch [462/3134], Loss: 0.01184872\n",
            "Epoch [1/1], Batch [463/3134], Loss: 0.01189119\n",
            "Epoch [1/1], Batch [464/3134], Loss: 0.01185230\n",
            "Epoch [1/1], Batch [465/3134], Loss: 0.01182447\n",
            "Epoch [1/1], Batch [466/3134], Loss: 0.01190500\n",
            "Epoch [1/1], Batch [467/3134], Loss: 0.01184001\n",
            "Epoch [1/1], Batch [468/3134], Loss: 0.01180711\n",
            "Epoch [1/1], Batch [469/3134], Loss: 0.01186322\n",
            "Epoch [1/1], Batch [470/3134], Loss: 0.01184260\n",
            "Epoch [1/1], Batch [471/3134], Loss: 0.01185489\n",
            "Epoch [1/1], Batch [472/3134], Loss: 0.01182011\n",
            "Epoch [1/1], Batch [473/3134], Loss: 0.01180700\n",
            "Epoch [1/1], Batch [474/3134], Loss: 0.01183661\n",
            "Epoch [1/1], Batch [475/3134], Loss: 0.01186350\n",
            "Epoch [1/1], Batch [476/3134], Loss: 0.01185002\n",
            "Epoch [1/1], Batch [477/3134], Loss: 0.01185313\n",
            "Epoch [1/1], Batch [478/3134], Loss: 0.01183637\n",
            "Epoch [1/1], Batch [479/3134], Loss: 0.01186184\n",
            "Epoch [1/1], Batch [480/3134], Loss: 0.01182813\n",
            "Epoch [1/1], Batch [481/3134], Loss: 0.01182737\n",
            "Epoch [1/1], Batch [482/3134], Loss: 0.01181701\n",
            "Epoch [1/1], Batch [483/3134], Loss: 0.01187835\n",
            "Epoch [1/1], Batch [484/3134], Loss: 0.01192462\n",
            "Epoch [1/1], Batch [485/3134], Loss: 0.01183963\n",
            "Epoch [1/1], Batch [486/3134], Loss: 0.01182678\n",
            "Epoch [1/1], Batch [487/3134], Loss: 0.01186009\n",
            "Epoch [1/1], Batch [488/3134], Loss: 0.01186916\n",
            "Epoch [1/1], Batch [489/3134], Loss: 0.01189239\n",
            "Epoch [1/1], Batch [490/3134], Loss: 0.01184882\n",
            "Epoch [1/1], Batch [491/3134], Loss: 0.01187945\n",
            "Epoch [1/1], Batch [492/3134], Loss: 0.01183298\n",
            "Epoch [1/1], Batch [493/3134], Loss: 0.01182872\n",
            "Epoch [1/1], Batch [494/3134], Loss: 0.01184154\n",
            "Epoch [1/1], Batch [495/3134], Loss: 0.01191455\n",
            "Epoch [1/1], Batch [496/3134], Loss: 0.01194000\n",
            "Epoch [1/1], Batch [497/3134], Loss: 0.01185244\n",
            "Epoch [1/1], Batch [498/3134], Loss: 0.01186153\n",
            "Epoch [1/1], Batch [499/3134], Loss: 0.01192972\n",
            "Epoch [1/1], Batch [500/3134], Loss: 0.01183920\n",
            "Epoch [1/1], Batch [501/3134], Loss: 0.01181753\n",
            "Epoch [1/1], Batch [502/3134], Loss: 0.01187626\n",
            "Epoch [1/1], Batch [503/3134], Loss: 0.01192067\n",
            "Epoch [1/1], Batch [504/3134], Loss: 0.01185866\n",
            "Epoch [1/1], Batch [505/3134], Loss: 0.01184854\n",
            "Epoch [1/1], Batch [506/3134], Loss: 0.01184389\n",
            "Epoch [1/1], Batch [507/3134], Loss: 0.01181988\n",
            "Epoch [1/1], Batch [508/3134], Loss: 0.01183861\n",
            "Epoch [1/1], Batch [509/3134], Loss: 0.01186286\n",
            "Epoch [1/1], Batch [510/3134], Loss: 0.01188033\n",
            "Epoch [1/1], Batch [511/3134], Loss: 0.01189392\n",
            "Epoch [1/1], Batch [512/3134], Loss: 0.01179412\n",
            "Epoch [1/1], Batch [513/3134], Loss: 0.01183903\n",
            "Epoch [1/1], Batch [514/3134], Loss: 0.01182786\n",
            "Epoch [1/1], Batch [515/3134], Loss: 0.01186923\n",
            "Epoch [1/1], Batch [516/3134], Loss: 0.01184459\n",
            "Epoch [1/1], Batch [517/3134], Loss: 0.01177098\n",
            "Epoch [1/1], Batch [518/3134], Loss: 0.01189739\n",
            "Epoch [1/1], Batch [519/3134], Loss: 0.01185204\n",
            "Epoch [1/1], Batch [520/3134], Loss: 0.01184371\n",
            "Epoch [1/1], Batch [521/3134], Loss: 0.01180501\n",
            "Epoch [1/1], Batch [522/3134], Loss: 0.01184974\n",
            "Epoch [1/1], Batch [523/3134], Loss: 0.01188434\n",
            "Epoch [1/1], Batch [524/3134], Loss: 0.01186447\n",
            "Epoch [1/1], Batch [525/3134], Loss: 0.01184381\n",
            "Epoch [1/1], Batch [526/3134], Loss: 0.01188617\n",
            "Epoch [1/1], Batch [527/3134], Loss: 0.01184053\n",
            "Epoch [1/1], Batch [528/3134], Loss: 0.01188678\n",
            "Epoch [1/1], Batch [529/3134], Loss: 0.01185447\n",
            "Epoch [1/1], Batch [530/3134], Loss: 0.01182435\n",
            "Epoch [1/1], Batch [531/3134], Loss: 0.01179040\n",
            "Epoch [1/1], Batch [532/3134], Loss: 0.01186151\n",
            "Epoch [1/1], Batch [533/3134], Loss: 0.01184902\n",
            "Epoch [1/1], Batch [534/3134], Loss: 0.01187568\n",
            "Epoch [1/1], Batch [535/3134], Loss: 0.01184905\n",
            "Epoch [1/1], Batch [536/3134], Loss: 0.01182624\n",
            "Epoch [1/1], Batch [537/3134], Loss: 0.01185979\n",
            "Epoch [1/1], Batch [538/3134], Loss: 0.01181034\n",
            "Epoch [1/1], Batch [539/3134], Loss: 0.01180691\n",
            "Epoch [1/1], Batch [540/3134], Loss: 0.01184294\n",
            "Epoch [1/1], Batch [541/3134], Loss: 0.01188495\n",
            "Epoch [1/1], Batch [542/3134], Loss: 0.01181995\n",
            "Epoch [1/1], Batch [543/3134], Loss: 0.01183662\n",
            "Epoch [1/1], Batch [544/3134], Loss: 0.01175224\n",
            "Epoch [1/1], Batch [545/3134], Loss: 0.01186257\n",
            "Epoch [1/1], Batch [546/3134], Loss: 0.01178231\n",
            "Epoch [1/1], Batch [547/3134], Loss: 0.01183920\n",
            "Epoch [1/1], Batch [548/3134], Loss: 0.01179070\n",
            "Epoch [1/1], Batch [549/3134], Loss: 0.01184356\n",
            "Epoch [1/1], Batch [550/3134], Loss: 0.01188990\n",
            "Epoch [1/1], Batch [551/3134], Loss: 0.01187288\n",
            "Epoch [1/1], Batch [552/3134], Loss: 0.01190564\n",
            "Epoch [1/1], Batch [553/3134], Loss: 0.01189726\n",
            "Epoch [1/1], Batch [554/3134], Loss: 0.01186677\n",
            "Epoch [1/1], Batch [555/3134], Loss: 0.01186024\n",
            "Epoch [1/1], Batch [556/3134], Loss: 0.01182911\n",
            "Epoch [1/1], Batch [557/3134], Loss: 0.01183781\n",
            "Epoch [1/1], Batch [558/3134], Loss: 0.01183458\n",
            "Epoch [1/1], Batch [559/3134], Loss: 0.01183393\n",
            "Epoch [1/1], Batch [560/3134], Loss: 0.01176508\n",
            "Epoch [1/1], Batch [561/3134], Loss: 0.01180670\n",
            "Epoch [1/1], Batch [562/3134], Loss: 0.01188564\n",
            "Epoch [1/1], Batch [563/3134], Loss: 0.01184444\n",
            "Epoch [1/1], Batch [564/3134], Loss: 0.01183400\n",
            "Epoch [1/1], Batch [565/3134], Loss: 0.01186113\n",
            "Epoch [1/1], Batch [566/3134], Loss: 0.01178977\n",
            "Epoch [1/1], Batch [567/3134], Loss: 0.01182525\n",
            "Epoch [1/1], Batch [568/3134], Loss: 0.01180902\n",
            "Epoch [1/1], Batch [569/3134], Loss: 0.01189687\n",
            "Epoch [1/1], Batch [570/3134], Loss: 0.01186467\n",
            "Epoch [1/1], Batch [571/3134], Loss: 0.01181712\n",
            "Epoch [1/1], Batch [572/3134], Loss: 0.01181789\n",
            "Epoch [1/1], Batch [573/3134], Loss: 0.01183916\n",
            "Epoch [1/1], Batch [574/3134], Loss: 0.01179496\n",
            "Epoch [1/1], Batch [575/3134], Loss: 0.01186999\n",
            "Epoch [1/1], Batch [576/3134], Loss: 0.01187379\n",
            "Epoch [1/1], Batch [577/3134], Loss: 0.01184339\n",
            "Epoch [1/1], Batch [578/3134], Loss: 0.01188056\n",
            "Epoch [1/1], Batch [579/3134], Loss: 0.01184979\n",
            "Epoch [1/1], Batch [580/3134], Loss: 0.01187897\n",
            "Epoch [1/1], Batch [581/3134], Loss: 0.01184607\n",
            "Epoch [1/1], Batch [582/3134], Loss: 0.01184533\n",
            "Epoch [1/1], Batch [583/3134], Loss: 0.01184713\n",
            "Epoch [1/1], Batch [584/3134], Loss: 0.01178073\n",
            "Epoch [1/1], Batch [585/3134], Loss: 0.01188263\n",
            "Epoch [1/1], Batch [586/3134], Loss: 0.01185812\n",
            "Epoch [1/1], Batch [587/3134], Loss: 0.01184295\n",
            "Epoch [1/1], Batch [588/3134], Loss: 0.01187877\n",
            "Epoch [1/1], Batch [589/3134], Loss: 0.01188244\n",
            "Epoch [1/1], Batch [590/3134], Loss: 0.01183360\n",
            "Epoch [1/1], Batch [591/3134], Loss: 0.01180308\n",
            "Epoch [1/1], Batch [592/3134], Loss: 0.01179692\n",
            "Epoch [1/1], Batch [593/3134], Loss: 0.01181284\n",
            "Epoch [1/1], Batch [594/3134], Loss: 0.01184541\n",
            "Epoch [1/1], Batch [595/3134], Loss: 0.01188574\n",
            "Epoch [1/1], Batch [596/3134], Loss: 0.01183991\n",
            "Epoch [1/1], Batch [597/3134], Loss: 0.01179894\n",
            "Epoch [1/1], Batch [598/3134], Loss: 0.01186735\n",
            "Epoch [1/1], Batch [599/3134], Loss: 0.01187378\n",
            "Epoch [1/1], Batch [600/3134], Loss: 0.01186658\n",
            "Epoch [1/1], Batch [601/3134], Loss: 0.01183599\n",
            "Epoch [1/1], Batch [602/3134], Loss: 0.01183052\n",
            "Epoch [1/1], Batch [603/3134], Loss: 0.01177709\n",
            "Epoch [1/1], Batch [604/3134], Loss: 0.01191602\n",
            "Epoch [1/1], Batch [605/3134], Loss: 0.01181332\n",
            "Epoch [1/1], Batch [606/3134], Loss: 0.01180713\n",
            "Epoch [1/1], Batch [607/3134], Loss: 0.01186195\n",
            "Epoch [1/1], Batch [608/3134], Loss: 0.01188452\n",
            "Epoch [1/1], Batch [609/3134], Loss: 0.01180304\n",
            "Epoch [1/1], Batch [610/3134], Loss: 0.01183528\n",
            "Epoch [1/1], Batch [611/3134], Loss: 0.01179877\n",
            "Epoch [1/1], Batch [612/3134], Loss: 0.01184044\n",
            "Epoch [1/1], Batch [613/3134], Loss: 0.01183141\n",
            "Epoch [1/1], Batch [614/3134], Loss: 0.01181545\n",
            "Epoch [1/1], Batch [615/3134], Loss: 0.01180520\n",
            "Epoch [1/1], Batch [616/3134], Loss: 0.01184841\n",
            "Epoch [1/1], Batch [617/3134], Loss: 0.01188051\n",
            "Epoch [1/1], Batch [618/3134], Loss: 0.01183983\n",
            "Epoch [1/1], Batch [619/3134], Loss: 0.01184864\n",
            "Epoch [1/1], Batch [620/3134], Loss: 0.01179146\n",
            "Epoch [1/1], Batch [621/3134], Loss: 0.01183464\n",
            "Epoch [1/1], Batch [622/3134], Loss: 0.01180470\n",
            "Epoch [1/1], Batch [623/3134], Loss: 0.01185727\n",
            "Epoch [1/1], Batch [624/3134], Loss: 0.01186404\n",
            "Epoch [1/1], Batch [625/3134], Loss: 0.01192795\n",
            "Epoch [1/1], Batch [626/3134], Loss: 0.01182566\n",
            "Epoch [1/1], Batch [627/3134], Loss: 0.01182335\n",
            "Epoch [1/1], Batch [628/3134], Loss: 0.01177875\n",
            "Epoch [1/1], Batch [629/3134], Loss: 0.01180588\n",
            "Epoch [1/1], Batch [630/3134], Loss: 0.01181487\n",
            "Epoch [1/1], Batch [631/3134], Loss: 0.01181827\n",
            "Epoch [1/1], Batch [632/3134], Loss: 0.01189466\n",
            "Epoch [1/1], Batch [633/3134], Loss: 0.01185423\n",
            "Epoch [1/1], Batch [634/3134], Loss: 0.01187464\n",
            "Epoch [1/1], Batch [635/3134], Loss: 0.01183935\n",
            "Epoch [1/1], Batch [636/3134], Loss: 0.01179787\n",
            "Epoch [1/1], Batch [637/3134], Loss: 0.01180957\n",
            "Epoch [1/1], Batch [638/3134], Loss: 0.01183672\n",
            "Epoch [1/1], Batch [639/3134], Loss: 0.01178672\n",
            "Epoch [1/1], Batch [640/3134], Loss: 0.01181889\n",
            "Epoch [1/1], Batch [641/3134], Loss: 0.01181335\n",
            "Epoch [1/1], Batch [642/3134], Loss: 0.01182813\n",
            "Epoch [1/1], Batch [643/3134], Loss: 0.01185257\n",
            "Epoch [1/1], Batch [644/3134], Loss: 0.01186719\n",
            "Epoch [1/1], Batch [645/3134], Loss: 0.01186101\n",
            "Epoch [1/1], Batch [646/3134], Loss: 0.01185118\n",
            "Epoch [1/1], Batch [647/3134], Loss: 0.01181033\n",
            "Epoch [1/1], Batch [648/3134], Loss: 0.01182655\n",
            "Epoch [1/1], Batch [649/3134], Loss: 0.01186325\n",
            "Epoch [1/1], Batch [650/3134], Loss: 0.01183426\n",
            "Epoch [1/1], Batch [651/3134], Loss: 0.01187144\n",
            "Epoch [1/1], Batch [652/3134], Loss: 0.01175475\n",
            "Epoch [1/1], Batch [653/3134], Loss: 0.01184225\n",
            "Epoch [1/1], Batch [654/3134], Loss: 0.01182719\n",
            "Epoch [1/1], Batch [655/3134], Loss: 0.01183749\n",
            "Epoch [1/1], Batch [656/3134], Loss: 0.01185184\n",
            "Epoch [1/1], Batch [657/3134], Loss: 0.01189566\n",
            "Epoch [1/1], Batch [658/3134], Loss: 0.01184797\n",
            "Epoch [1/1], Batch [659/3134], Loss: 0.01185786\n",
            "Epoch [1/1], Batch [660/3134], Loss: 0.01187429\n",
            "Epoch [1/1], Batch [661/3134], Loss: 0.01185409\n",
            "Epoch [1/1], Batch [662/3134], Loss: 0.01174572\n",
            "Epoch [1/1], Batch [663/3134], Loss: 0.01184059\n",
            "Epoch [1/1], Batch [664/3134], Loss: 0.01187138\n",
            "Epoch [1/1], Batch [665/3134], Loss: 0.01183098\n",
            "Epoch [1/1], Batch [666/3134], Loss: 0.01185257\n",
            "Epoch [1/1], Batch [667/3134], Loss: 0.01186590\n",
            "Epoch [1/1], Batch [668/3134], Loss: 0.01184860\n",
            "Epoch [1/1], Batch [669/3134], Loss: 0.01181131\n",
            "Epoch [1/1], Batch [670/3134], Loss: 0.01182178\n",
            "Epoch [1/1], Batch [671/3134], Loss: 0.01180892\n",
            "Epoch [1/1], Batch [672/3134], Loss: 0.01182696\n",
            "Epoch [1/1], Batch [673/3134], Loss: 0.01179319\n",
            "Epoch [1/1], Batch [674/3134], Loss: 0.01190689\n",
            "Epoch [1/1], Batch [675/3134], Loss: 0.01183894\n",
            "Epoch [1/1], Batch [676/3134], Loss: 0.01181914\n",
            "Epoch [1/1], Batch [677/3134], Loss: 0.01183783\n",
            "Epoch [1/1], Batch [678/3134], Loss: 0.01197985\n",
            "Epoch [1/1], Batch [679/3134], Loss: 0.01183187\n",
            "Epoch [1/1], Batch [680/3134], Loss: 0.01181230\n",
            "Epoch [1/1], Batch [681/3134], Loss: 0.01185789\n",
            "Epoch [1/1], Batch [682/3134], Loss: 0.01187564\n",
            "Epoch [1/1], Batch [683/3134], Loss: 0.01188559\n",
            "Epoch [1/1], Batch [684/3134], Loss: 0.01183592\n",
            "Epoch [1/1], Batch [685/3134], Loss: 0.01176903\n",
            "Epoch [1/1], Batch [686/3134], Loss: 0.01186169\n",
            "Epoch [1/1], Batch [687/3134], Loss: 0.01181223\n",
            "Epoch [1/1], Batch [688/3134], Loss: 0.01180537\n",
            "Epoch [1/1], Batch [689/3134], Loss: 0.01184400\n",
            "Epoch [1/1], Batch [690/3134], Loss: 0.01191158\n",
            "Epoch [1/1], Batch [691/3134], Loss: 0.01185659\n",
            "Epoch [1/1], Batch [692/3134], Loss: 0.01186352\n",
            "Epoch [1/1], Batch [693/3134], Loss: 0.01187757\n",
            "Epoch [1/1], Batch [694/3134], Loss: 0.01181648\n",
            "Epoch [1/1], Batch [695/3134], Loss: 0.01189914\n",
            "Epoch [1/1], Batch [696/3134], Loss: 0.01181446\n",
            "Epoch [1/1], Batch [697/3134], Loss: 0.01185106\n",
            "Epoch [1/1], Batch [698/3134], Loss: 0.01184951\n",
            "Epoch [1/1], Batch [699/3134], Loss: 0.01190773\n",
            "Epoch [1/1], Batch [700/3134], Loss: 0.01181598\n",
            "Epoch [1/1], Batch [701/3134], Loss: 0.01189243\n",
            "Epoch [1/1], Batch [702/3134], Loss: 0.01185923\n",
            "Epoch [1/1], Batch [703/3134], Loss: 0.01178224\n",
            "Epoch [1/1], Batch [704/3134], Loss: 0.01184505\n",
            "Epoch [1/1], Batch [705/3134], Loss: 0.01184794\n",
            "Epoch [1/1], Batch [706/3134], Loss: 0.01180982\n",
            "Epoch [1/1], Batch [707/3134], Loss: 0.01183266\n",
            "Epoch [1/1], Batch [708/3134], Loss: 0.01183962\n",
            "Epoch [1/1], Batch [709/3134], Loss: 0.01179197\n",
            "Epoch [1/1], Batch [710/3134], Loss: 0.01180394\n",
            "Epoch [1/1], Batch [711/3134], Loss: 0.01185550\n",
            "Epoch [1/1], Batch [712/3134], Loss: 0.01182386\n",
            "Epoch [1/1], Batch [713/3134], Loss: 0.01180610\n",
            "Epoch [1/1], Batch [714/3134], Loss: 0.01179801\n",
            "Epoch [1/1], Batch [715/3134], Loss: 0.01182388\n",
            "Epoch [1/1], Batch [716/3134], Loss: 0.01176536\n",
            "Epoch [1/1], Batch [717/3134], Loss: 0.01182472\n",
            "Epoch [1/1], Batch [718/3134], Loss: 0.01183400\n",
            "Epoch [1/1], Batch [719/3134], Loss: 0.01187471\n",
            "Epoch [1/1], Batch [720/3134], Loss: 0.01181729\n",
            "Epoch [1/1], Batch [721/3134], Loss: 0.01181301\n",
            "Epoch [1/1], Batch [722/3134], Loss: 0.01179400\n",
            "Epoch [1/1], Batch [723/3134], Loss: 0.01192473\n",
            "Epoch [1/1], Batch [724/3134], Loss: 0.01184984\n",
            "Epoch [1/1], Batch [725/3134], Loss: 0.01183608\n",
            "Epoch [1/1], Batch [726/3134], Loss: 0.01183439\n",
            "Epoch [1/1], Batch [727/3134], Loss: 0.01180159\n",
            "Epoch [1/1], Batch [728/3134], Loss: 0.01183777\n",
            "Epoch [1/1], Batch [729/3134], Loss: 0.01191563\n",
            "Epoch [1/1], Batch [730/3134], Loss: 0.01187899\n",
            "Epoch [1/1], Batch [731/3134], Loss: 0.01187509\n",
            "Epoch [1/1], Batch [732/3134], Loss: 0.01178772\n",
            "Epoch [1/1], Batch [733/3134], Loss: 0.01178730\n",
            "Epoch [1/1], Batch [734/3134], Loss: 0.01185052\n",
            "Epoch [1/1], Batch [735/3134], Loss: 0.01183369\n",
            "Epoch [1/1], Batch [736/3134], Loss: 0.01189435\n",
            "Epoch [1/1], Batch [737/3134], Loss: 0.01183083\n",
            "Epoch [1/1], Batch [738/3134], Loss: 0.01179757\n",
            "Epoch [1/1], Batch [739/3134], Loss: 0.01190046\n",
            "Epoch [1/1], Batch [740/3134], Loss: 0.01193631\n",
            "Epoch [1/1], Batch [741/3134], Loss: 0.01187800\n",
            "Epoch [1/1], Batch [742/3134], Loss: 0.01188809\n",
            "Epoch [1/1], Batch [743/3134], Loss: 0.01189667\n",
            "Epoch [1/1], Batch [744/3134], Loss: 0.01179430\n",
            "Epoch [1/1], Batch [745/3134], Loss: 0.01179371\n",
            "Epoch [1/1], Batch [746/3134], Loss: 0.01179407\n",
            "Epoch [1/1], Batch [747/3134], Loss: 0.01180478\n",
            "Epoch [1/1], Batch [748/3134], Loss: 0.01180824\n",
            "Epoch [1/1], Batch [749/3134], Loss: 0.01182046\n",
            "Epoch [1/1], Batch [750/3134], Loss: 0.01182714\n",
            "Epoch [1/1], Batch [751/3134], Loss: 0.01187384\n",
            "Epoch [1/1], Batch [752/3134], Loss: 0.01181428\n",
            "Epoch [1/1], Batch [753/3134], Loss: 0.01175292\n",
            "Epoch [1/1], Batch [754/3134], Loss: 0.01185412\n",
            "Epoch [1/1], Batch [755/3134], Loss: 0.01185566\n",
            "Epoch [1/1], Batch [756/3134], Loss: 0.01182844\n",
            "Epoch [1/1], Batch [757/3134], Loss: 0.01183136\n",
            "Epoch [1/1], Batch [758/3134], Loss: 0.01184679\n",
            "Epoch [1/1], Batch [759/3134], Loss: 0.01185339\n",
            "Epoch [1/1], Batch [760/3134], Loss: 0.01180331\n",
            "Epoch [1/1], Batch [761/3134], Loss: 0.01183189\n",
            "Epoch [1/1], Batch [762/3134], Loss: 0.01182029\n",
            "Epoch [1/1], Batch [763/3134], Loss: 0.01188819\n",
            "Epoch [1/1], Batch [764/3134], Loss: 0.01187764\n",
            "Epoch [1/1], Batch [765/3134], Loss: 0.01178035\n",
            "Epoch [1/1], Batch [766/3134], Loss: 0.01183047\n",
            "Epoch [1/1], Batch [767/3134], Loss: 0.01187997\n",
            "Epoch [1/1], Batch [768/3134], Loss: 0.01184124\n",
            "Epoch [1/1], Batch [769/3134], Loss: 0.01188083\n",
            "Epoch [1/1], Batch [770/3134], Loss: 0.01179808\n",
            "Epoch [1/1], Batch [771/3134], Loss: 0.01176142\n",
            "Epoch [1/1], Batch [772/3134], Loss: 0.01180728\n",
            "Epoch [1/1], Batch [773/3134], Loss: 0.01184455\n",
            "Epoch [1/1], Batch [774/3134], Loss: 0.01180949\n",
            "Epoch [1/1], Batch [775/3134], Loss: 0.01181604\n",
            "Epoch [1/1], Batch [776/3134], Loss: 0.01180555\n",
            "Epoch [1/1], Batch [777/3134], Loss: 0.01185461\n",
            "Epoch [1/1], Batch [778/3134], Loss: 0.01180257\n",
            "Epoch [1/1], Batch [779/3134], Loss: 0.01182420\n",
            "Epoch [1/1], Batch [780/3134], Loss: 0.01185740\n",
            "Epoch [1/1], Batch [781/3134], Loss: 0.01180756\n",
            "Epoch [1/1], Batch [782/3134], Loss: 0.01180198\n",
            "Epoch [1/1], Batch [783/3134], Loss: 0.01184458\n",
            "Epoch [1/1], Batch [784/3134], Loss: 0.01187434\n",
            "Epoch [1/1], Batch [785/3134], Loss: 0.01180160\n",
            "Epoch [1/1], Batch [786/3134], Loss: 0.01180943\n",
            "Epoch [1/1], Batch [787/3134], Loss: 0.01181913\n",
            "Epoch [1/1], Batch [788/3134], Loss: 0.01186541\n",
            "Epoch [1/1], Batch [789/3134], Loss: 0.01184405\n",
            "Epoch [1/1], Batch [790/3134], Loss: 0.01185015\n",
            "Epoch [1/1], Batch [791/3134], Loss: 0.01183060\n",
            "Epoch [1/1], Batch [792/3134], Loss: 0.01187718\n",
            "Epoch [1/1], Batch [793/3134], Loss: 0.01185810\n",
            "Epoch [1/1], Batch [794/3134], Loss: 0.01181083\n",
            "Epoch [1/1], Batch [795/3134], Loss: 0.01191468\n",
            "Epoch [1/1], Batch [796/3134], Loss: 0.01183925\n",
            "Epoch [1/1], Batch [797/3134], Loss: 0.01177904\n",
            "Epoch [1/1], Batch [798/3134], Loss: 0.01182031\n",
            "Epoch [1/1], Batch [799/3134], Loss: 0.01183738\n",
            "Epoch [1/1], Batch [800/3134], Loss: 0.01188279\n",
            "Epoch [1/1], Batch [801/3134], Loss: 0.01191558\n",
            "Epoch [1/1], Batch [802/3134], Loss: 0.01179096\n",
            "Epoch [1/1], Batch [803/3134], Loss: 0.01174412\n",
            "Epoch [1/1], Batch [804/3134], Loss: 0.01179718\n",
            "Epoch [1/1], Batch [805/3134], Loss: 0.01182511\n",
            "Epoch [1/1], Batch [806/3134], Loss: 0.01185545\n",
            "Epoch [1/1], Batch [807/3134], Loss: 0.01183010\n",
            "Epoch [1/1], Batch [808/3134], Loss: 0.01182691\n",
            "Epoch [1/1], Batch [809/3134], Loss: 0.01178068\n",
            "Epoch [1/1], Batch [810/3134], Loss: 0.01185308\n",
            "Epoch [1/1], Batch [811/3134], Loss: 0.01184971\n",
            "Epoch [1/1], Batch [812/3134], Loss: 0.01186519\n",
            "Epoch [1/1], Batch [813/3134], Loss: 0.01179835\n",
            "Epoch [1/1], Batch [814/3134], Loss: 0.01180704\n",
            "Epoch [1/1], Batch [815/3134], Loss: 0.01179481\n",
            "Epoch [1/1], Batch [816/3134], Loss: 0.01179188\n",
            "Epoch [1/1], Batch [817/3134], Loss: 0.01184376\n",
            "Epoch [1/1], Batch [818/3134], Loss: 0.01186613\n",
            "Epoch [1/1], Batch [819/3134], Loss: 0.01184593\n",
            "Epoch [1/1], Batch [820/3134], Loss: 0.01186021\n",
            "Epoch [1/1], Batch [821/3134], Loss: 0.01180721\n",
            "Epoch [1/1], Batch [822/3134], Loss: 0.01185493\n",
            "Epoch [1/1], Batch [823/3134], Loss: 0.01184159\n",
            "Epoch [1/1], Batch [824/3134], Loss: 0.01188648\n",
            "Epoch [1/1], Batch [825/3134], Loss: 0.01177603\n",
            "Epoch [1/1], Batch [826/3134], Loss: 0.01175914\n",
            "Epoch [1/1], Batch [827/3134], Loss: 0.01183971\n",
            "Epoch [1/1], Batch [828/3134], Loss: 0.01187377\n",
            "Epoch [1/1], Batch [829/3134], Loss: 0.01174823\n",
            "Epoch [1/1], Batch [830/3134], Loss: 0.01182622\n",
            "Epoch [1/1], Batch [831/3134], Loss: 0.01184417\n",
            "Epoch [1/1], Batch [832/3134], Loss: 0.01178839\n",
            "Epoch [1/1], Batch [833/3134], Loss: 0.01181577\n",
            "Epoch [1/1], Batch [834/3134], Loss: 0.01187168\n",
            "Epoch [1/1], Batch [835/3134], Loss: 0.01183926\n",
            "Epoch [1/1], Batch [836/3134], Loss: 0.01184718\n",
            "Epoch [1/1], Batch [837/3134], Loss: 0.01187943\n",
            "Epoch [1/1], Batch [838/3134], Loss: 0.01183702\n",
            "Epoch [1/1], Batch [839/3134], Loss: 0.01185062\n",
            "Epoch [1/1], Batch [840/3134], Loss: 0.01185104\n",
            "Epoch [1/1], Batch [841/3134], Loss: 0.01182551\n",
            "Epoch [1/1], Batch [842/3134], Loss: 0.01184829\n",
            "Epoch [1/1], Batch [843/3134], Loss: 0.01185893\n",
            "Epoch [1/1], Batch [844/3134], Loss: 0.01179751\n",
            "Epoch [1/1], Batch [845/3134], Loss: 0.01177816\n",
            "Epoch [1/1], Batch [846/3134], Loss: 0.01185993\n",
            "Epoch [1/1], Batch [847/3134], Loss: 0.01178683\n",
            "Epoch [1/1], Batch [848/3134], Loss: 0.01181152\n",
            "Epoch [1/1], Batch [849/3134], Loss: 0.01183744\n",
            "Epoch [1/1], Batch [850/3134], Loss: 0.01181415\n",
            "Epoch [1/1], Batch [851/3134], Loss: 0.01182288\n",
            "Epoch [1/1], Batch [852/3134], Loss: 0.01181680\n",
            "Epoch [1/1], Batch [853/3134], Loss: 0.01183282\n",
            "Epoch [1/1], Batch [854/3134], Loss: 0.01186582\n",
            "Epoch [1/1], Batch [855/3134], Loss: 0.01180137\n",
            "Epoch [1/1], Batch [856/3134], Loss: 0.01187127\n",
            "Epoch [1/1], Batch [857/3134], Loss: 0.01180794\n",
            "Epoch [1/1], Batch [858/3134], Loss: 0.01182561\n",
            "Epoch [1/1], Batch [859/3134], Loss: 0.01186036\n",
            "Epoch [1/1], Batch [860/3134], Loss: 0.01184351\n",
            "Epoch [1/1], Batch [861/3134], Loss: 0.01181583\n",
            "Epoch [1/1], Batch [862/3134], Loss: 0.01190827\n",
            "Epoch [1/1], Batch [863/3134], Loss: 0.01180267\n",
            "Epoch [1/1], Batch [864/3134], Loss: 0.01188151\n",
            "Epoch [1/1], Batch [865/3134], Loss: 0.01190005\n",
            "Epoch [1/1], Batch [866/3134], Loss: 0.01185784\n",
            "Epoch [1/1], Batch [867/3134], Loss: 0.01185942\n",
            "Epoch [1/1], Batch [868/3134], Loss: 0.01184872\n",
            "Epoch [1/1], Batch [869/3134], Loss: 0.01181246\n",
            "Epoch [1/1], Batch [870/3134], Loss: 0.01183151\n",
            "Epoch [1/1], Batch [871/3134], Loss: 0.01180013\n",
            "Epoch [1/1], Batch [872/3134], Loss: 0.01180198\n",
            "Epoch [1/1], Batch [873/3134], Loss: 0.01185480\n",
            "Epoch [1/1], Batch [874/3134], Loss: 0.01178718\n",
            "Epoch [1/1], Batch [875/3134], Loss: 0.01186889\n",
            "Epoch [1/1], Batch [876/3134], Loss: 0.01187626\n",
            "Epoch [1/1], Batch [877/3134], Loss: 0.01184506\n",
            "Epoch [1/1], Batch [878/3134], Loss: 0.01183697\n",
            "Epoch [1/1], Batch [879/3134], Loss: 0.01176881\n",
            "Epoch [1/1], Batch [880/3134], Loss: 0.01185723\n",
            "Epoch [1/1], Batch [881/3134], Loss: 0.01188703\n",
            "Epoch [1/1], Batch [882/3134], Loss: 0.01187346\n",
            "Epoch [1/1], Batch [883/3134], Loss: 0.01178629\n",
            "Epoch [1/1], Batch [884/3134], Loss: 0.01179353\n",
            "Epoch [1/1], Batch [885/3134], Loss: 0.01178041\n",
            "Epoch [1/1], Batch [886/3134], Loss: 0.01175801\n",
            "Epoch [1/1], Batch [887/3134], Loss: 0.01179533\n",
            "Epoch [1/1], Batch [888/3134], Loss: 0.01187516\n",
            "Epoch [1/1], Batch [889/3134], Loss: 0.01179922\n",
            "Epoch [1/1], Batch [890/3134], Loss: 0.01190262\n",
            "Epoch [1/1], Batch [891/3134], Loss: 0.01179735\n",
            "Epoch [1/1], Batch [892/3134], Loss: 0.01184958\n",
            "Epoch [1/1], Batch [893/3134], Loss: 0.01177304\n",
            "Epoch [1/1], Batch [894/3134], Loss: 0.01180104\n",
            "Epoch [1/1], Batch [895/3134], Loss: 0.01185900\n",
            "Epoch [1/1], Batch [896/3134], Loss: 0.01180108\n",
            "Epoch [1/1], Batch [897/3134], Loss: 0.01192588\n",
            "Epoch [1/1], Batch [898/3134], Loss: 0.01178691\n",
            "Epoch [1/1], Batch [899/3134], Loss: 0.01185215\n",
            "Epoch [1/1], Batch [900/3134], Loss: 0.01180203\n",
            "Epoch [1/1], Batch [901/3134], Loss: 0.01181415\n",
            "Epoch [1/1], Batch [902/3134], Loss: 0.01184143\n",
            "Epoch [1/1], Batch [903/3134], Loss: 0.01188709\n",
            "Epoch [1/1], Batch [904/3134], Loss: 0.01187295\n",
            "Epoch [1/1], Batch [905/3134], Loss: 0.01180933\n",
            "Epoch [1/1], Batch [906/3134], Loss: 0.01189367\n",
            "Epoch [1/1], Batch [907/3134], Loss: 0.01180370\n",
            "Epoch [1/1], Batch [908/3134], Loss: 0.01177222\n",
            "Epoch [1/1], Batch [909/3134], Loss: 0.01178262\n",
            "Epoch [1/1], Batch [910/3134], Loss: 0.01181684\n",
            "Epoch [1/1], Batch [911/3134], Loss: 0.01187250\n",
            "Epoch [1/1], Batch [912/3134], Loss: 0.01181708\n",
            "Epoch [1/1], Batch [913/3134], Loss: 0.01185530\n",
            "Epoch [1/1], Batch [914/3134], Loss: 0.01179097\n",
            "Epoch [1/1], Batch [915/3134], Loss: 0.01183025\n",
            "Epoch [1/1], Batch [916/3134], Loss: 0.01181330\n",
            "Epoch [1/1], Batch [917/3134], Loss: 0.01184764\n",
            "Epoch [1/1], Batch [918/3134], Loss: 0.01181676\n",
            "Epoch [1/1], Batch [919/3134], Loss: 0.01185249\n",
            "Epoch [1/1], Batch [920/3134], Loss: 0.01181504\n",
            "Epoch [1/1], Batch [921/3134], Loss: 0.01182766\n",
            "Epoch [1/1], Batch [922/3134], Loss: 0.01181569\n",
            "Epoch [1/1], Batch [923/3134], Loss: 0.01186521\n",
            "Epoch [1/1], Batch [924/3134], Loss: 0.01185252\n",
            "Epoch [1/1], Batch [925/3134], Loss: 0.01187422\n",
            "Epoch [1/1], Batch [926/3134], Loss: 0.01182250\n",
            "Epoch [1/1], Batch [927/3134], Loss: 0.01181305\n",
            "Epoch [1/1], Batch [928/3134], Loss: 0.01180084\n",
            "Epoch [1/1], Batch [929/3134], Loss: 0.01180257\n",
            "Epoch [1/1], Batch [930/3134], Loss: 0.01186702\n",
            "Epoch [1/1], Batch [931/3134], Loss: 0.01179799\n",
            "Epoch [1/1], Batch [932/3134], Loss: 0.01181037\n",
            "Epoch [1/1], Batch [933/3134], Loss: 0.01182442\n",
            "Epoch [1/1], Batch [934/3134], Loss: 0.01184552\n",
            "Epoch [1/1], Batch [935/3134], Loss: 0.01184861\n",
            "Epoch [1/1], Batch [936/3134], Loss: 0.01185044\n",
            "Epoch [1/1], Batch [937/3134], Loss: 0.01185102\n",
            "Epoch [1/1], Batch [938/3134], Loss: 0.01179326\n",
            "Epoch [1/1], Batch [939/3134], Loss: 0.01180064\n",
            "Epoch [1/1], Batch [940/3134], Loss: 0.01180412\n",
            "Epoch [1/1], Batch [941/3134], Loss: 0.01183270\n",
            "Epoch [1/1], Batch [942/3134], Loss: 0.01188110\n",
            "Epoch [1/1], Batch [943/3134], Loss: 0.01187575\n",
            "Epoch [1/1], Batch [944/3134], Loss: 0.01188094\n",
            "Epoch [1/1], Batch [945/3134], Loss: 0.01182074\n",
            "Epoch [1/1], Batch [946/3134], Loss: 0.01183718\n",
            "Epoch [1/1], Batch [947/3134], Loss: 0.01184823\n",
            "Epoch [1/1], Batch [948/3134], Loss: 0.01188529\n",
            "Epoch [1/1], Batch [949/3134], Loss: 0.01181160\n",
            "Epoch [1/1], Batch [950/3134], Loss: 0.01179914\n",
            "Epoch [1/1], Batch [951/3134], Loss: 0.01181132\n",
            "Epoch [1/1], Batch [952/3134], Loss: 0.01180560\n",
            "Epoch [1/1], Batch [953/3134], Loss: 0.01181045\n",
            "Epoch [1/1], Batch [954/3134], Loss: 0.01181586\n",
            "Epoch [1/1], Batch [955/3134], Loss: 0.01184981\n",
            "Epoch [1/1], Batch [956/3134], Loss: 0.01180815\n",
            "Epoch [1/1], Batch [957/3134], Loss: 0.01179944\n",
            "Epoch [1/1], Batch [958/3134], Loss: 0.01181896\n",
            "Epoch [1/1], Batch [959/3134], Loss: 0.01178462\n",
            "Epoch [1/1], Batch [960/3134], Loss: 0.01180823\n",
            "Epoch [1/1], Batch [961/3134], Loss: 0.01181611\n",
            "Epoch [1/1], Batch [962/3134], Loss: 0.01181678\n",
            "Epoch [1/1], Batch [963/3134], Loss: 0.01175858\n",
            "Epoch [1/1], Batch [964/3134], Loss: 0.01182096\n",
            "Epoch [1/1], Batch [965/3134], Loss: 0.01182165\n",
            "Epoch [1/1], Batch [966/3134], Loss: 0.01185267\n",
            "Epoch [1/1], Batch [967/3134], Loss: 0.01185443\n",
            "Epoch [1/1], Batch [968/3134], Loss: 0.01186510\n",
            "Epoch [1/1], Batch [969/3134], Loss: 0.01175507\n",
            "Epoch [1/1], Batch [970/3134], Loss: 0.01184725\n",
            "Epoch [1/1], Batch [971/3134], Loss: 0.01185435\n",
            "Epoch [1/1], Batch [972/3134], Loss: 0.01182442\n",
            "Epoch [1/1], Batch [973/3134], Loss: 0.01181132\n",
            "Epoch [1/1], Batch [974/3134], Loss: 0.01186274\n",
            "Epoch [1/1], Batch [975/3134], Loss: 0.01182667\n",
            "Epoch [1/1], Batch [976/3134], Loss: 0.01184503\n",
            "Epoch [1/1], Batch [977/3134], Loss: 0.01183680\n",
            "Epoch [1/1], Batch [978/3134], Loss: 0.01183653\n",
            "Epoch [1/1], Batch [979/3134], Loss: 0.01187544\n",
            "Epoch [1/1], Batch [980/3134], Loss: 0.01179096\n",
            "Epoch [1/1], Batch [981/3134], Loss: 0.01183023\n",
            "Epoch [1/1], Batch [982/3134], Loss: 0.01178637\n",
            "Epoch [1/1], Batch [983/3134], Loss: 0.01181618\n",
            "Epoch [1/1], Batch [984/3134], Loss: 0.01181941\n",
            "Epoch [1/1], Batch [985/3134], Loss: 0.01184892\n",
            "Epoch [1/1], Batch [986/3134], Loss: 0.01180151\n",
            "Epoch [1/1], Batch [987/3134], Loss: 0.01180695\n",
            "Epoch [1/1], Batch [988/3134], Loss: 0.01181892\n",
            "Epoch [1/1], Batch [989/3134], Loss: 0.01183278\n",
            "Epoch [1/1], Batch [990/3134], Loss: 0.01186703\n",
            "Epoch [1/1], Batch [991/3134], Loss: 0.01184495\n",
            "Epoch [1/1], Batch [992/3134], Loss: 0.01192614\n",
            "Epoch [1/1], Batch [993/3134], Loss: 0.01186924\n",
            "Epoch [1/1], Batch [994/3134], Loss: 0.01178716\n",
            "Epoch [1/1], Batch [995/3134], Loss: 0.01181084\n",
            "Epoch [1/1], Batch [996/3134], Loss: 0.01184539\n",
            "Epoch [1/1], Batch [997/3134], Loss: 0.01181431\n",
            "Epoch [1/1], Batch [998/3134], Loss: 0.01185524\n",
            "Epoch [1/1], Batch [999/3134], Loss: 0.01186282\n",
            "Epoch [1/1], Batch [1000/3134], Loss: 0.01184046\n",
            "Epoch [1/1], Batch [1001/3134], Loss: 0.01190426\n",
            "Epoch [1/1], Batch [1002/3134], Loss: 0.01180071\n",
            "Epoch [1/1], Batch [1003/3134], Loss: 0.01178644\n",
            "Epoch [1/1], Batch [1004/3134], Loss: 0.01183710\n",
            "Epoch [1/1], Batch [1005/3134], Loss: 0.01183117\n",
            "Epoch [1/1], Batch [1006/3134], Loss: 0.01188087\n",
            "Epoch [1/1], Batch [1007/3134], Loss: 0.01179131\n",
            "Epoch [1/1], Batch [1008/3134], Loss: 0.01181208\n",
            "Epoch [1/1], Batch [1009/3134], Loss: 0.01185316\n",
            "Epoch [1/1], Batch [1010/3134], Loss: 0.01189766\n",
            "Epoch [1/1], Batch [1011/3134], Loss: 0.01180025\n",
            "Epoch [1/1], Batch [1012/3134], Loss: 0.01180320\n",
            "Epoch [1/1], Batch [1013/3134], Loss: 0.01180738\n",
            "Epoch [1/1], Batch [1014/3134], Loss: 0.01183908\n",
            "Epoch [1/1], Batch [1015/3134], Loss: 0.01181264\n",
            "Epoch [1/1], Batch [1016/3134], Loss: 0.01182039\n",
            "Epoch [1/1], Batch [1017/3134], Loss: 0.01186187\n",
            "Epoch [1/1], Batch [1018/3134], Loss: 0.01183459\n",
            "Epoch [1/1], Batch [1019/3134], Loss: 0.01189408\n",
            "Epoch [1/1], Batch [1020/3134], Loss: 0.01178299\n",
            "Epoch [1/1], Batch [1021/3134], Loss: 0.01181528\n",
            "Epoch [1/1], Batch [1022/3134], Loss: 0.01179362\n",
            "Epoch [1/1], Batch [1023/3134], Loss: 0.01183364\n",
            "Epoch [1/1], Batch [1024/3134], Loss: 0.01180268\n",
            "Epoch [1/1], Batch [1025/3134], Loss: 0.01183838\n",
            "Epoch [1/1], Batch [1026/3134], Loss: 0.01182481\n",
            "Epoch [1/1], Batch [1027/3134], Loss: 0.01177529\n",
            "Epoch [1/1], Batch [1028/3134], Loss: 0.01180121\n",
            "Epoch [1/1], Batch [1029/3134], Loss: 0.01187036\n",
            "Epoch [1/1], Batch [1030/3134], Loss: 0.01177963\n",
            "Epoch [1/1], Batch [1031/3134], Loss: 0.01183812\n",
            "Epoch [1/1], Batch [1032/3134], Loss: 0.01176558\n",
            "Epoch [1/1], Batch [1033/3134], Loss: 0.01184496\n",
            "Epoch [1/1], Batch [1034/3134], Loss: 0.01182947\n",
            "Epoch [1/1], Batch [1035/3134], Loss: 0.01179870\n",
            "Epoch [1/1], Batch [1036/3134], Loss: 0.01181232\n",
            "Epoch [1/1], Batch [1037/3134], Loss: 0.01176014\n",
            "Epoch [1/1], Batch [1038/3134], Loss: 0.01178208\n",
            "Epoch [1/1], Batch [1039/3134], Loss: 0.01179816\n",
            "Epoch [1/1], Batch [1040/3134], Loss: 0.01181770\n",
            "Epoch [1/1], Batch [1041/3134], Loss: 0.01180680\n",
            "Epoch [1/1], Batch [1042/3134], Loss: 0.01184412\n",
            "Epoch [1/1], Batch [1043/3134], Loss: 0.01183019\n",
            "Epoch [1/1], Batch [1044/3134], Loss: 0.01183272\n",
            "Epoch [1/1], Batch [1045/3134], Loss: 0.01182497\n",
            "Epoch [1/1], Batch [1046/3134], Loss: 0.01183840\n",
            "Epoch [1/1], Batch [1047/3134], Loss: 0.01180816\n",
            "Epoch [1/1], Batch [1048/3134], Loss: 0.01177980\n",
            "Epoch [1/1], Batch [1049/3134], Loss: 0.01180885\n",
            "Epoch [1/1], Batch [1050/3134], Loss: 0.01183197\n",
            "Epoch [1/1], Batch [1051/3134], Loss: 0.01184909\n",
            "Epoch [1/1], Batch [1052/3134], Loss: 0.01179950\n",
            "Epoch [1/1], Batch [1053/3134], Loss: 0.01181095\n",
            "Epoch [1/1], Batch [1054/3134], Loss: 0.01185755\n",
            "Epoch [1/1], Batch [1055/3134], Loss: 0.01186207\n",
            "Epoch [1/1], Batch [1056/3134], Loss: 0.01178673\n",
            "Epoch [1/1], Batch [1057/3134], Loss: 0.01181560\n",
            "Epoch [1/1], Batch [1058/3134], Loss: 0.01180119\n",
            "Epoch [1/1], Batch [1059/3134], Loss: 0.01179591\n",
            "Epoch [1/1], Batch [1060/3134], Loss: 0.01178996\n",
            "Epoch [1/1], Batch [1061/3134], Loss: 0.01183570\n",
            "Epoch [1/1], Batch [1062/3134], Loss: 0.01186636\n",
            "Epoch [1/1], Batch [1063/3134], Loss: 0.01187216\n",
            "Epoch [1/1], Batch [1064/3134], Loss: 0.01188696\n",
            "Epoch [1/1], Batch [1065/3134], Loss: 0.01187338\n",
            "Epoch [1/1], Batch [1066/3134], Loss: 0.01186869\n",
            "Epoch [1/1], Batch [1067/3134], Loss: 0.01181449\n",
            "Epoch [1/1], Batch [1068/3134], Loss: 0.01180568\n",
            "Epoch [1/1], Batch [1069/3134], Loss: 0.01178755\n",
            "Epoch [1/1], Batch [1070/3134], Loss: 0.01177666\n",
            "Epoch [1/1], Batch [1071/3134], Loss: 0.01181837\n",
            "Epoch [1/1], Batch [1072/3134], Loss: 0.01184657\n",
            "Epoch [1/1], Batch [1073/3134], Loss: 0.01184801\n",
            "Epoch [1/1], Batch [1074/3134], Loss: 0.01182296\n",
            "Epoch [1/1], Batch [1075/3134], Loss: 0.01181213\n",
            "Epoch [1/1], Batch [1076/3134], Loss: 0.01187408\n",
            "Epoch [1/1], Batch [1077/3134], Loss: 0.01176717\n",
            "Epoch [1/1], Batch [1078/3134], Loss: 0.01180998\n",
            "Epoch [1/1], Batch [1079/3134], Loss: 0.01172157\n",
            "Epoch [1/1], Batch [1080/3134], Loss: 0.01188143\n",
            "Epoch [1/1], Batch [1081/3134], Loss: 0.01183600\n",
            "Epoch [1/1], Batch [1082/3134], Loss: 0.01186778\n",
            "Epoch [1/1], Batch [1083/3134], Loss: 0.01180465\n",
            "Epoch [1/1], Batch [1084/3134], Loss: 0.01181612\n",
            "Epoch [1/1], Batch [1085/3134], Loss: 0.01175115\n",
            "Epoch [1/1], Batch [1086/3134], Loss: 0.01185469\n",
            "Epoch [1/1], Batch [1087/3134], Loss: 0.01185791\n",
            "Epoch [1/1], Batch [1088/3134], Loss: 0.01176910\n",
            "Epoch [1/1], Batch [1089/3134], Loss: 0.01182406\n",
            "Epoch [1/1], Batch [1090/3134], Loss: 0.01179453\n",
            "Epoch [1/1], Batch [1091/3134], Loss: 0.01179834\n",
            "Epoch [1/1], Batch [1092/3134], Loss: 0.01183196\n",
            "Epoch [1/1], Batch [1093/3134], Loss: 0.01180061\n",
            "Epoch [1/1], Batch [1094/3134], Loss: 0.01184792\n",
            "Epoch [1/1], Batch [1095/3134], Loss: 0.01178594\n",
            "Epoch [1/1], Batch [1096/3134], Loss: 0.01183143\n",
            "Epoch [1/1], Batch [1097/3134], Loss: 0.01185141\n",
            "Epoch [1/1], Batch [1098/3134], Loss: 0.01179035\n",
            "Epoch [1/1], Batch [1099/3134], Loss: 0.01182386\n",
            "Epoch [1/1], Batch [1100/3134], Loss: 0.01188204\n",
            "Epoch [1/1], Batch [1101/3134], Loss: 0.01175308\n",
            "Epoch [1/1], Batch [1102/3134], Loss: 0.01189126\n",
            "Epoch [1/1], Batch [1103/3134], Loss: 0.01185826\n",
            "Epoch [1/1], Batch [1104/3134], Loss: 0.01181764\n",
            "Epoch [1/1], Batch [1105/3134], Loss: 0.01184211\n",
            "Epoch [1/1], Batch [1106/3134], Loss: 0.01188183\n",
            "Epoch [1/1], Batch [1107/3134], Loss: 0.01186845\n",
            "Epoch [1/1], Batch [1108/3134], Loss: 0.01181066\n",
            "Epoch [1/1], Batch [1109/3134], Loss: 0.01188038\n",
            "Epoch [1/1], Batch [1110/3134], Loss: 0.01178301\n",
            "Epoch [1/1], Batch [1111/3134], Loss: 0.01187764\n",
            "Epoch [1/1], Batch [1112/3134], Loss: 0.01183429\n",
            "Epoch [1/1], Batch [1113/3134], Loss: 0.01185674\n",
            "Epoch [1/1], Batch [1114/3134], Loss: 0.01179464\n",
            "Epoch [1/1], Batch [1115/3134], Loss: 0.01183214\n",
            "Epoch [1/1], Batch [1116/3134], Loss: 0.01182928\n",
            "Epoch [1/1], Batch [1117/3134], Loss: 0.01179688\n",
            "Epoch [1/1], Batch [1118/3134], Loss: 0.01180720\n",
            "Epoch [1/1], Batch [1119/3134], Loss: 0.01182602\n",
            "Epoch [1/1], Batch [1120/3134], Loss: 0.01189142\n",
            "Epoch [1/1], Batch [1121/3134], Loss: 0.01180995\n",
            "Epoch [1/1], Batch [1122/3134], Loss: 0.01180438\n",
            "Epoch [1/1], Batch [1123/3134], Loss: 0.01181360\n",
            "Epoch [1/1], Batch [1124/3134], Loss: 0.01188005\n",
            "Epoch [1/1], Batch [1125/3134], Loss: 0.01184401\n",
            "Epoch [1/1], Batch [1126/3134], Loss: 0.01181968\n",
            "Epoch [1/1], Batch [1127/3134], Loss: 0.01187773\n",
            "Epoch [1/1], Batch [1128/3134], Loss: 0.01177221\n",
            "Epoch [1/1], Batch [1129/3134], Loss: 0.01181526\n",
            "Epoch [1/1], Batch [1130/3134], Loss: 0.01183303\n",
            "Epoch [1/1], Batch [1131/3134], Loss: 0.01183124\n",
            "Epoch [1/1], Batch [1132/3134], Loss: 0.01182180\n",
            "Epoch [1/1], Batch [1133/3134], Loss: 0.01179263\n",
            "Epoch [1/1], Batch [1134/3134], Loss: 0.01186821\n",
            "Epoch [1/1], Batch [1135/3134], Loss: 0.01182813\n",
            "Epoch [1/1], Batch [1136/3134], Loss: 0.01183377\n",
            "Epoch [1/1], Batch [1137/3134], Loss: 0.01177233\n",
            "Epoch [1/1], Batch [1138/3134], Loss: 0.01180548\n",
            "Epoch [1/1], Batch [1139/3134], Loss: 0.01184206\n",
            "Epoch [1/1], Batch [1140/3134], Loss: 0.01186485\n",
            "Epoch [1/1], Batch [1141/3134], Loss: 0.01180234\n",
            "Epoch [1/1], Batch [1142/3134], Loss: 0.01190090\n",
            "Epoch [1/1], Batch [1143/3134], Loss: 0.01179867\n",
            "Epoch [1/1], Batch [1144/3134], Loss: 0.01182317\n",
            "Epoch [1/1], Batch [1145/3134], Loss: 0.01183392\n",
            "Epoch [1/1], Batch [1146/3134], Loss: 0.01179402\n",
            "Epoch [1/1], Batch [1147/3134], Loss: 0.01181765\n",
            "Epoch [1/1], Batch [1148/3134], Loss: 0.01180694\n",
            "Epoch [1/1], Batch [1149/3134], Loss: 0.01187574\n",
            "Epoch [1/1], Batch [1150/3134], Loss: 0.01187177\n",
            "Epoch [1/1], Batch [1151/3134], Loss: 0.01181547\n",
            "Epoch [1/1], Batch [1152/3134], Loss: 0.01179260\n",
            "Epoch [1/1], Batch [1153/3134], Loss: 0.01178185\n",
            "Epoch [1/1], Batch [1154/3134], Loss: 0.01180329\n",
            "Epoch [1/1], Batch [1155/3134], Loss: 0.01181601\n",
            "Epoch [1/1], Batch [1156/3134], Loss: 0.01179529\n",
            "Epoch [1/1], Batch [1157/3134], Loss: 0.01181289\n",
            "Epoch [1/1], Batch [1158/3134], Loss: 0.01186641\n",
            "Epoch [1/1], Batch [1159/3134], Loss: 0.01186064\n",
            "Epoch [1/1], Batch [1160/3134], Loss: 0.01177003\n",
            "Epoch [1/1], Batch [1161/3134], Loss: 0.01182227\n",
            "Epoch [1/1], Batch [1162/3134], Loss: 0.01175927\n",
            "Epoch [1/1], Batch [1163/3134], Loss: 0.01176901\n",
            "Epoch [1/1], Batch [1164/3134], Loss: 0.01186663\n",
            "Epoch [1/1], Batch [1165/3134], Loss: 0.01181144\n",
            "Epoch [1/1], Batch [1166/3134], Loss: 0.01180909\n",
            "Epoch [1/1], Batch [1167/3134], Loss: 0.01180519\n",
            "Epoch [1/1], Batch [1168/3134], Loss: 0.01177783\n",
            "Epoch [1/1], Batch [1169/3134], Loss: 0.01187491\n",
            "Epoch [1/1], Batch [1170/3134], Loss: 0.01181400\n",
            "Epoch [1/1], Batch [1171/3134], Loss: 0.01183659\n",
            "Epoch [1/1], Batch [1172/3134], Loss: 0.01184569\n",
            "Epoch [1/1], Batch [1173/3134], Loss: 0.01184473\n",
            "Epoch [1/1], Batch [1174/3134], Loss: 0.01181504\n",
            "Epoch [1/1], Batch [1175/3134], Loss: 0.01184228\n",
            "Epoch [1/1], Batch [1176/3134], Loss: 0.01179998\n",
            "Epoch [1/1], Batch [1177/3134], Loss: 0.01175000\n",
            "Epoch [1/1], Batch [1178/3134], Loss: 0.01180856\n",
            "Epoch [1/1], Batch [1179/3134], Loss: 0.01181261\n",
            "Epoch [1/1], Batch [1180/3134], Loss: 0.01185480\n",
            "Epoch [1/1], Batch [1181/3134], Loss: 0.01186918\n",
            "Epoch [1/1], Batch [1182/3134], Loss: 0.01180612\n",
            "Epoch [1/1], Batch [1183/3134], Loss: 0.01184814\n",
            "Epoch [1/1], Batch [1184/3134], Loss: 0.01182455\n",
            "Epoch [1/1], Batch [1185/3134], Loss: 0.01180652\n",
            "Epoch [1/1], Batch [1186/3134], Loss: 0.01183922\n",
            "Epoch [1/1], Batch [1187/3134], Loss: 0.01184953\n",
            "Epoch [1/1], Batch [1188/3134], Loss: 0.01182100\n",
            "Epoch [1/1], Batch [1189/3134], Loss: 0.01181747\n",
            "Epoch [1/1], Batch [1190/3134], Loss: 0.01181784\n",
            "Epoch [1/1], Batch [1191/3134], Loss: 0.01180102\n",
            "Epoch [1/1], Batch [1192/3134], Loss: 0.01180919\n",
            "Epoch [1/1], Batch [1193/3134], Loss: 0.01181854\n",
            "Epoch [1/1], Batch [1194/3134], Loss: 0.01182760\n",
            "Epoch [1/1], Batch [1195/3134], Loss: 0.01183053\n",
            "Epoch [1/1], Batch [1196/3134], Loss: 0.01185286\n",
            "Epoch [1/1], Batch [1197/3134], Loss: 0.01181515\n",
            "Epoch [1/1], Batch [1198/3134], Loss: 0.01183572\n",
            "Epoch [1/1], Batch [1199/3134], Loss: 0.01179781\n",
            "Epoch [1/1], Batch [1200/3134], Loss: 0.01183372\n",
            "Epoch [1/1], Batch [1201/3134], Loss: 0.01174465\n",
            "Epoch [1/1], Batch [1202/3134], Loss: 0.01184266\n",
            "Epoch [1/1], Batch [1203/3134], Loss: 0.01186688\n",
            "Epoch [1/1], Batch [1204/3134], Loss: 0.01178428\n",
            "Epoch [1/1], Batch [1205/3134], Loss: 0.01183029\n",
            "Epoch [1/1], Batch [1206/3134], Loss: 0.01185500\n",
            "Epoch [1/1], Batch [1207/3134], Loss: 0.01183903\n",
            "Epoch [1/1], Batch [1208/3134], Loss: 0.01179185\n",
            "Epoch [1/1], Batch [1209/3134], Loss: 0.01175845\n",
            "Epoch [1/1], Batch [1210/3134], Loss: 0.01183114\n",
            "Epoch [1/1], Batch [1211/3134], Loss: 0.01182923\n",
            "Epoch [1/1], Batch [1212/3134], Loss: 0.01183463\n",
            "Epoch [1/1], Batch [1213/3134], Loss: 0.01181585\n",
            "Epoch [1/1], Batch [1214/3134], Loss: 0.01180433\n",
            "Epoch [1/1], Batch [1215/3134], Loss: 0.01182408\n",
            "Epoch [1/1], Batch [1216/3134], Loss: 0.01182027\n",
            "Epoch [1/1], Batch [1217/3134], Loss: 0.01182111\n",
            "Epoch [1/1], Batch [1218/3134], Loss: 0.01180831\n",
            "Epoch [1/1], Batch [1219/3134], Loss: 0.01186149\n",
            "Epoch [1/1], Batch [1220/3134], Loss: 0.01188237\n",
            "Epoch [1/1], Batch [1221/3134], Loss: 0.01182510\n",
            "Epoch [1/1], Batch [1222/3134], Loss: 0.01182125\n",
            "Epoch [1/1], Batch [1223/3134], Loss: 0.01181386\n",
            "Epoch [1/1], Batch [1224/3134], Loss: 0.01179340\n",
            "Epoch [1/1], Batch [1225/3134], Loss: 0.01177461\n",
            "Epoch [1/1], Batch [1226/3134], Loss: 0.01187972\n",
            "Epoch [1/1], Batch [1227/3134], Loss: 0.01177789\n",
            "Epoch [1/1], Batch [1228/3134], Loss: 0.01179135\n",
            "Epoch [1/1], Batch [1229/3134], Loss: 0.01174479\n",
            "Epoch [1/1], Batch [1230/3134], Loss: 0.01184013\n",
            "Epoch [1/1], Batch [1231/3134], Loss: 0.01184851\n",
            "Epoch [1/1], Batch [1232/3134], Loss: 0.01183351\n",
            "Epoch [1/1], Batch [1233/3134], Loss: 0.01175051\n",
            "Epoch [1/1], Batch [1234/3134], Loss: 0.01185838\n",
            "Epoch [1/1], Batch [1235/3134], Loss: 0.01180188\n",
            "Epoch [1/1], Batch [1236/3134], Loss: 0.01177672\n",
            "Epoch [1/1], Batch [1237/3134], Loss: 0.01182750\n",
            "Epoch [1/1], Batch [1238/3134], Loss: 0.01180420\n",
            "Epoch [1/1], Batch [1239/3134], Loss: 0.01176177\n",
            "Epoch [1/1], Batch [1240/3134], Loss: 0.01184884\n",
            "Epoch [1/1], Batch [1241/3134], Loss: 0.01183501\n",
            "Epoch [1/1], Batch [1242/3134], Loss: 0.01186150\n",
            "Epoch [1/1], Batch [1243/3134], Loss: 0.01191522\n",
            "Epoch [1/1], Batch [1244/3134], Loss: 0.01181378\n",
            "Epoch [1/1], Batch [1245/3134], Loss: 0.01184273\n",
            "Epoch [1/1], Batch [1246/3134], Loss: 0.01174757\n",
            "Epoch [1/1], Batch [1247/3134], Loss: 0.01185942\n",
            "Epoch [1/1], Batch [1248/3134], Loss: 0.01182096\n",
            "Epoch [1/1], Batch [1249/3134], Loss: 0.01181913\n",
            "Epoch [1/1], Batch [1250/3134], Loss: 0.01183078\n",
            "Epoch [1/1], Batch [1251/3134], Loss: 0.01184716\n",
            "Epoch [1/1], Batch [1252/3134], Loss: 0.01180347\n",
            "Epoch [1/1], Batch [1253/3134], Loss: 0.01188578\n",
            "Epoch [1/1], Batch [1254/3134], Loss: 0.01183999\n",
            "Epoch [1/1], Batch [1255/3134], Loss: 0.01179228\n",
            "Epoch [1/1], Batch [1256/3134], Loss: 0.01178663\n",
            "Epoch [1/1], Batch [1257/3134], Loss: 0.01181851\n",
            "Epoch [1/1], Batch [1258/3134], Loss: 0.01180812\n",
            "Epoch [1/1], Batch [1259/3134], Loss: 0.01184572\n",
            "Epoch [1/1], Batch [1260/3134], Loss: 0.01185306\n",
            "Epoch [1/1], Batch [1261/3134], Loss: 0.01183132\n",
            "Epoch [1/1], Batch [1262/3134], Loss: 0.01180489\n",
            "Epoch [1/1], Batch [1263/3134], Loss: 0.01183367\n",
            "Epoch [1/1], Batch [1264/3134], Loss: 0.01181819\n",
            "Epoch [1/1], Batch [1265/3134], Loss: 0.01183155\n",
            "Epoch [1/1], Batch [1266/3134], Loss: 0.01177729\n",
            "Epoch [1/1], Batch [1267/3134], Loss: 0.01176790\n",
            "Epoch [1/1], Batch [1268/3134], Loss: 0.01181266\n",
            "Epoch [1/1], Batch [1269/3134], Loss: 0.01179180\n",
            "Epoch [1/1], Batch [1270/3134], Loss: 0.01187643\n",
            "Epoch [1/1], Batch [1271/3134], Loss: 0.01174895\n",
            "Epoch [1/1], Batch [1272/3134], Loss: 0.01182424\n",
            "Epoch [1/1], Batch [1273/3134], Loss: 0.01183017\n",
            "Epoch [1/1], Batch [1274/3134], Loss: 0.01175128\n",
            "Epoch [1/1], Batch [1275/3134], Loss: 0.01181731\n",
            "Epoch [1/1], Batch [1276/3134], Loss: 0.01177999\n",
            "Epoch [1/1], Batch [1277/3134], Loss: 0.01180955\n",
            "Epoch [1/1], Batch [1278/3134], Loss: 0.01184828\n",
            "Epoch [1/1], Batch [1279/3134], Loss: 0.01177922\n",
            "Epoch [1/1], Batch [1280/3134], Loss: 0.01182673\n",
            "Epoch [1/1], Batch [1281/3134], Loss: 0.01185320\n",
            "Epoch [1/1], Batch [1282/3134], Loss: 0.01180710\n",
            "Epoch [1/1], Batch [1283/3134], Loss: 0.01182353\n",
            "Epoch [1/1], Batch [1284/3134], Loss: 0.01174087\n",
            "Epoch [1/1], Batch [1285/3134], Loss: 0.01181827\n",
            "Epoch [1/1], Batch [1286/3134], Loss: 0.01187438\n",
            "Epoch [1/1], Batch [1287/3134], Loss: 0.01184012\n",
            "Epoch [1/1], Batch [1288/3134], Loss: 0.01174690\n",
            "Epoch [1/1], Batch [1289/3134], Loss: 0.01184470\n",
            "Epoch [1/1], Batch [1290/3134], Loss: 0.01183244\n",
            "Epoch [1/1], Batch [1291/3134], Loss: 0.01178121\n",
            "Epoch [1/1], Batch [1292/3134], Loss: 0.01179641\n",
            "Epoch [1/1], Batch [1293/3134], Loss: 0.01176342\n",
            "Epoch [1/1], Batch [1294/3134], Loss: 0.01179421\n",
            "Epoch [1/1], Batch [1295/3134], Loss: 0.01183698\n",
            "Epoch [1/1], Batch [1296/3134], Loss: 0.01181197\n",
            "Epoch [1/1], Batch [1297/3134], Loss: 0.01182846\n",
            "Epoch [1/1], Batch [1298/3134], Loss: 0.01185170\n",
            "Epoch [1/1], Batch [1299/3134], Loss: 0.01181162\n",
            "Epoch [1/1], Batch [1300/3134], Loss: 0.01186539\n",
            "Epoch [1/1], Batch [1301/3134], Loss: 0.01177175\n",
            "Epoch [1/1], Batch [1302/3134], Loss: 0.01179772\n",
            "Epoch [1/1], Batch [1303/3134], Loss: 0.01183491\n",
            "Epoch [1/1], Batch [1304/3134], Loss: 0.01183279\n",
            "Epoch [1/1], Batch [1305/3134], Loss: 0.01175298\n",
            "Epoch [1/1], Batch [1306/3134], Loss: 0.01186608\n",
            "Epoch [1/1], Batch [1307/3134], Loss: 0.01176590\n",
            "Epoch [1/1], Batch [1308/3134], Loss: 0.01181648\n",
            "Epoch [1/1], Batch [1309/3134], Loss: 0.01175206\n",
            "Epoch [1/1], Batch [1310/3134], Loss: 0.01182953\n",
            "Epoch [1/1], Batch [1311/3134], Loss: 0.01185655\n",
            "Epoch [1/1], Batch [1312/3134], Loss: 0.01182296\n",
            "Epoch [1/1], Batch [1313/3134], Loss: 0.01178908\n",
            "Epoch [1/1], Batch [1314/3134], Loss: 0.01182420\n",
            "Epoch [1/1], Batch [1315/3134], Loss: 0.01188465\n",
            "Epoch [1/1], Batch [1316/3134], Loss: 0.01174684\n",
            "Epoch [1/1], Batch [1317/3134], Loss: 0.01180125\n",
            "Epoch [1/1], Batch [1318/3134], Loss: 0.01179001\n",
            "Epoch [1/1], Batch [1319/3134], Loss: 0.01183949\n",
            "Epoch [1/1], Batch [1320/3134], Loss: 0.01178091\n",
            "Epoch [1/1], Batch [1321/3134], Loss: 0.01181366\n",
            "Epoch [1/1], Batch [1322/3134], Loss: 0.01182066\n",
            "Epoch [1/1], Batch [1323/3134], Loss: 0.01183871\n",
            "Epoch [1/1], Batch [1324/3134], Loss: 0.01176696\n",
            "Epoch [1/1], Batch [1325/3134], Loss: 0.01185392\n",
            "Epoch [1/1], Batch [1326/3134], Loss: 0.01179106\n",
            "Epoch [1/1], Batch [1327/3134], Loss: 0.01190440\n",
            "Epoch [1/1], Batch [1328/3134], Loss: 0.01170984\n",
            "Epoch [1/1], Batch [1329/3134], Loss: 0.01183367\n",
            "Epoch [1/1], Batch [1330/3134], Loss: 0.01183661\n",
            "Epoch [1/1], Batch [1331/3134], Loss: 0.01189005\n",
            "Epoch [1/1], Batch [1332/3134], Loss: 0.01182123\n",
            "Epoch [1/1], Batch [1333/3134], Loss: 0.01185825\n",
            "Epoch [1/1], Batch [1334/3134], Loss: 0.01191439\n",
            "Epoch [1/1], Batch [1335/3134], Loss: 0.01179455\n",
            "Epoch [1/1], Batch [1336/3134], Loss: 0.01181489\n",
            "Epoch [1/1], Batch [1337/3134], Loss: 0.01183170\n",
            "Epoch [1/1], Batch [1338/3134], Loss: 0.01175600\n",
            "Epoch [1/1], Batch [1339/3134], Loss: 0.01184398\n",
            "Epoch [1/1], Batch [1340/3134], Loss: 0.01184268\n",
            "Epoch [1/1], Batch [1341/3134], Loss: 0.01185189\n",
            "Epoch [1/1], Batch [1342/3134], Loss: 0.01184053\n",
            "Epoch [1/1], Batch [1343/3134], Loss: 0.01188837\n",
            "Epoch [1/1], Batch [1344/3134], Loss: 0.01183540\n",
            "Epoch [1/1], Batch [1345/3134], Loss: 0.01181712\n",
            "Epoch [1/1], Batch [1346/3134], Loss: 0.01180185\n",
            "Epoch [1/1], Batch [1347/3134], Loss: 0.01178709\n",
            "Epoch [1/1], Batch [1348/3134], Loss: 0.01177210\n",
            "Epoch [1/1], Batch [1349/3134], Loss: 0.01186731\n",
            "Epoch [1/1], Batch [1350/3134], Loss: 0.01185034\n",
            "Epoch [1/1], Batch [1351/3134], Loss: 0.01185071\n",
            "Epoch [1/1], Batch [1352/3134], Loss: 0.01182192\n",
            "Epoch [1/1], Batch [1353/3134], Loss: 0.01182985\n",
            "Epoch [1/1], Batch [1354/3134], Loss: 0.01181942\n",
            "Epoch [1/1], Batch [1355/3134], Loss: 0.01181785\n",
            "Epoch [1/1], Batch [1356/3134], Loss: 0.01177513\n",
            "Epoch [1/1], Batch [1357/3134], Loss: 0.01185118\n",
            "Epoch [1/1], Batch [1358/3134], Loss: 0.01184139\n",
            "Epoch [1/1], Batch [1359/3134], Loss: 0.01178417\n",
            "Epoch [1/1], Batch [1360/3134], Loss: 0.01176791\n",
            "Epoch [1/1], Batch [1361/3134], Loss: 0.01176690\n",
            "Epoch [1/1], Batch [1362/3134], Loss: 0.01182580\n",
            "Epoch [1/1], Batch [1363/3134], Loss: 0.01176639\n",
            "Epoch [1/1], Batch [1364/3134], Loss: 0.01182600\n",
            "Epoch [1/1], Batch [1365/3134], Loss: 0.01179024\n",
            "Epoch [1/1], Batch [1366/3134], Loss: 0.01183778\n",
            "Epoch [1/1], Batch [1367/3134], Loss: 0.01181079\n",
            "Epoch [1/1], Batch [1368/3134], Loss: 0.01180846\n",
            "Epoch [1/1], Batch [1369/3134], Loss: 0.01185721\n",
            "Epoch [1/1], Batch [1370/3134], Loss: 0.01178490\n",
            "Epoch [1/1], Batch [1371/3134], Loss: 0.01181159\n",
            "Epoch [1/1], Batch [1372/3134], Loss: 0.01182886\n",
            "Epoch [1/1], Batch [1373/3134], Loss: 0.01185533\n",
            "Epoch [1/1], Batch [1374/3134], Loss: 0.01182687\n",
            "Epoch [1/1], Batch [1375/3134], Loss: 0.01182378\n",
            "Epoch [1/1], Batch [1376/3134], Loss: 0.01188587\n",
            "Epoch [1/1], Batch [1377/3134], Loss: 0.01189587\n",
            "Epoch [1/1], Batch [1378/3134], Loss: 0.01183507\n",
            "Epoch [1/1], Batch [1379/3134], Loss: 0.01181717\n",
            "Epoch [1/1], Batch [1380/3134], Loss: 0.01183087\n",
            "Epoch [1/1], Batch [1381/3134], Loss: 0.01176669\n",
            "Epoch [1/1], Batch [1382/3134], Loss: 0.01178098\n",
            "Epoch [1/1], Batch [1383/3134], Loss: 0.01178458\n",
            "Epoch [1/1], Batch [1384/3134], Loss: 0.01178708\n",
            "Epoch [1/1], Batch [1385/3134], Loss: 0.01182647\n",
            "Epoch [1/1], Batch [1386/3134], Loss: 0.01184662\n",
            "Epoch [1/1], Batch [1387/3134], Loss: 0.01183293\n",
            "Epoch [1/1], Batch [1388/3134], Loss: 0.01181288\n",
            "Epoch [1/1], Batch [1389/3134], Loss: 0.01182451\n",
            "Epoch [1/1], Batch [1390/3134], Loss: 0.01180117\n",
            "Epoch [1/1], Batch [1391/3134], Loss: 0.01185029\n",
            "Epoch [1/1], Batch [1392/3134], Loss: 0.01183697\n",
            "Epoch [1/1], Batch [1393/3134], Loss: 0.01181690\n",
            "Epoch [1/1], Batch [1394/3134], Loss: 0.01183402\n",
            "Epoch [1/1], Batch [1395/3134], Loss: 0.01180573\n",
            "Epoch [1/1], Batch [1396/3134], Loss: 0.01185090\n",
            "Epoch [1/1], Batch [1397/3134], Loss: 0.01175017\n",
            "Epoch [1/1], Batch [1398/3134], Loss: 0.01179262\n",
            "Epoch [1/1], Batch [1399/3134], Loss: 0.01180935\n",
            "Epoch [1/1], Batch [1400/3134], Loss: 0.01185247\n",
            "Epoch [1/1], Batch [1401/3134], Loss: 0.01187076\n",
            "Epoch [1/1], Batch [1402/3134], Loss: 0.01185580\n",
            "Epoch [1/1], Batch [1403/3134], Loss: 0.01182258\n",
            "Epoch [1/1], Batch [1404/3134], Loss: 0.01177679\n",
            "Epoch [1/1], Batch [1405/3134], Loss: 0.01178891\n",
            "Epoch [1/1], Batch [1406/3134], Loss: 0.01177061\n",
            "Epoch [1/1], Batch [1407/3134], Loss: 0.01181656\n",
            "Epoch [1/1], Batch [1408/3134], Loss: 0.01179169\n",
            "Epoch [1/1], Batch [1409/3134], Loss: 0.01183346\n",
            "Epoch [1/1], Batch [1410/3134], Loss: 0.01176614\n",
            "Epoch [1/1], Batch [1411/3134], Loss: 0.01186465\n",
            "Epoch [1/1], Batch [1412/3134], Loss: 0.01186351\n",
            "Epoch [1/1], Batch [1413/3134], Loss: 0.01183272\n",
            "Epoch [1/1], Batch [1414/3134], Loss: 0.01182027\n",
            "Epoch [1/1], Batch [1415/3134], Loss: 0.01173639\n",
            "Epoch [1/1], Batch [1416/3134], Loss: 0.01179376\n",
            "Epoch [1/1], Batch [1417/3134], Loss: 0.01183589\n",
            "Epoch [1/1], Batch [1418/3134], Loss: 0.01182790\n",
            "Epoch [1/1], Batch [1419/3134], Loss: 0.01184881\n",
            "Epoch [1/1], Batch [1420/3134], Loss: 0.01178626\n",
            "Epoch [1/1], Batch [1421/3134], Loss: 0.01179892\n",
            "Epoch [1/1], Batch [1422/3134], Loss: 0.01188841\n",
            "Epoch [1/1], Batch [1423/3134], Loss: 0.01180443\n",
            "Epoch [1/1], Batch [1424/3134], Loss: 0.01182344\n",
            "Epoch [1/1], Batch [1425/3134], Loss: 0.01174029\n",
            "Epoch [1/1], Batch [1426/3134], Loss: 0.01180546\n",
            "Epoch [1/1], Batch [1427/3134], Loss: 0.01183193\n",
            "Epoch [1/1], Batch [1428/3134], Loss: 0.01182748\n",
            "Epoch [1/1], Batch [1429/3134], Loss: 0.01189785\n",
            "Epoch [1/1], Batch [1430/3134], Loss: 0.01181771\n",
            "Epoch [1/1], Batch [1431/3134], Loss: 0.01181623\n",
            "Epoch [1/1], Batch [1432/3134], Loss: 0.01178481\n",
            "Epoch [1/1], Batch [1433/3134], Loss: 0.01180549\n",
            "Epoch [1/1], Batch [1434/3134], Loss: 0.01179030\n",
            "Epoch [1/1], Batch [1435/3134], Loss: 0.01181405\n",
            "Epoch [1/1], Batch [1436/3134], Loss: 0.01179866\n",
            "Epoch [1/1], Batch [1437/3134], Loss: 0.01181659\n",
            "Epoch [1/1], Batch [1438/3134], Loss: 0.01180708\n",
            "Epoch [1/1], Batch [1439/3134], Loss: 0.01178441\n",
            "Epoch [1/1], Batch [1440/3134], Loss: 0.01189841\n",
            "Epoch [1/1], Batch [1441/3134], Loss: 0.01185658\n",
            "Epoch [1/1], Batch [1442/3134], Loss: 0.01179886\n",
            "Epoch [1/1], Batch [1443/3134], Loss: 0.01177811\n",
            "Epoch [1/1], Batch [1444/3134], Loss: 0.01183257\n",
            "Epoch [1/1], Batch [1445/3134], Loss: 0.01181298\n",
            "Epoch [1/1], Batch [1446/3134], Loss: 0.01179737\n",
            "Epoch [1/1], Batch [1447/3134], Loss: 0.01176699\n",
            "Epoch [1/1], Batch [1448/3134], Loss: 0.01181675\n",
            "Epoch [1/1], Batch [1449/3134], Loss: 0.01182339\n",
            "Epoch [1/1], Batch [1450/3134], Loss: 0.01181529\n",
            "Epoch [1/1], Batch [1451/3134], Loss: 0.01178729\n",
            "Epoch [1/1], Batch [1452/3134], Loss: 0.01174770\n",
            "Epoch [1/1], Batch [1453/3134], Loss: 0.01179046\n",
            "Epoch [1/1], Batch [1454/3134], Loss: 0.01177059\n",
            "Epoch [1/1], Batch [1455/3134], Loss: 0.01182942\n",
            "Epoch [1/1], Batch [1456/3134], Loss: 0.01176662\n",
            "Epoch [1/1], Batch [1457/3134], Loss: 0.01177348\n",
            "Epoch [1/1], Batch [1458/3134], Loss: 0.01180032\n",
            "Epoch [1/1], Batch [1459/3134], Loss: 0.01183432\n",
            "Epoch [1/1], Batch [1460/3134], Loss: 0.01180965\n",
            "Epoch [1/1], Batch [1461/3134], Loss: 0.01176189\n",
            "Epoch [1/1], Batch [1462/3134], Loss: 0.01182148\n",
            "Epoch [1/1], Batch [1463/3134], Loss: 0.01180738\n",
            "Epoch [1/1], Batch [1464/3134], Loss: 0.01178683\n",
            "Epoch [1/1], Batch [1465/3134], Loss: 0.01178196\n",
            "Epoch [1/1], Batch [1466/3134], Loss: 0.01188865\n",
            "Epoch [1/1], Batch [1467/3134], Loss: 0.01181176\n",
            "Epoch [1/1], Batch [1468/3134], Loss: 0.01183790\n",
            "Epoch [1/1], Batch [1469/3134], Loss: 0.01179644\n",
            "Epoch [1/1], Batch [1470/3134], Loss: 0.01181397\n",
            "Epoch [1/1], Batch [1471/3134], Loss: 0.01182117\n",
            "Epoch [1/1], Batch [1472/3134], Loss: 0.01181378\n",
            "Epoch [1/1], Batch [1473/3134], Loss: 0.01182394\n",
            "Epoch [1/1], Batch [1474/3134], Loss: 0.01177663\n",
            "Epoch [1/1], Batch [1475/3134], Loss: 0.01177355\n",
            "Epoch [1/1], Batch [1476/3134], Loss: 0.01182853\n",
            "Epoch [1/1], Batch [1477/3134], Loss: 0.01182731\n",
            "Epoch [1/1], Batch [1478/3134], Loss: 0.01181297\n",
            "Epoch [1/1], Batch [1479/3134], Loss: 0.01182205\n",
            "Epoch [1/1], Batch [1480/3134], Loss: 0.01174215\n",
            "Epoch [1/1], Batch [1481/3134], Loss: 0.01187204\n",
            "Epoch [1/1], Batch [1482/3134], Loss: 0.01187444\n",
            "Epoch [1/1], Batch [1483/3134], Loss: 0.01180940\n",
            "Epoch [1/1], Batch [1484/3134], Loss: 0.01177604\n",
            "Epoch [1/1], Batch [1485/3134], Loss: 0.01184983\n",
            "Epoch [1/1], Batch [1486/3134], Loss: 0.01184142\n",
            "Epoch [1/1], Batch [1487/3134], Loss: 0.01182509\n",
            "Epoch [1/1], Batch [1488/3134], Loss: 0.01180540\n",
            "Epoch [1/1], Batch [1489/3134], Loss: 0.01180208\n",
            "Epoch [1/1], Batch [1490/3134], Loss: 0.01179749\n",
            "Epoch [1/1], Batch [1491/3134], Loss: 0.01189479\n",
            "Epoch [1/1], Batch [1492/3134], Loss: 0.01187726\n",
            "Epoch [1/1], Batch [1493/3134], Loss: 0.01185952\n",
            "Epoch [1/1], Batch [1494/3134], Loss: 0.01184996\n",
            "Epoch [1/1], Batch [1495/3134], Loss: 0.01178420\n",
            "Epoch [1/1], Batch [1496/3134], Loss: 0.01179989\n",
            "Epoch [1/1], Batch [1497/3134], Loss: 0.01179312\n",
            "Epoch [1/1], Batch [1498/3134], Loss: 0.01176527\n",
            "Epoch [1/1], Batch [1499/3134], Loss: 0.01179909\n",
            "Epoch [1/1], Batch [1500/3134], Loss: 0.01180282\n",
            "Epoch [1/1], Batch [1501/3134], Loss: 0.01173895\n",
            "Epoch [1/1], Batch [1502/3134], Loss: 0.01177393\n",
            "Epoch [1/1], Batch [1503/3134], Loss: 0.01179997\n",
            "Epoch [1/1], Batch [1504/3134], Loss: 0.01177868\n",
            "Epoch [1/1], Batch [1505/3134], Loss: 0.01176136\n",
            "Epoch [1/1], Batch [1506/3134], Loss: 0.01182637\n",
            "Epoch [1/1], Batch [1507/3134], Loss: 0.01179654\n",
            "Epoch [1/1], Batch [1508/3134], Loss: 0.01182812\n",
            "Epoch [1/1], Batch [1509/3134], Loss: 0.01179854\n",
            "Epoch [1/1], Batch [1510/3134], Loss: 0.01184047\n",
            "Epoch [1/1], Batch [1511/3134], Loss: 0.01178154\n",
            "Epoch [1/1], Batch [1512/3134], Loss: 0.01178645\n",
            "Epoch [1/1], Batch [1513/3134], Loss: 0.01178842\n",
            "Epoch [1/1], Batch [1514/3134], Loss: 0.01177542\n",
            "Epoch [1/1], Batch [1515/3134], Loss: 0.01185666\n",
            "Epoch [1/1], Batch [1516/3134], Loss: 0.01180804\n",
            "Epoch [1/1], Batch [1517/3134], Loss: 0.01179983\n",
            "Epoch [1/1], Batch [1518/3134], Loss: 0.01180662\n",
            "Epoch [1/1], Batch [1519/3134], Loss: 0.01183281\n",
            "Epoch [1/1], Batch [1520/3134], Loss: 0.01175871\n",
            "Epoch [1/1], Batch [1521/3134], Loss: 0.01177951\n",
            "Epoch [1/1], Batch [1522/3134], Loss: 0.01177052\n",
            "Epoch [1/1], Batch [1523/3134], Loss: 0.01182889\n",
            "Epoch [1/1], Batch [1524/3134], Loss: 0.01182220\n",
            "Epoch [1/1], Batch [1525/3134], Loss: 0.01173154\n",
            "Epoch [1/1], Batch [1526/3134], Loss: 0.01179407\n",
            "Epoch [1/1], Batch [1527/3134], Loss: 0.01179656\n",
            "Epoch [1/1], Batch [1528/3134], Loss: 0.01183529\n",
            "Epoch [1/1], Batch [1529/3134], Loss: 0.01178738\n",
            "Epoch [1/1], Batch [1530/3134], Loss: 0.01183939\n",
            "Epoch [1/1], Batch [1531/3134], Loss: 0.01178898\n",
            "Epoch [1/1], Batch [1532/3134], Loss: 0.01177655\n",
            "Epoch [1/1], Batch [1533/3134], Loss: 0.01183534\n",
            "Epoch [1/1], Batch [1534/3134], Loss: 0.01175516\n",
            "Epoch [1/1], Batch [1535/3134], Loss: 0.01175226\n",
            "Epoch [1/1], Batch [1536/3134], Loss: 0.01184035\n",
            "Epoch [1/1], Batch [1537/3134], Loss: 0.01180979\n",
            "Epoch [1/1], Batch [1538/3134], Loss: 0.01178557\n",
            "Epoch [1/1], Batch [1539/3134], Loss: 0.01175799\n",
            "Epoch [1/1], Batch [1540/3134], Loss: 0.01180434\n",
            "Epoch [1/1], Batch [1541/3134], Loss: 0.01179425\n",
            "Epoch [1/1], Batch [1542/3134], Loss: 0.01178786\n",
            "Epoch [1/1], Batch [1543/3134], Loss: 0.01182616\n",
            "Epoch [1/1], Batch [1544/3134], Loss: 0.01178072\n",
            "Epoch [1/1], Batch [1545/3134], Loss: 0.01175316\n",
            "Epoch [1/1], Batch [1546/3134], Loss: 0.01178818\n",
            "Epoch [1/1], Batch [1547/3134], Loss: 0.01176109\n",
            "Epoch [1/1], Batch [1548/3134], Loss: 0.01174370\n",
            "Epoch [1/1], Batch [1549/3134], Loss: 0.01179446\n",
            "Epoch [1/1], Batch [1550/3134], Loss: 0.01184088\n",
            "Epoch [1/1], Batch [1551/3134], Loss: 0.01170675\n",
            "Epoch [1/1], Batch [1552/3134], Loss: 0.01176619\n",
            "Epoch [1/1], Batch [1553/3134], Loss: 0.01178492\n",
            "Epoch [1/1], Batch [1554/3134], Loss: 0.01178295\n",
            "Epoch [1/1], Batch [1555/3134], Loss: 0.01180625\n",
            "Epoch [1/1], Batch [1556/3134], Loss: 0.01177324\n",
            "Epoch [1/1], Batch [1557/3134], Loss: 0.01181083\n",
            "Epoch [1/1], Batch [1558/3134], Loss: 0.01184432\n",
            "Epoch [1/1], Batch [1559/3134], Loss: 0.01179520\n",
            "Epoch [1/1], Batch [1560/3134], Loss: 0.01176785\n",
            "Epoch [1/1], Batch [1561/3134], Loss: 0.01175472\n",
            "Epoch [1/1], Batch [1562/3134], Loss: 0.01179454\n",
            "Epoch [1/1], Batch [1563/3134], Loss: 0.01180098\n",
            "Epoch [1/1], Batch [1564/3134], Loss: 0.01182040\n",
            "Epoch [1/1], Batch [1565/3134], Loss: 0.01179660\n",
            "Epoch [1/1], Batch [1566/3134], Loss: 0.01185215\n",
            "Epoch [1/1], Batch [1567/3134], Loss: 0.01179106\n",
            "Epoch [1/1], Batch [1568/3134], Loss: 0.01185152\n",
            "Epoch [1/1], Batch [1569/3134], Loss: 0.01182729\n",
            "Epoch [1/1], Batch [1570/3134], Loss: 0.01178397\n",
            "Epoch [1/1], Batch [1571/3134], Loss: 0.01175072\n",
            "Epoch [1/1], Batch [1572/3134], Loss: 0.01176772\n",
            "Epoch [1/1], Batch [1573/3134], Loss: 0.01177347\n",
            "Epoch [1/1], Batch [1574/3134], Loss: 0.01185575\n",
            "Epoch [1/1], Batch [1575/3134], Loss: 0.01170706\n",
            "Epoch [1/1], Batch [1576/3134], Loss: 0.01186769\n",
            "Epoch [1/1], Batch [1577/3134], Loss: 0.01180164\n",
            "Epoch [1/1], Batch [1578/3134], Loss: 0.01179373\n",
            "Epoch [1/1], Batch [1579/3134], Loss: 0.01180114\n",
            "Epoch [1/1], Batch [1580/3134], Loss: 0.01179690\n",
            "Epoch [1/1], Batch [1581/3134], Loss: 0.01183879\n",
            "Epoch [1/1], Batch [1582/3134], Loss: 0.01179246\n",
            "Epoch [1/1], Batch [1583/3134], Loss: 0.01178508\n",
            "Epoch [1/1], Batch [1584/3134], Loss: 0.01177071\n",
            "Epoch [1/1], Batch [1585/3134], Loss: 0.01183887\n",
            "Epoch [1/1], Batch [1586/3134], Loss: 0.01180238\n",
            "Epoch [1/1], Batch [1587/3134], Loss: 0.01188136\n",
            "Epoch [1/1], Batch [1588/3134], Loss: 0.01181259\n",
            "Epoch [1/1], Batch [1589/3134], Loss: 0.01181659\n",
            "Epoch [1/1], Batch [1590/3134], Loss: 0.01178056\n",
            "Epoch [1/1], Batch [1591/3134], Loss: 0.01179491\n",
            "Epoch [1/1], Batch [1592/3134], Loss: 0.01180956\n",
            "Epoch [1/1], Batch [1593/3134], Loss: 0.01187312\n",
            "Epoch [1/1], Batch [1594/3134], Loss: 0.01175989\n",
            "Epoch [1/1], Batch [1595/3134], Loss: 0.01181252\n",
            "Epoch [1/1], Batch [1596/3134], Loss: 0.01180857\n",
            "Epoch [1/1], Batch [1597/3134], Loss: 0.01171422\n",
            "Epoch [1/1], Batch [1598/3134], Loss: 0.01172010\n",
            "Epoch [1/1], Batch [1599/3134], Loss: 0.01181937\n",
            "Epoch [1/1], Batch [1600/3134], Loss: 0.01181889\n",
            "Epoch [1/1], Batch [1601/3134], Loss: 0.01181767\n",
            "Epoch [1/1], Batch [1602/3134], Loss: 0.01173778\n",
            "Epoch [1/1], Batch [1603/3134], Loss: 0.01178803\n",
            "Epoch [1/1], Batch [1604/3134], Loss: 0.01182114\n",
            "Epoch [1/1], Batch [1605/3134], Loss: 0.01181991\n",
            "Epoch [1/1], Batch [1606/3134], Loss: 0.01181262\n",
            "Epoch [1/1], Batch [1607/3134], Loss: 0.01184353\n",
            "Epoch [1/1], Batch [1608/3134], Loss: 0.01177153\n",
            "Epoch [1/1], Batch [1609/3134], Loss: 0.01181242\n",
            "Epoch [1/1], Batch [1610/3134], Loss: 0.01180661\n",
            "Epoch [1/1], Batch [1611/3134], Loss: 0.01185204\n",
            "Epoch [1/1], Batch [1612/3134], Loss: 0.01188198\n",
            "Epoch [1/1], Batch [1613/3134], Loss: 0.01185125\n",
            "Epoch [1/1], Batch [1614/3134], Loss: 0.01173604\n",
            "Epoch [1/1], Batch [1615/3134], Loss: 0.01181554\n",
            "Epoch [1/1], Batch [1616/3134], Loss: 0.01184842\n",
            "Epoch [1/1], Batch [1617/3134], Loss: 0.01177082\n",
            "Epoch [1/1], Batch [1618/3134], Loss: 0.01183764\n",
            "Epoch [1/1], Batch [1619/3134], Loss: 0.01180849\n",
            "Epoch [1/1], Batch [1620/3134], Loss: 0.01175533\n",
            "Epoch [1/1], Batch [1621/3134], Loss: 0.01184398\n",
            "Epoch [1/1], Batch [1622/3134], Loss: 0.01182881\n",
            "Epoch [1/1], Batch [1623/3134], Loss: 0.01181412\n",
            "Epoch [1/1], Batch [1624/3134], Loss: 0.01186574\n",
            "Epoch [1/1], Batch [1625/3134], Loss: 0.01187185\n",
            "Epoch [1/1], Batch [1626/3134], Loss: 0.01181545\n",
            "Epoch [1/1], Batch [1627/3134], Loss: 0.01182280\n",
            "Epoch [1/1], Batch [1628/3134], Loss: 0.01177902\n",
            "Epoch [1/1], Batch [1629/3134], Loss: 0.01175743\n",
            "Epoch [1/1], Batch [1630/3134], Loss: 0.01178928\n",
            "Epoch [1/1], Batch [1631/3134], Loss: 0.01176623\n",
            "Epoch [1/1], Batch [1632/3134], Loss: 0.01179143\n",
            "Epoch [1/1], Batch [1633/3134], Loss: 0.01175488\n",
            "Epoch [1/1], Batch [1634/3134], Loss: 0.01184362\n",
            "Epoch [1/1], Batch [1635/3134], Loss: 0.01184996\n",
            "Epoch [1/1], Batch [1636/3134], Loss: 0.01180361\n",
            "Epoch [1/1], Batch [1637/3134], Loss: 0.01182819\n",
            "Epoch [1/1], Batch [1638/3134], Loss: 0.01185608\n",
            "Epoch [1/1], Batch [1639/3134], Loss: 0.01182068\n",
            "Epoch [1/1], Batch [1640/3134], Loss: 0.01176159\n",
            "Epoch [1/1], Batch [1641/3134], Loss: 0.01181240\n",
            "Epoch [1/1], Batch [1642/3134], Loss: 0.01176722\n",
            "Epoch [1/1], Batch [1643/3134], Loss: 0.01186112\n",
            "Epoch [1/1], Batch [1644/3134], Loss: 0.01181874\n",
            "Epoch [1/1], Batch [1645/3134], Loss: 0.01179064\n",
            "Epoch [1/1], Batch [1646/3134], Loss: 0.01177962\n",
            "Epoch [1/1], Batch [1647/3134], Loss: 0.01178960\n",
            "Epoch [1/1], Batch [1648/3134], Loss: 0.01181078\n",
            "Epoch [1/1], Batch [1649/3134], Loss: 0.01176790\n",
            "Epoch [1/1], Batch [1650/3134], Loss: 0.01179583\n",
            "Epoch [1/1], Batch [1651/3134], Loss: 0.01182846\n",
            "Epoch [1/1], Batch [1652/3134], Loss: 0.01179150\n",
            "Epoch [1/1], Batch [1653/3134], Loss: 0.01180603\n",
            "Epoch [1/1], Batch [1654/3134], Loss: 0.01178855\n",
            "Epoch [1/1], Batch [1655/3134], Loss: 0.01179396\n",
            "Epoch [1/1], Batch [1656/3134], Loss: 0.01174695\n",
            "Epoch [1/1], Batch [1657/3134], Loss: 0.01177409\n",
            "Epoch [1/1], Batch [1658/3134], Loss: 0.01185868\n",
            "Epoch [1/1], Batch [1659/3134], Loss: 0.01181036\n",
            "Epoch [1/1], Batch [1660/3134], Loss: 0.01184078\n",
            "Epoch [1/1], Batch [1661/3134], Loss: 0.01179241\n",
            "Epoch [1/1], Batch [1662/3134], Loss: 0.01184390\n",
            "Epoch [1/1], Batch [1663/3134], Loss: 0.01171144\n",
            "Epoch [1/1], Batch [1664/3134], Loss: 0.01178436\n",
            "Epoch [1/1], Batch [1665/3134], Loss: 0.01178662\n",
            "Epoch [1/1], Batch [1666/3134], Loss: 0.01179672\n",
            "Epoch [1/1], Batch [1667/3134], Loss: 0.01178166\n",
            "Epoch [1/1], Batch [1668/3134], Loss: 0.01178274\n",
            "Epoch [1/1], Batch [1669/3134], Loss: 0.01182619\n",
            "Epoch [1/1], Batch [1670/3134], Loss: 0.01174887\n",
            "Epoch [1/1], Batch [1671/3134], Loss: 0.01184315\n",
            "Epoch [1/1], Batch [1672/3134], Loss: 0.01180543\n",
            "Epoch [1/1], Batch [1673/3134], Loss: 0.01180849\n",
            "Epoch [1/1], Batch [1674/3134], Loss: 0.01180647\n",
            "Epoch [1/1], Batch [1675/3134], Loss: 0.01182458\n",
            "Epoch [1/1], Batch [1676/3134], Loss: 0.01182121\n",
            "Epoch [1/1], Batch [1677/3134], Loss: 0.01180528\n",
            "Epoch [1/1], Batch [1678/3134], Loss: 0.01179031\n",
            "Epoch [1/1], Batch [1679/3134], Loss: 0.01176727\n",
            "Epoch [1/1], Batch [1680/3134], Loss: 0.01181136\n",
            "Epoch [1/1], Batch [1681/3134], Loss: 0.01180820\n",
            "Epoch [1/1], Batch [1682/3134], Loss: 0.01182519\n",
            "Epoch [1/1], Batch [1683/3134], Loss: 0.01175539\n",
            "Epoch [1/1], Batch [1684/3134], Loss: 0.01180985\n",
            "Epoch [1/1], Batch [1685/3134], Loss: 0.01185471\n",
            "Epoch [1/1], Batch [1686/3134], Loss: 0.01180195\n",
            "Epoch [1/1], Batch [1687/3134], Loss: 0.01180529\n",
            "Epoch [1/1], Batch [1688/3134], Loss: 0.01177691\n",
            "Epoch [1/1], Batch [1689/3134], Loss: 0.01182083\n",
            "Epoch [1/1], Batch [1690/3134], Loss: 0.01177772\n",
            "Epoch [1/1], Batch [1691/3134], Loss: 0.01174701\n",
            "Epoch [1/1], Batch [1692/3134], Loss: 0.01182639\n",
            "Epoch [1/1], Batch [1693/3134], Loss: 0.01179002\n",
            "Epoch [1/1], Batch [1694/3134], Loss: 0.01173256\n",
            "Epoch [1/1], Batch [1695/3134], Loss: 0.01176110\n",
            "Epoch [1/1], Batch [1696/3134], Loss: 0.01177997\n",
            "Epoch [1/1], Batch [1697/3134], Loss: 0.01187852\n",
            "Epoch [1/1], Batch [1698/3134], Loss: 0.01180460\n",
            "Epoch [1/1], Batch [1699/3134], Loss: 0.01179961\n",
            "Epoch [1/1], Batch [1700/3134], Loss: 0.01182334\n",
            "Epoch [1/1], Batch [1701/3134], Loss: 0.01187045\n",
            "Epoch [1/1], Batch [1702/3134], Loss: 0.01186171\n",
            "Epoch [1/1], Batch [1703/3134], Loss: 0.01177612\n",
            "Epoch [1/1], Batch [1704/3134], Loss: 0.01179286\n",
            "Epoch [1/1], Batch [1705/3134], Loss: 0.01183327\n",
            "Epoch [1/1], Batch [1706/3134], Loss: 0.01179141\n",
            "Epoch [1/1], Batch [1707/3134], Loss: 0.01175003\n",
            "Epoch [1/1], Batch [1708/3134], Loss: 0.01176953\n",
            "Epoch [1/1], Batch [1709/3134], Loss: 0.01179959\n",
            "Epoch [1/1], Batch [1710/3134], Loss: 0.01178660\n",
            "Epoch [1/1], Batch [1711/3134], Loss: 0.01175925\n",
            "Epoch [1/1], Batch [1712/3134], Loss: 0.01185200\n",
            "Epoch [1/1], Batch [1713/3134], Loss: 0.01177727\n",
            "Epoch [1/1], Batch [1714/3134], Loss: 0.01185857\n",
            "Epoch [1/1], Batch [1715/3134], Loss: 0.01183597\n",
            "Epoch [1/1], Batch [1716/3134], Loss: 0.01178313\n",
            "Epoch [1/1], Batch [1717/3134], Loss: 0.01180832\n",
            "Epoch [1/1], Batch [1718/3134], Loss: 0.01175722\n",
            "Epoch [1/1], Batch [1719/3134], Loss: 0.01179889\n",
            "Epoch [1/1], Batch [1720/3134], Loss: 0.01179571\n",
            "Epoch [1/1], Batch [1721/3134], Loss: 0.01179464\n",
            "Epoch [1/1], Batch [1722/3134], Loss: 0.01176404\n",
            "Epoch [1/1], Batch [1723/3134], Loss: 0.01180896\n",
            "Epoch [1/1], Batch [1724/3134], Loss: 0.01175610\n",
            "Epoch [1/1], Batch [1725/3134], Loss: 0.01178881\n",
            "Epoch [1/1], Batch [1726/3134], Loss: 0.01180457\n",
            "Epoch [1/1], Batch [1727/3134], Loss: 0.01186828\n",
            "Epoch [1/1], Batch [1728/3134], Loss: 0.01180433\n",
            "Epoch [1/1], Batch [1729/3134], Loss: 0.01182122\n",
            "Epoch [1/1], Batch [1730/3134], Loss: 0.01169006\n",
            "Epoch [1/1], Batch [1731/3134], Loss: 0.01179181\n",
            "Epoch [1/1], Batch [1732/3134], Loss: 0.01177138\n",
            "Epoch [1/1], Batch [1733/3134], Loss: 0.01176205\n",
            "Epoch [1/1], Batch [1734/3134], Loss: 0.01183199\n",
            "Epoch [1/1], Batch [1735/3134], Loss: 0.01181388\n",
            "Epoch [1/1], Batch [1736/3134], Loss: 0.01179801\n",
            "Epoch [1/1], Batch [1737/3134], Loss: 0.01182967\n",
            "Epoch [1/1], Batch [1738/3134], Loss: 0.01176645\n",
            "Epoch [1/1], Batch [1739/3134], Loss: 0.01187773\n",
            "Epoch [1/1], Batch [1740/3134], Loss: 0.01181449\n",
            "Epoch [1/1], Batch [1741/3134], Loss: 0.01182047\n",
            "Epoch [1/1], Batch [1742/3134], Loss: 0.01178702\n",
            "Epoch [1/1], Batch [1743/3134], Loss: 0.01181220\n",
            "Epoch [1/1], Batch [1744/3134], Loss: 0.01177236\n",
            "Epoch [1/1], Batch [1745/3134], Loss: 0.01176072\n",
            "Epoch [1/1], Batch [1746/3134], Loss: 0.01182437\n",
            "Epoch [1/1], Batch [1747/3134], Loss: 0.01177938\n",
            "Epoch [1/1], Batch [1748/3134], Loss: 0.01187617\n",
            "Epoch [1/1], Batch [1749/3134], Loss: 0.01178127\n",
            "Epoch [1/1], Batch [1750/3134], Loss: 0.01182603\n",
            "Epoch [1/1], Batch [1751/3134], Loss: 0.01180805\n",
            "Epoch [1/1], Batch [1752/3134], Loss: 0.01177924\n",
            "Epoch [1/1], Batch [1753/3134], Loss: 0.01179304\n",
            "Epoch [1/1], Batch [1754/3134], Loss: 0.01179334\n",
            "Epoch [1/1], Batch [1755/3134], Loss: 0.01179089\n",
            "Epoch [1/1], Batch [1756/3134], Loss: 0.01176327\n",
            "Epoch [1/1], Batch [1757/3134], Loss: 0.01176710\n",
            "Epoch [1/1], Batch [1758/3134], Loss: 0.01180181\n",
            "Epoch [1/1], Batch [1759/3134], Loss: 0.01182638\n",
            "Epoch [1/1], Batch [1760/3134], Loss: 0.01183052\n",
            "Epoch [1/1], Batch [1761/3134], Loss: 0.01179599\n",
            "Epoch [1/1], Batch [1762/3134], Loss: 0.01178714\n",
            "Epoch [1/1], Batch [1763/3134], Loss: 0.01180585\n",
            "Epoch [1/1], Batch [1764/3134], Loss: 0.01176089\n",
            "Epoch [1/1], Batch [1765/3134], Loss: 0.01179037\n",
            "Epoch [1/1], Batch [1766/3134], Loss: 0.01182002\n",
            "Epoch [1/1], Batch [1767/3134], Loss: 0.01175526\n",
            "Epoch [1/1], Batch [1768/3134], Loss: 0.01181646\n",
            "Epoch [1/1], Batch [1769/3134], Loss: 0.01178788\n",
            "Epoch [1/1], Batch [1770/3134], Loss: 0.01176436\n",
            "Epoch [1/1], Batch [1771/3134], Loss: 0.01182626\n",
            "Epoch [1/1], Batch [1772/3134], Loss: 0.01176747\n",
            "Epoch [1/1], Batch [1773/3134], Loss: 0.01178251\n",
            "Epoch [1/1], Batch [1774/3134], Loss: 0.01176686\n",
            "Epoch [1/1], Batch [1775/3134], Loss: 0.01176565\n",
            "Epoch [1/1], Batch [1776/3134], Loss: 0.01185435\n",
            "Epoch [1/1], Batch [1777/3134], Loss: 0.01184404\n",
            "Epoch [1/1], Batch [1778/3134], Loss: 0.01180450\n",
            "Epoch [1/1], Batch [1779/3134], Loss: 0.01176576\n",
            "Epoch [1/1], Batch [1780/3134], Loss: 0.01175834\n",
            "Epoch [1/1], Batch [1781/3134], Loss: 0.01175563\n",
            "Epoch [1/1], Batch [1782/3134], Loss: 0.01175577\n",
            "Epoch [1/1], Batch [1783/3134], Loss: 0.01189951\n",
            "Epoch [1/1], Batch [1784/3134], Loss: 0.01181444\n",
            "Epoch [1/1], Batch [1785/3134], Loss: 0.01181622\n",
            "Epoch [1/1], Batch [1786/3134], Loss: 0.01176427\n",
            "Epoch [1/1], Batch [1787/3134], Loss: 0.01179274\n",
            "Epoch [1/1], Batch [1788/3134], Loss: 0.01188495\n",
            "Epoch [1/1], Batch [1789/3134], Loss: 0.01185446\n",
            "Epoch [1/1], Batch [1790/3134], Loss: 0.01171102\n",
            "Epoch [1/1], Batch [1791/3134], Loss: 0.01178780\n",
            "Epoch [1/1], Batch [1792/3134], Loss: 0.01180576\n",
            "Epoch [1/1], Batch [1793/3134], Loss: 0.01174695\n",
            "Epoch [1/1], Batch [1794/3134], Loss: 0.01180774\n",
            "Epoch [1/1], Batch [1795/3134], Loss: 0.01186938\n",
            "Epoch [1/1], Batch [1796/3134], Loss: 0.01175746\n",
            "Epoch [1/1], Batch [1797/3134], Loss: 0.01184923\n",
            "Epoch [1/1], Batch [1798/3134], Loss: 0.01185062\n",
            "Epoch [1/1], Batch [1799/3134], Loss: 0.01174596\n",
            "Epoch [1/1], Batch [1800/3134], Loss: 0.01180328\n",
            "Epoch [1/1], Batch [1801/3134], Loss: 0.01182306\n",
            "Epoch [1/1], Batch [1802/3134], Loss: 0.01175351\n",
            "Epoch [1/1], Batch [1803/3134], Loss: 0.01178450\n",
            "Epoch [1/1], Batch [1804/3134], Loss: 0.01176496\n",
            "Epoch [1/1], Batch [1805/3134], Loss: 0.01175284\n",
            "Epoch [1/1], Batch [1806/3134], Loss: 0.01182640\n",
            "Epoch [1/1], Batch [1807/3134], Loss: 0.01178261\n",
            "Epoch [1/1], Batch [1808/3134], Loss: 0.01180892\n",
            "Epoch [1/1], Batch [1809/3134], Loss: 0.01181740\n",
            "Epoch [1/1], Batch [1810/3134], Loss: 0.01174963\n",
            "Epoch [1/1], Batch [1811/3134], Loss: 0.01178838\n",
            "Epoch [1/1], Batch [1812/3134], Loss: 0.01180488\n",
            "Epoch [1/1], Batch [1813/3134], Loss: 0.01178724\n",
            "Epoch [1/1], Batch [1814/3134], Loss: 0.01176990\n",
            "Epoch [1/1], Batch [1815/3134], Loss: 0.01173941\n",
            "Epoch [1/1], Batch [1816/3134], Loss: 0.01176697\n",
            "Epoch [1/1], Batch [1817/3134], Loss: 0.01184087\n",
            "Epoch [1/1], Batch [1818/3134], Loss: 0.01183022\n",
            "Epoch [1/1], Batch [1819/3134], Loss: 0.01179203\n",
            "Epoch [1/1], Batch [1820/3134], Loss: 0.01183328\n",
            "Epoch [1/1], Batch [1821/3134], Loss: 0.01175912\n",
            "Epoch [1/1], Batch [1822/3134], Loss: 0.01176936\n",
            "Epoch [1/1], Batch [1823/3134], Loss: 0.01172321\n",
            "Epoch [1/1], Batch [1824/3134], Loss: 0.01180010\n",
            "Epoch [1/1], Batch [1825/3134], Loss: 0.01184764\n",
            "Epoch [1/1], Batch [1826/3134], Loss: 0.01186073\n",
            "Epoch [1/1], Batch [1827/3134], Loss: 0.01183404\n",
            "Epoch [1/1], Batch [1828/3134], Loss: 0.01181754\n",
            "Epoch [1/1], Batch [1829/3134], Loss: 0.01180420\n",
            "Epoch [1/1], Batch [1830/3134], Loss: 0.01179248\n",
            "Epoch [1/1], Batch [1831/3134], Loss: 0.01177625\n",
            "Epoch [1/1], Batch [1832/3134], Loss: 0.01174079\n",
            "Epoch [1/1], Batch [1833/3134], Loss: 0.01180480\n",
            "Epoch [1/1], Batch [1834/3134], Loss: 0.01181751\n",
            "Epoch [1/1], Batch [1835/3134], Loss: 0.01186409\n",
            "Epoch [1/1], Batch [1836/3134], Loss: 0.01185048\n",
            "Epoch [1/1], Batch [1837/3134], Loss: 0.01183497\n",
            "Epoch [1/1], Batch [1838/3134], Loss: 0.01185223\n",
            "Epoch [1/1], Batch [1839/3134], Loss: 0.01183258\n",
            "Epoch [1/1], Batch [1840/3134], Loss: 0.01176878\n",
            "Epoch [1/1], Batch [1841/3134], Loss: 0.01179077\n",
            "Epoch [1/1], Batch [1842/3134], Loss: 0.01178920\n",
            "Epoch [1/1], Batch [1843/3134], Loss: 0.01176797\n",
            "Epoch [1/1], Batch [1844/3134], Loss: 0.01179569\n",
            "Epoch [1/1], Batch [1845/3134], Loss: 0.01176256\n",
            "Epoch [1/1], Batch [1846/3134], Loss: 0.01182768\n",
            "Epoch [1/1], Batch [1847/3134], Loss: 0.01177399\n",
            "Epoch [1/1], Batch [1848/3134], Loss: 0.01179092\n",
            "Epoch [1/1], Batch [1849/3134], Loss: 0.01185317\n",
            "Epoch [1/1], Batch [1850/3134], Loss: 0.01175362\n",
            "Epoch [1/1], Batch [1851/3134], Loss: 0.01183023\n",
            "Epoch [1/1], Batch [1852/3134], Loss: 0.01183475\n",
            "Epoch [1/1], Batch [1853/3134], Loss: 0.01177638\n",
            "Epoch [1/1], Batch [1854/3134], Loss: 0.01178883\n",
            "Epoch [1/1], Batch [1855/3134], Loss: 0.01180241\n",
            "Epoch [1/1], Batch [1856/3134], Loss: 0.01179889\n",
            "Epoch [1/1], Batch [1857/3134], Loss: 0.01181788\n",
            "Epoch [1/1], Batch [1858/3134], Loss: 0.01183197\n",
            "Epoch [1/1], Batch [1859/3134], Loss: 0.01173114\n",
            "Epoch [1/1], Batch [1860/3134], Loss: 0.01181799\n",
            "Epoch [1/1], Batch [1861/3134], Loss: 0.01182019\n",
            "Epoch [1/1], Batch [1862/3134], Loss: 0.01171617\n",
            "Epoch [1/1], Batch [1863/3134], Loss: 0.01181324\n",
            "Epoch [1/1], Batch [1864/3134], Loss: 0.01180411\n",
            "Epoch [1/1], Batch [1865/3134], Loss: 0.01180223\n",
            "Epoch [1/1], Batch [1866/3134], Loss: 0.01185356\n",
            "Epoch [1/1], Batch [1867/3134], Loss: 0.01169129\n",
            "Epoch [1/1], Batch [1868/3134], Loss: 0.01180371\n",
            "Epoch [1/1], Batch [1869/3134], Loss: 0.01178777\n",
            "Epoch [1/1], Batch [1870/3134], Loss: 0.01177184\n",
            "Epoch [1/1], Batch [1871/3134], Loss: 0.01181298\n",
            "Epoch [1/1], Batch [1872/3134], Loss: 0.01177329\n",
            "Epoch [1/1], Batch [1873/3134], Loss: 0.01178254\n",
            "Epoch [1/1], Batch [1874/3134], Loss: 0.01178871\n",
            "Epoch [1/1], Batch [1875/3134], Loss: 0.01180901\n",
            "Epoch [1/1], Batch [1876/3134], Loss: 0.01183373\n",
            "Epoch [1/1], Batch [1877/3134], Loss: 0.01178791\n",
            "Epoch [1/1], Batch [1878/3134], Loss: 0.01176201\n",
            "Epoch [1/1], Batch [1879/3134], Loss: 0.01186221\n",
            "Epoch [1/1], Batch [1880/3134], Loss: 0.01178596\n",
            "Epoch [1/1], Batch [1881/3134], Loss: 0.01179717\n",
            "Epoch [1/1], Batch [1882/3134], Loss: 0.01175699\n",
            "Epoch [1/1], Batch [1883/3134], Loss: 0.01173570\n",
            "Epoch [1/1], Batch [1884/3134], Loss: 0.01174001\n",
            "Epoch [1/1], Batch [1885/3134], Loss: 0.01180058\n",
            "Epoch [1/1], Batch [1886/3134], Loss: 0.01177970\n",
            "Epoch [1/1], Batch [1887/3134], Loss: 0.01177709\n",
            "Epoch [1/1], Batch [1888/3134], Loss: 0.01178318\n",
            "Epoch [1/1], Batch [1889/3134], Loss: 0.01179172\n",
            "Epoch [1/1], Batch [1890/3134], Loss: 0.01179005\n",
            "Epoch [1/1], Batch [1891/3134], Loss: 0.01170792\n",
            "Epoch [1/1], Batch [1892/3134], Loss: 0.01186222\n",
            "Epoch [1/1], Batch [1893/3134], Loss: 0.01181542\n",
            "Epoch [1/1], Batch [1894/3134], Loss: 0.01178890\n",
            "Epoch [1/1], Batch [1895/3134], Loss: 0.01180079\n",
            "Epoch [1/1], Batch [1896/3134], Loss: 0.01172780\n",
            "Epoch [1/1], Batch [1897/3134], Loss: 0.01175739\n",
            "Epoch [1/1], Batch [1898/3134], Loss: 0.01184689\n",
            "Epoch [1/1], Batch [1899/3134], Loss: 0.01172657\n",
            "Epoch [1/1], Batch [1900/3134], Loss: 0.01179480\n",
            "Epoch [1/1], Batch [1901/3134], Loss: 0.01176353\n",
            "Epoch [1/1], Batch [1902/3134], Loss: 0.01184379\n",
            "Epoch [1/1], Batch [1903/3134], Loss: 0.01179102\n",
            "Epoch [1/1], Batch [1904/3134], Loss: 0.01172774\n",
            "Epoch [1/1], Batch [1905/3134], Loss: 0.01177428\n",
            "Epoch [1/1], Batch [1906/3134], Loss: 0.01171842\n",
            "Epoch [1/1], Batch [1907/3134], Loss: 0.01177696\n",
            "Epoch [1/1], Batch [1908/3134], Loss: 0.01178283\n",
            "Epoch [1/1], Batch [1909/3134], Loss: 0.01183035\n",
            "Epoch [1/1], Batch [1910/3134], Loss: 0.01176523\n",
            "Epoch [1/1], Batch [1911/3134], Loss: 0.01182542\n",
            "Epoch [1/1], Batch [1912/3134], Loss: 0.01178926\n",
            "Epoch [1/1], Batch [1913/3134], Loss: 0.01181260\n",
            "Epoch [1/1], Batch [1914/3134], Loss: 0.01183558\n",
            "Epoch [1/1], Batch [1915/3134], Loss: 0.01179954\n",
            "Epoch [1/1], Batch [1916/3134], Loss: 0.01177195\n",
            "Epoch [1/1], Batch [1917/3134], Loss: 0.01181135\n",
            "Epoch [1/1], Batch [1918/3134], Loss: 0.01179217\n",
            "Epoch [1/1], Batch [1919/3134], Loss: 0.01176539\n",
            "Epoch [1/1], Batch [1920/3134], Loss: 0.01181960\n",
            "Epoch [1/1], Batch [1921/3134], Loss: 0.01180263\n",
            "Epoch [1/1], Batch [1922/3134], Loss: 0.01177816\n",
            "Epoch [1/1], Batch [1923/3134], Loss: 0.01176674\n",
            "Epoch [1/1], Batch [1924/3134], Loss: 0.01178481\n",
            "Epoch [1/1], Batch [1925/3134], Loss: 0.01174359\n",
            "Epoch [1/1], Batch [1926/3134], Loss: 0.01179185\n",
            "Epoch [1/1], Batch [1927/3134], Loss: 0.01175037\n",
            "Epoch [1/1], Batch [1928/3134], Loss: 0.01179632\n",
            "Epoch [1/1], Batch [1929/3134], Loss: 0.01175472\n",
            "Epoch [1/1], Batch [1930/3134], Loss: 0.01173951\n",
            "Epoch [1/1], Batch [1931/3134], Loss: 0.01180021\n",
            "Epoch [1/1], Batch [1932/3134], Loss: 0.01178554\n",
            "Epoch [1/1], Batch [1933/3134], Loss: 0.01176332\n",
            "Epoch [1/1], Batch [1934/3134], Loss: 0.01180185\n",
            "Epoch [1/1], Batch [1935/3134], Loss: 0.01177086\n",
            "Epoch [1/1], Batch [1936/3134], Loss: 0.01175699\n",
            "Epoch [1/1], Batch [1937/3134], Loss: 0.01179958\n",
            "Epoch [1/1], Batch [1938/3134], Loss: 0.01175772\n",
            "Epoch [1/1], Batch [1939/3134], Loss: 0.01174223\n",
            "Epoch [1/1], Batch [1940/3134], Loss: 0.01184367\n",
            "Epoch [1/1], Batch [1941/3134], Loss: 0.01183921\n",
            "Epoch [1/1], Batch [1942/3134], Loss: 0.01178718\n",
            "Epoch [1/1], Batch [1943/3134], Loss: 0.01174053\n",
            "Epoch [1/1], Batch [1944/3134], Loss: 0.01183194\n",
            "Epoch [1/1], Batch [1945/3134], Loss: 0.01176909\n",
            "Epoch [1/1], Batch [1946/3134], Loss: 0.01186150\n",
            "Epoch [1/1], Batch [1947/3134], Loss: 0.01174722\n",
            "Epoch [1/1], Batch [1948/3134], Loss: 0.01181757\n",
            "Epoch [1/1], Batch [1949/3134], Loss: 0.01184182\n",
            "Epoch [1/1], Batch [1950/3134], Loss: 0.01177372\n",
            "Epoch [1/1], Batch [1951/3134], Loss: 0.01182266\n",
            "Epoch [1/1], Batch [1952/3134], Loss: 0.01174626\n",
            "Epoch [1/1], Batch [1953/3134], Loss: 0.01172904\n",
            "Epoch [1/1], Batch [1954/3134], Loss: 0.01181123\n",
            "Epoch [1/1], Batch [1955/3134], Loss: 0.01184565\n",
            "Epoch [1/1], Batch [1956/3134], Loss: 0.01183242\n",
            "Epoch [1/1], Batch [1957/3134], Loss: 0.01175110\n",
            "Epoch [1/1], Batch [1958/3134], Loss: 0.01179493\n",
            "Epoch [1/1], Batch [1959/3134], Loss: 0.01174693\n",
            "Epoch [1/1], Batch [1960/3134], Loss: 0.01183839\n",
            "Epoch [1/1], Batch [1961/3134], Loss: 0.01178387\n",
            "Epoch [1/1], Batch [1962/3134], Loss: 0.01173005\n",
            "Epoch [1/1], Batch [1963/3134], Loss: 0.01181261\n",
            "Epoch [1/1], Batch [1964/3134], Loss: 0.01181317\n",
            "Epoch [1/1], Batch [1965/3134], Loss: 0.01188335\n",
            "Epoch [1/1], Batch [1966/3134], Loss: 0.01177657\n",
            "Epoch [1/1], Batch [1967/3134], Loss: 0.01179846\n",
            "Epoch [1/1], Batch [1968/3134], Loss: 0.01177979\n",
            "Epoch [1/1], Batch [1969/3134], Loss: 0.01180039\n",
            "Epoch [1/1], Batch [1970/3134], Loss: 0.01178197\n",
            "Epoch [1/1], Batch [1971/3134], Loss: 0.01179226\n",
            "Epoch [1/1], Batch [1972/3134], Loss: 0.01180732\n",
            "Epoch [1/1], Batch [1973/3134], Loss: 0.01180175\n",
            "Epoch [1/1], Batch [1974/3134], Loss: 0.01179126\n",
            "Epoch [1/1], Batch [1975/3134], Loss: 0.01179430\n",
            "Epoch [1/1], Batch [1976/3134], Loss: 0.01176941\n",
            "Epoch [1/1], Batch [1977/3134], Loss: 0.01181800\n",
            "Epoch [1/1], Batch [1978/3134], Loss: 0.01180526\n",
            "Epoch [1/1], Batch [1979/3134], Loss: 0.01178590\n",
            "Epoch [1/1], Batch [1980/3134], Loss: 0.01182687\n",
            "Epoch [1/1], Batch [1981/3134], Loss: 0.01181921\n",
            "Epoch [1/1], Batch [1982/3134], Loss: 0.01180168\n",
            "Epoch [1/1], Batch [1983/3134], Loss: 0.01177950\n",
            "Epoch [1/1], Batch [1984/3134], Loss: 0.01177251\n",
            "Epoch [1/1], Batch [1985/3134], Loss: 0.01179110\n",
            "Epoch [1/1], Batch [1986/3134], Loss: 0.01179644\n",
            "Epoch [1/1], Batch [1987/3134], Loss: 0.01175605\n",
            "Epoch [1/1], Batch [1988/3134], Loss: 0.01182548\n",
            "Epoch [1/1], Batch [1989/3134], Loss: 0.01174281\n",
            "Epoch [1/1], Batch [1990/3134], Loss: 0.01184289\n",
            "Epoch [1/1], Batch [1991/3134], Loss: 0.01180721\n",
            "Epoch [1/1], Batch [1992/3134], Loss: 0.01171091\n",
            "Epoch [1/1], Batch [1993/3134], Loss: 0.01181155\n",
            "Epoch [1/1], Batch [1994/3134], Loss: 0.01180025\n",
            "Epoch [1/1], Batch [1995/3134], Loss: 0.01181662\n",
            "Epoch [1/1], Batch [1996/3134], Loss: 0.01181262\n",
            "Epoch [1/1], Batch [1997/3134], Loss: 0.01177056\n",
            "Epoch [1/1], Batch [1998/3134], Loss: 0.01179028\n",
            "Epoch [1/1], Batch [1999/3134], Loss: 0.01178939\n",
            "Epoch [1/1], Batch [2000/3134], Loss: 0.01172985\n",
            "Epoch [1/1], Batch [2001/3134], Loss: 0.01172845\n",
            "Epoch [1/1], Batch [2002/3134], Loss: 0.01177214\n",
            "Epoch [1/1], Batch [2003/3134], Loss: 0.01181886\n",
            "Epoch [1/1], Batch [2004/3134], Loss: 0.01182795\n",
            "Epoch [1/1], Batch [2005/3134], Loss: 0.01175079\n",
            "Epoch [1/1], Batch [2006/3134], Loss: 0.01177360\n",
            "Epoch [1/1], Batch [2007/3134], Loss: 0.01179084\n",
            "Epoch [1/1], Batch [2008/3134], Loss: 0.01177313\n",
            "Epoch [1/1], Batch [2009/3134], Loss: 0.01182844\n",
            "Epoch [1/1], Batch [2010/3134], Loss: 0.01173498\n",
            "Epoch [1/1], Batch [2011/3134], Loss: 0.01180197\n",
            "Epoch [1/1], Batch [2012/3134], Loss: 0.01181833\n",
            "Epoch [1/1], Batch [2013/3134], Loss: 0.01179209\n",
            "Epoch [1/1], Batch [2014/3134], Loss: 0.01173224\n",
            "Epoch [1/1], Batch [2015/3134], Loss: 0.01176053\n",
            "Epoch [1/1], Batch [2016/3134], Loss: 0.01180082\n",
            "Epoch [1/1], Batch [2017/3134], Loss: 0.01176975\n",
            "Epoch [1/1], Batch [2018/3134], Loss: 0.01178752\n",
            "Epoch [1/1], Batch [2019/3134], Loss: 0.01182706\n",
            "Epoch [1/1], Batch [2020/3134], Loss: 0.01176065\n",
            "Epoch [1/1], Batch [2021/3134], Loss: 0.01176378\n",
            "Epoch [1/1], Batch [2022/3134], Loss: 0.01174326\n",
            "Epoch [1/1], Batch [2023/3134], Loss: 0.01177957\n",
            "Epoch [1/1], Batch [2024/3134], Loss: 0.01177998\n",
            "Epoch [1/1], Batch [2025/3134], Loss: 0.01177001\n",
            "Epoch [1/1], Batch [2026/3134], Loss: 0.01173627\n",
            "Epoch [1/1], Batch [2027/3134], Loss: 0.01185129\n",
            "Epoch [1/1], Batch [2028/3134], Loss: 0.01187118\n",
            "Epoch [1/1], Batch [2029/3134], Loss: 0.01179164\n",
            "Epoch [1/1], Batch [2030/3134], Loss: 0.01180294\n",
            "Epoch [1/1], Batch [2031/3134], Loss: 0.01180852\n",
            "Epoch [1/1], Batch [2032/3134], Loss: 0.01177831\n",
            "Epoch [1/1], Batch [2033/3134], Loss: 0.01178261\n",
            "Epoch [1/1], Batch [2034/3134], Loss: 0.01181405\n",
            "Epoch [1/1], Batch [2035/3134], Loss: 0.01178005\n",
            "Epoch [1/1], Batch [2036/3134], Loss: 0.01177358\n",
            "Epoch [1/1], Batch [2037/3134], Loss: 0.01185008\n",
            "Epoch [1/1], Batch [2038/3134], Loss: 0.01179579\n",
            "Epoch [1/1], Batch [2039/3134], Loss: 0.01175597\n",
            "Epoch [1/1], Batch [2040/3134], Loss: 0.01176456\n",
            "Epoch [1/1], Batch [2041/3134], Loss: 0.01173207\n",
            "Epoch [1/1], Batch [2042/3134], Loss: 0.01176134\n",
            "Epoch [1/1], Batch [2043/3134], Loss: 0.01180309\n",
            "Epoch [1/1], Batch [2044/3134], Loss: 0.01173324\n",
            "Epoch [1/1], Batch [2045/3134], Loss: 0.01182366\n",
            "Epoch [1/1], Batch [2046/3134], Loss: 0.01180299\n",
            "Epoch [1/1], Batch [2047/3134], Loss: 0.01180341\n",
            "Epoch [1/1], Batch [2048/3134], Loss: 0.01180235\n",
            "Epoch [1/1], Batch [2049/3134], Loss: 0.01181245\n",
            "Epoch [1/1], Batch [2050/3134], Loss: 0.01178435\n",
            "Epoch [1/1], Batch [2051/3134], Loss: 0.01176854\n",
            "Epoch [1/1], Batch [2052/3134], Loss: 0.01176068\n",
            "Epoch [1/1], Batch [2053/3134], Loss: 0.01182723\n",
            "Epoch [1/1], Batch [2054/3134], Loss: 0.01178574\n",
            "Epoch [1/1], Batch [2055/3134], Loss: 0.01178123\n",
            "Epoch [1/1], Batch [2056/3134], Loss: 0.01174222\n",
            "Epoch [1/1], Batch [2057/3134], Loss: 0.01175943\n",
            "Epoch [1/1], Batch [2058/3134], Loss: 0.01176931\n",
            "Epoch [1/1], Batch [2059/3134], Loss: 0.01181326\n",
            "Epoch [1/1], Batch [2060/3134], Loss: 0.01182077\n",
            "Epoch [1/1], Batch [2061/3134], Loss: 0.01173135\n",
            "Epoch [1/1], Batch [2062/3134], Loss: 0.01179951\n",
            "Epoch [1/1], Batch [2063/3134], Loss: 0.01180263\n",
            "Epoch [1/1], Batch [2064/3134], Loss: 0.01178371\n",
            "Epoch [1/1], Batch [2065/3134], Loss: 0.01182948\n",
            "Epoch [1/1], Batch [2066/3134], Loss: 0.01179517\n",
            "Epoch [1/1], Batch [2067/3134], Loss: 0.01178001\n",
            "Epoch [1/1], Batch [2068/3134], Loss: 0.01179318\n",
            "Epoch [1/1], Batch [2069/3134], Loss: 0.01176551\n",
            "Epoch [1/1], Batch [2070/3134], Loss: 0.01185994\n",
            "Epoch [1/1], Batch [2071/3134], Loss: 0.01182623\n",
            "Epoch [1/1], Batch [2072/3134], Loss: 0.01181700\n",
            "Epoch [1/1], Batch [2073/3134], Loss: 0.01178991\n",
            "Epoch [1/1], Batch [2074/3134], Loss: 0.01175776\n",
            "Epoch [1/1], Batch [2075/3134], Loss: 0.01179395\n",
            "Epoch [1/1], Batch [2076/3134], Loss: 0.01183300\n",
            "Epoch [1/1], Batch [2077/3134], Loss: 0.01177448\n",
            "Epoch [1/1], Batch [2078/3134], Loss: 0.01173645\n",
            "Epoch [1/1], Batch [2079/3134], Loss: 0.01176631\n",
            "Epoch [1/1], Batch [2080/3134], Loss: 0.01174147\n",
            "Epoch [1/1], Batch [2081/3134], Loss: 0.01179526\n",
            "Epoch [1/1], Batch [2082/3134], Loss: 0.01179273\n",
            "Epoch [1/1], Batch [2083/3134], Loss: 0.01178240\n",
            "Epoch [1/1], Batch [2084/3134], Loss: 0.01176041\n",
            "Epoch [1/1], Batch [2085/3134], Loss: 0.01182756\n",
            "Epoch [1/1], Batch [2086/3134], Loss: 0.01178851\n",
            "Epoch [1/1], Batch [2087/3134], Loss: 0.01178528\n",
            "Epoch [1/1], Batch [2088/3134], Loss: 0.01179039\n",
            "Epoch [1/1], Batch [2089/3134], Loss: 0.01184597\n",
            "Epoch [1/1], Batch [2090/3134], Loss: 0.01187015\n",
            "Epoch [1/1], Batch [2091/3134], Loss: 0.01174861\n",
            "Epoch [1/1], Batch [2092/3134], Loss: 0.01174584\n",
            "Epoch [1/1], Batch [2093/3134], Loss: 0.01173091\n",
            "Epoch [1/1], Batch [2094/3134], Loss: 0.01179783\n",
            "Epoch [1/1], Batch [2095/3134], Loss: 0.01174611\n",
            "Epoch [1/1], Batch [2096/3134], Loss: 0.01181788\n",
            "Epoch [1/1], Batch [2097/3134], Loss: 0.01180816\n",
            "Epoch [1/1], Batch [2098/3134], Loss: 0.01178433\n",
            "Epoch [1/1], Batch [2099/3134], Loss: 0.01174116\n",
            "Epoch [1/1], Batch [2100/3134], Loss: 0.01175270\n",
            "Epoch [1/1], Batch [2101/3134], Loss: 0.01181612\n",
            "Epoch [1/1], Batch [2102/3134], Loss: 0.01171801\n",
            "Epoch [1/1], Batch [2103/3134], Loss: 0.01180034\n",
            "Epoch [1/1], Batch [2104/3134], Loss: 0.01178217\n",
            "Epoch [1/1], Batch [2105/3134], Loss: 0.01176372\n",
            "Epoch [1/1], Batch [2106/3134], Loss: 0.01182662\n",
            "Epoch [1/1], Batch [2107/3134], Loss: 0.01179930\n",
            "Epoch [1/1], Batch [2108/3134], Loss: 0.01177321\n",
            "Epoch [1/1], Batch [2109/3134], Loss: 0.01180793\n",
            "Epoch [1/1], Batch [2110/3134], Loss: 0.01176153\n",
            "Epoch [1/1], Batch [2111/3134], Loss: 0.01181224\n",
            "Epoch [1/1], Batch [2112/3134], Loss: 0.01180558\n",
            "Epoch [1/1], Batch [2113/3134], Loss: 0.01172690\n",
            "Epoch [1/1], Batch [2114/3134], Loss: 0.01178563\n",
            "Epoch [1/1], Batch [2115/3134], Loss: 0.01178063\n",
            "Epoch [1/1], Batch [2116/3134], Loss: 0.01178724\n",
            "Epoch [1/1], Batch [2117/3134], Loss: 0.01182131\n",
            "Epoch [1/1], Batch [2118/3134], Loss: 0.01185849\n",
            "Epoch [1/1], Batch [2119/3134], Loss: 0.01179948\n",
            "Epoch [1/1], Batch [2120/3134], Loss: 0.01173125\n",
            "Epoch [1/1], Batch [2121/3134], Loss: 0.01177268\n",
            "Epoch [1/1], Batch [2122/3134], Loss: 0.01175250\n",
            "Epoch [1/1], Batch [2123/3134], Loss: 0.01177561\n",
            "Epoch [1/1], Batch [2124/3134], Loss: 0.01174815\n",
            "Epoch [1/1], Batch [2125/3134], Loss: 0.01180934\n",
            "Epoch [1/1], Batch [2126/3134], Loss: 0.01176493\n",
            "Epoch [1/1], Batch [2127/3134], Loss: 0.01177396\n",
            "Epoch [1/1], Batch [2128/3134], Loss: 0.01178921\n",
            "Epoch [1/1], Batch [2129/3134], Loss: 0.01180093\n",
            "Epoch [1/1], Batch [2130/3134], Loss: 0.01180408\n",
            "Epoch [1/1], Batch [2131/3134], Loss: 0.01179640\n",
            "Epoch [1/1], Batch [2132/3134], Loss: 0.01175915\n",
            "Epoch [1/1], Batch [2133/3134], Loss: 0.01182899\n",
            "Epoch [1/1], Batch [2134/3134], Loss: 0.01177498\n",
            "Epoch [1/1], Batch [2135/3134], Loss: 0.01177526\n",
            "Epoch [1/1], Batch [2136/3134], Loss: 0.01174558\n",
            "Epoch [1/1], Batch [2137/3134], Loss: 0.01170904\n",
            "Epoch [1/1], Batch [2138/3134], Loss: 0.01178955\n",
            "Epoch [1/1], Batch [2139/3134], Loss: 0.01173373\n",
            "Epoch [1/1], Batch [2140/3134], Loss: 0.01180381\n",
            "Epoch [1/1], Batch [2141/3134], Loss: 0.01177823\n",
            "Epoch [1/1], Batch [2142/3134], Loss: 0.01181617\n",
            "Epoch [1/1], Batch [2143/3134], Loss: 0.01175473\n",
            "Epoch [1/1], Batch [2144/3134], Loss: 0.01174097\n",
            "Epoch [1/1], Batch [2145/3134], Loss: 0.01173870\n",
            "Epoch [1/1], Batch [2146/3134], Loss: 0.01178627\n",
            "Epoch [1/1], Batch [2147/3134], Loss: 0.01184739\n",
            "Epoch [1/1], Batch [2148/3134], Loss: 0.01180833\n",
            "Epoch [1/1], Batch [2149/3134], Loss: 0.01175722\n",
            "Epoch [1/1], Batch [2150/3134], Loss: 0.01175939\n",
            "Epoch [1/1], Batch [2151/3134], Loss: 0.01174961\n",
            "Epoch [1/1], Batch [2152/3134], Loss: 0.01178050\n",
            "Epoch [1/1], Batch [2153/3134], Loss: 0.01180557\n",
            "Epoch [1/1], Batch [2154/3134], Loss: 0.01181512\n",
            "Epoch [1/1], Batch [2155/3134], Loss: 0.01176287\n",
            "Epoch [1/1], Batch [2156/3134], Loss: 0.01180787\n",
            "Epoch [1/1], Batch [2157/3134], Loss: 0.01177598\n",
            "Epoch [1/1], Batch [2158/3134], Loss: 0.01180809\n",
            "Epoch [1/1], Batch [2159/3134], Loss: 0.01184493\n",
            "Epoch [1/1], Batch [2160/3134], Loss: 0.01175508\n",
            "Epoch [1/1], Batch [2161/3134], Loss: 0.01177627\n",
            "Epoch [1/1], Batch [2162/3134], Loss: 0.01178196\n",
            "Epoch [1/1], Batch [2163/3134], Loss: 0.01176303\n",
            "Epoch [1/1], Batch [2164/3134], Loss: 0.01182799\n",
            "Epoch [1/1], Batch [2165/3134], Loss: 0.01177747\n",
            "Epoch [1/1], Batch [2166/3134], Loss: 0.01176325\n",
            "Epoch [1/1], Batch [2167/3134], Loss: 0.01177133\n",
            "Epoch [1/1], Batch [2168/3134], Loss: 0.01172898\n",
            "Epoch [1/1], Batch [2169/3134], Loss: 0.01176586\n",
            "Epoch [1/1], Batch [2170/3134], Loss: 0.01181693\n",
            "Epoch [1/1], Batch [2171/3134], Loss: 0.01178042\n",
            "Epoch [1/1], Batch [2172/3134], Loss: 0.01181626\n",
            "Epoch [1/1], Batch [2173/3134], Loss: 0.01172500\n",
            "Epoch [1/1], Batch [2174/3134], Loss: 0.01176319\n",
            "Epoch [1/1], Batch [2175/3134], Loss: 0.01181810\n",
            "Epoch [1/1], Batch [2176/3134], Loss: 0.01172694\n",
            "Epoch [1/1], Batch [2177/3134], Loss: 0.01180791\n",
            "Epoch [1/1], Batch [2178/3134], Loss: 0.01176748\n",
            "Epoch [1/1], Batch [2179/3134], Loss: 0.01182597\n",
            "Epoch [1/1], Batch [2180/3134], Loss: 0.01177393\n",
            "Epoch [1/1], Batch [2181/3134], Loss: 0.01174108\n",
            "Epoch [1/1], Batch [2182/3134], Loss: 0.01170267\n",
            "Epoch [1/1], Batch [2183/3134], Loss: 0.01176690\n",
            "Epoch [1/1], Batch [2184/3134], Loss: 0.01173516\n",
            "Epoch [1/1], Batch [2185/3134], Loss: 0.01181107\n",
            "Epoch [1/1], Batch [2186/3134], Loss: 0.01178693\n",
            "Epoch [1/1], Batch [2187/3134], Loss: 0.01172560\n",
            "Epoch [1/1], Batch [2188/3134], Loss: 0.01176927\n",
            "Epoch [1/1], Batch [2189/3134], Loss: 0.01177428\n",
            "Epoch [1/1], Batch [2190/3134], Loss: 0.01181461\n",
            "Epoch [1/1], Batch [2191/3134], Loss: 0.01170064\n",
            "Epoch [1/1], Batch [2192/3134], Loss: 0.01177066\n",
            "Epoch [1/1], Batch [2193/3134], Loss: 0.01182385\n",
            "Epoch [1/1], Batch [2194/3134], Loss: 0.01185720\n",
            "Epoch [1/1], Batch [2195/3134], Loss: 0.01174715\n",
            "Epoch [1/1], Batch [2196/3134], Loss: 0.01181192\n",
            "Epoch [1/1], Batch [2197/3134], Loss: 0.01177708\n",
            "Epoch [1/1], Batch [2198/3134], Loss: 0.01181715\n",
            "Epoch [1/1], Batch [2199/3134], Loss: 0.01175983\n",
            "Epoch [1/1], Batch [2200/3134], Loss: 0.01180474\n",
            "Epoch [1/1], Batch [2201/3134], Loss: 0.01179253\n",
            "Epoch [1/1], Batch [2202/3134], Loss: 0.01181767\n",
            "Epoch [1/1], Batch [2203/3134], Loss: 0.01178166\n",
            "Epoch [1/1], Batch [2204/3134], Loss: 0.01178930\n",
            "Epoch [1/1], Batch [2205/3134], Loss: 0.01181137\n",
            "Epoch [1/1], Batch [2206/3134], Loss: 0.01185974\n",
            "Epoch [1/1], Batch [2207/3134], Loss: 0.01182135\n",
            "Epoch [1/1], Batch [2208/3134], Loss: 0.01179033\n",
            "Epoch [1/1], Batch [2209/3134], Loss: 0.01177675\n",
            "Epoch [1/1], Batch [2210/3134], Loss: 0.01179821\n",
            "Epoch [1/1], Batch [2211/3134], Loss: 0.01183279\n",
            "Epoch [1/1], Batch [2212/3134], Loss: 0.01175195\n",
            "Epoch [1/1], Batch [2213/3134], Loss: 0.01179631\n",
            "Epoch [1/1], Batch [2214/3134], Loss: 0.01180480\n",
            "Epoch [1/1], Batch [2215/3134], Loss: 0.01182536\n",
            "Epoch [1/1], Batch [2216/3134], Loss: 0.01181102\n",
            "Epoch [1/1], Batch [2217/3134], Loss: 0.01179236\n",
            "Epoch [1/1], Batch [2218/3134], Loss: 0.01178168\n",
            "Epoch [1/1], Batch [2219/3134], Loss: 0.01185087\n",
            "Epoch [1/1], Batch [2220/3134], Loss: 0.01176354\n",
            "Epoch [1/1], Batch [2221/3134], Loss: 0.01177246\n",
            "Epoch [1/1], Batch [2222/3134], Loss: 0.01180911\n",
            "Epoch [1/1], Batch [2223/3134], Loss: 0.01175585\n",
            "Epoch [1/1], Batch [2224/3134], Loss: 0.01176245\n",
            "Epoch [1/1], Batch [2225/3134], Loss: 0.01186967\n",
            "Epoch [1/1], Batch [2226/3134], Loss: 0.01174987\n",
            "Epoch [1/1], Batch [2227/3134], Loss: 0.01177351\n",
            "Epoch [1/1], Batch [2228/3134], Loss: 0.01176878\n",
            "Epoch [1/1], Batch [2229/3134], Loss: 0.01178900\n",
            "Epoch [1/1], Batch [2230/3134], Loss: 0.01183423\n",
            "Epoch [1/1], Batch [2231/3134], Loss: 0.01174853\n",
            "Epoch [1/1], Batch [2232/3134], Loss: 0.01181900\n",
            "Epoch [1/1], Batch [2233/3134], Loss: 0.01179102\n",
            "Epoch [1/1], Batch [2234/3134], Loss: 0.01176444\n",
            "Epoch [1/1], Batch [2235/3134], Loss: 0.01171386\n",
            "Epoch [1/1], Batch [2236/3134], Loss: 0.01177002\n",
            "Epoch [1/1], Batch [2237/3134], Loss: 0.01182799\n",
            "Epoch [1/1], Batch [2238/3134], Loss: 0.01177845\n",
            "Epoch [1/1], Batch [2239/3134], Loss: 0.01178177\n",
            "Epoch [1/1], Batch [2240/3134], Loss: 0.01176620\n",
            "Epoch [1/1], Batch [2241/3134], Loss: 0.01183344\n",
            "Epoch [1/1], Batch [2242/3134], Loss: 0.01174553\n",
            "Epoch [1/1], Batch [2243/3134], Loss: 0.01181323\n",
            "Epoch [1/1], Batch [2244/3134], Loss: 0.01177603\n",
            "Epoch [1/1], Batch [2245/3134], Loss: 0.01175131\n",
            "Epoch [1/1], Batch [2246/3134], Loss: 0.01173305\n",
            "Epoch [1/1], Batch [2247/3134], Loss: 0.01172619\n",
            "Epoch [1/1], Batch [2248/3134], Loss: 0.01179269\n",
            "Epoch [1/1], Batch [2249/3134], Loss: 0.01180892\n",
            "Epoch [1/1], Batch [2250/3134], Loss: 0.01178304\n",
            "Epoch [1/1], Batch [2251/3134], Loss: 0.01181096\n",
            "Epoch [1/1], Batch [2252/3134], Loss: 0.01176986\n",
            "Epoch [1/1], Batch [2253/3134], Loss: 0.01182878\n",
            "Epoch [1/1], Batch [2254/3134], Loss: 0.01177866\n",
            "Epoch [1/1], Batch [2255/3134], Loss: 0.01175641\n",
            "Epoch [1/1], Batch [2256/3134], Loss: 0.01182453\n",
            "Epoch [1/1], Batch [2257/3134], Loss: 0.01177960\n",
            "Epoch [1/1], Batch [2258/3134], Loss: 0.01178994\n",
            "Epoch [1/1], Batch [2259/3134], Loss: 0.01178510\n",
            "Epoch [1/1], Batch [2260/3134], Loss: 0.01181997\n",
            "Epoch [1/1], Batch [2261/3134], Loss: 0.01183102\n",
            "Epoch [1/1], Batch [2262/3134], Loss: 0.01184180\n",
            "Epoch [1/1], Batch [2263/3134], Loss: 0.01187967\n",
            "Epoch [1/1], Batch [2264/3134], Loss: 0.01178930\n",
            "Epoch [1/1], Batch [2265/3134], Loss: 0.01178447\n",
            "Epoch [1/1], Batch [2266/3134], Loss: 0.01170420\n",
            "Epoch [1/1], Batch [2267/3134], Loss: 0.01180839\n",
            "Epoch [1/1], Batch [2268/3134], Loss: 0.01182529\n",
            "Epoch [1/1], Batch [2269/3134], Loss: 0.01175747\n",
            "Epoch [1/1], Batch [2270/3134], Loss: 0.01177625\n",
            "Epoch [1/1], Batch [2271/3134], Loss: 0.01172780\n",
            "Epoch [1/1], Batch [2272/3134], Loss: 0.01176555\n",
            "Epoch [1/1], Batch [2273/3134], Loss: 0.01175867\n",
            "Epoch [1/1], Batch [2274/3134], Loss: 0.01178859\n",
            "Epoch [1/1], Batch [2275/3134], Loss: 0.01179215\n",
            "Epoch [1/1], Batch [2276/3134], Loss: 0.01176622\n",
            "Epoch [1/1], Batch [2277/3134], Loss: 0.01178499\n",
            "Epoch [1/1], Batch [2278/3134], Loss: 0.01174832\n",
            "Epoch [1/1], Batch [2279/3134], Loss: 0.01172624\n",
            "Epoch [1/1], Batch [2280/3134], Loss: 0.01177551\n",
            "Epoch [1/1], Batch [2281/3134], Loss: 0.01180120\n",
            "Epoch [1/1], Batch [2282/3134], Loss: 0.01178273\n",
            "Epoch [1/1], Batch [2283/3134], Loss: 0.01176459\n",
            "Epoch [1/1], Batch [2284/3134], Loss: 0.01178944\n",
            "Epoch [1/1], Batch [2285/3134], Loss: 0.01180251\n",
            "Epoch [1/1], Batch [2286/3134], Loss: 0.01174356\n",
            "Epoch [1/1], Batch [2287/3134], Loss: 0.01185833\n",
            "Epoch [1/1], Batch [2288/3134], Loss: 0.01175551\n",
            "Epoch [1/1], Batch [2289/3134], Loss: 0.01176008\n",
            "Epoch [1/1], Batch [2290/3134], Loss: 0.01185628\n",
            "Epoch [1/1], Batch [2291/3134], Loss: 0.01173378\n",
            "Epoch [1/1], Batch [2292/3134], Loss: 0.01174561\n",
            "Epoch [1/1], Batch [2293/3134], Loss: 0.01179454\n",
            "Epoch [1/1], Batch [2294/3134], Loss: 0.01177835\n",
            "Epoch [1/1], Batch [2295/3134], Loss: 0.01174146\n",
            "Epoch [1/1], Batch [2296/3134], Loss: 0.01178170\n",
            "Epoch [1/1], Batch [2297/3134], Loss: 0.01174682\n",
            "Epoch [1/1], Batch [2298/3134], Loss: 0.01181322\n",
            "Epoch [1/1], Batch [2299/3134], Loss: 0.01180857\n",
            "Epoch [1/1], Batch [2300/3134], Loss: 0.01176307\n",
            "Epoch [1/1], Batch [2301/3134], Loss: 0.01177523\n",
            "Epoch [1/1], Batch [2302/3134], Loss: 0.01174937\n",
            "Epoch [1/1], Batch [2303/3134], Loss: 0.01177278\n",
            "Epoch [1/1], Batch [2304/3134], Loss: 0.01181503\n",
            "Epoch [1/1], Batch [2305/3134], Loss: 0.01172660\n",
            "Epoch [1/1], Batch [2306/3134], Loss: 0.01177514\n",
            "Epoch [1/1], Batch [2307/3134], Loss: 0.01177446\n",
            "Epoch [1/1], Batch [2308/3134], Loss: 0.01177768\n",
            "Epoch [1/1], Batch [2309/3134], Loss: 0.01179370\n",
            "Epoch [1/1], Batch [2310/3134], Loss: 0.01177265\n",
            "Epoch [1/1], Batch [2311/3134], Loss: 0.01179073\n",
            "Epoch [1/1], Batch [2312/3134], Loss: 0.01175140\n",
            "Epoch [1/1], Batch [2313/3134], Loss: 0.01182327\n",
            "Epoch [1/1], Batch [2314/3134], Loss: 0.01174452\n",
            "Epoch [1/1], Batch [2315/3134], Loss: 0.01178038\n",
            "Epoch [1/1], Batch [2316/3134], Loss: 0.01173479\n",
            "Epoch [1/1], Batch [2317/3134], Loss: 0.01172419\n",
            "Epoch [1/1], Batch [2318/3134], Loss: 0.01178975\n",
            "Epoch [1/1], Batch [2319/3134], Loss: 0.01174661\n",
            "Epoch [1/1], Batch [2320/3134], Loss: 0.01178746\n",
            "Epoch [1/1], Batch [2321/3134], Loss: 0.01175222\n",
            "Epoch [1/1], Batch [2322/3134], Loss: 0.01174825\n",
            "Epoch [1/1], Batch [2323/3134], Loss: 0.01176366\n",
            "Epoch [1/1], Batch [2324/3134], Loss: 0.01178896\n",
            "Epoch [1/1], Batch [2325/3134], Loss: 0.01178673\n",
            "Epoch [1/1], Batch [2326/3134], Loss: 0.01173941\n",
            "Epoch [1/1], Batch [2327/3134], Loss: 0.01179997\n",
            "Epoch [1/1], Batch [2328/3134], Loss: 0.01176492\n",
            "Epoch [1/1], Batch [2329/3134], Loss: 0.01174918\n",
            "Epoch [1/1], Batch [2330/3134], Loss: 0.01174304\n",
            "Epoch [1/1], Batch [2331/3134], Loss: 0.01180613\n",
            "Epoch [1/1], Batch [2332/3134], Loss: 0.01177148\n",
            "Epoch [1/1], Batch [2333/3134], Loss: 0.01170990\n",
            "Epoch [1/1], Batch [2334/3134], Loss: 0.01186368\n",
            "Epoch [1/1], Batch [2335/3134], Loss: 0.01172578\n",
            "Epoch [1/1], Batch [2336/3134], Loss: 0.01175867\n",
            "Epoch [1/1], Batch [2337/3134], Loss: 0.01181604\n",
            "Epoch [1/1], Batch [2338/3134], Loss: 0.01184573\n",
            "Epoch [1/1], Batch [2339/3134], Loss: 0.01173973\n",
            "Epoch [1/1], Batch [2340/3134], Loss: 0.01175208\n",
            "Epoch [1/1], Batch [2341/3134], Loss: 0.01178666\n",
            "Epoch [1/1], Batch [2342/3134], Loss: 0.01179785\n",
            "Epoch [1/1], Batch [2343/3134], Loss: 0.01175398\n",
            "Epoch [1/1], Batch [2344/3134], Loss: 0.01174815\n",
            "Epoch [1/1], Batch [2345/3134], Loss: 0.01178494\n",
            "Epoch [1/1], Batch [2346/3134], Loss: 0.01174053\n",
            "Epoch [1/1], Batch [2347/3134], Loss: 0.01176177\n",
            "Epoch [1/1], Batch [2348/3134], Loss: 0.01180874\n",
            "Epoch [1/1], Batch [2349/3134], Loss: 0.01179362\n",
            "Epoch [1/1], Batch [2350/3134], Loss: 0.01178284\n",
            "Epoch [1/1], Batch [2351/3134], Loss: 0.01186508\n",
            "Epoch [1/1], Batch [2352/3134], Loss: 0.01181720\n",
            "Epoch [1/1], Batch [2353/3134], Loss: 0.01176560\n",
            "Epoch [1/1], Batch [2354/3134], Loss: 0.01180692\n",
            "Epoch [1/1], Batch [2355/3134], Loss: 0.01183254\n",
            "Epoch [1/1], Batch [2356/3134], Loss: 0.01179870\n",
            "Epoch [1/1], Batch [2357/3134], Loss: 0.01182684\n",
            "Epoch [1/1], Batch [2358/3134], Loss: 0.01172207\n",
            "Epoch [1/1], Batch [2359/3134], Loss: 0.01177890\n",
            "Epoch [1/1], Batch [2360/3134], Loss: 0.01179145\n",
            "Epoch [1/1], Batch [2361/3134], Loss: 0.01180927\n",
            "Epoch [1/1], Batch [2362/3134], Loss: 0.01170791\n",
            "Epoch [1/1], Batch [2363/3134], Loss: 0.01175285\n",
            "Epoch [1/1], Batch [2364/3134], Loss: 0.01181466\n",
            "Epoch [1/1], Batch [2365/3134], Loss: 0.01175353\n",
            "Epoch [1/1], Batch [2366/3134], Loss: 0.01183098\n",
            "Epoch [1/1], Batch [2367/3134], Loss: 0.01178362\n",
            "Epoch [1/1], Batch [2368/3134], Loss: 0.01180196\n",
            "Epoch [1/1], Batch [2369/3134], Loss: 0.01179025\n",
            "Epoch [1/1], Batch [2370/3134], Loss: 0.01176375\n",
            "Epoch [1/1], Batch [2371/3134], Loss: 0.01181433\n",
            "Epoch [1/1], Batch [2372/3134], Loss: 0.01173032\n",
            "Epoch [1/1], Batch [2373/3134], Loss: 0.01176194\n",
            "Epoch [1/1], Batch [2374/3134], Loss: 0.01179054\n",
            "Epoch [1/1], Batch [2375/3134], Loss: 0.01175039\n",
            "Epoch [1/1], Batch [2376/3134], Loss: 0.01174753\n",
            "Epoch [1/1], Batch [2377/3134], Loss: 0.01178936\n",
            "Epoch [1/1], Batch [2378/3134], Loss: 0.01183057\n",
            "Epoch [1/1], Batch [2379/3134], Loss: 0.01182464\n",
            "Epoch [1/1], Batch [2380/3134], Loss: 0.01179912\n",
            "Epoch [1/1], Batch [2381/3134], Loss: 0.01177620\n",
            "Epoch [1/1], Batch [2382/3134], Loss: 0.01178631\n",
            "Epoch [1/1], Batch [2383/3134], Loss: 0.01178569\n",
            "Epoch [1/1], Batch [2384/3134], Loss: 0.01178395\n",
            "Epoch [1/1], Batch [2385/3134], Loss: 0.01183581\n",
            "Epoch [1/1], Batch [2386/3134], Loss: 0.01179826\n",
            "Epoch [1/1], Batch [2387/3134], Loss: 0.01177016\n",
            "Epoch [1/1], Batch [2388/3134], Loss: 0.01179968\n",
            "Epoch [1/1], Batch [2389/3134], Loss: 0.01177326\n",
            "Epoch [1/1], Batch [2390/3134], Loss: 0.01178620\n",
            "Epoch [1/1], Batch [2391/3134], Loss: 0.01181921\n",
            "Epoch [1/1], Batch [2392/3134], Loss: 0.01178062\n",
            "Epoch [1/1], Batch [2393/3134], Loss: 0.01178472\n",
            "Epoch [1/1], Batch [2394/3134], Loss: 0.01174035\n",
            "Epoch [1/1], Batch [2395/3134], Loss: 0.01177639\n",
            "Epoch [1/1], Batch [2396/3134], Loss: 0.01176486\n",
            "Epoch [1/1], Batch [2397/3134], Loss: 0.01175686\n",
            "Epoch [1/1], Batch [2398/3134], Loss: 0.01178377\n",
            "Epoch [1/1], Batch [2399/3134], Loss: 0.01180262\n",
            "Epoch [1/1], Batch [2400/3134], Loss: 0.01182996\n",
            "Epoch [1/1], Batch [2401/3134], Loss: 0.01174416\n",
            "Epoch [1/1], Batch [2402/3134], Loss: 0.01178429\n",
            "Epoch [1/1], Batch [2403/3134], Loss: 0.01179438\n",
            "Epoch [1/1], Batch [2404/3134], Loss: 0.01174428\n",
            "Epoch [1/1], Batch [2405/3134], Loss: 0.01173606\n",
            "Epoch [1/1], Batch [2406/3134], Loss: 0.01176871\n",
            "Epoch [1/1], Batch [2407/3134], Loss: 0.01175818\n",
            "Epoch [1/1], Batch [2408/3134], Loss: 0.01178323\n",
            "Epoch [1/1], Batch [2409/3134], Loss: 0.01179628\n",
            "Epoch [1/1], Batch [2410/3134], Loss: 0.01176797\n",
            "Epoch [1/1], Batch [2411/3134], Loss: 0.01179340\n",
            "Epoch [1/1], Batch [2412/3134], Loss: 0.01174267\n",
            "Epoch [1/1], Batch [2413/3134], Loss: 0.01176026\n",
            "Epoch [1/1], Batch [2414/3134], Loss: 0.01175618\n",
            "Epoch [1/1], Batch [2415/3134], Loss: 0.01173489\n",
            "Epoch [1/1], Batch [2416/3134], Loss: 0.01176069\n",
            "Epoch [1/1], Batch [2417/3134], Loss: 0.01174528\n",
            "Epoch [1/1], Batch [2418/3134], Loss: 0.01182209\n",
            "Epoch [1/1], Batch [2419/3134], Loss: 0.01179539\n",
            "Epoch [1/1], Batch [2420/3134], Loss: 0.01175618\n",
            "Epoch [1/1], Batch [2421/3134], Loss: 0.01171003\n",
            "Epoch [1/1], Batch [2422/3134], Loss: 0.01176289\n",
            "Epoch [1/1], Batch [2423/3134], Loss: 0.01176846\n",
            "Epoch [1/1], Batch [2424/3134], Loss: 0.01172992\n",
            "Epoch [1/1], Batch [2425/3134], Loss: 0.01176217\n",
            "Epoch [1/1], Batch [2426/3134], Loss: 0.01180720\n",
            "Epoch [1/1], Batch [2427/3134], Loss: 0.01170664\n",
            "Epoch [1/1], Batch [2428/3134], Loss: 0.01180486\n",
            "Epoch [1/1], Batch [2429/3134], Loss: 0.01183031\n",
            "Epoch [1/1], Batch [2430/3134], Loss: 0.01171944\n",
            "Epoch [1/1], Batch [2431/3134], Loss: 0.01174874\n",
            "Epoch [1/1], Batch [2432/3134], Loss: 0.01178121\n",
            "Epoch [1/1], Batch [2433/3134], Loss: 0.01178855\n",
            "Epoch [1/1], Batch [2434/3134], Loss: 0.01179038\n",
            "Epoch [1/1], Batch [2435/3134], Loss: 0.01174674\n",
            "Epoch [1/1], Batch [2436/3134], Loss: 0.01176154\n",
            "Epoch [1/1], Batch [2437/3134], Loss: 0.01172033\n",
            "Epoch [1/1], Batch [2438/3134], Loss: 0.01177731\n",
            "Epoch [1/1], Batch [2439/3134], Loss: 0.01174142\n",
            "Epoch [1/1], Batch [2440/3134], Loss: 0.01174925\n",
            "Epoch [1/1], Batch [2441/3134], Loss: 0.01180831\n",
            "Epoch [1/1], Batch [2442/3134], Loss: 0.01182048\n",
            "Epoch [1/1], Batch [2443/3134], Loss: 0.01181406\n",
            "Epoch [1/1], Batch [2444/3134], Loss: 0.01176819\n",
            "Epoch [1/1], Batch [2445/3134], Loss: 0.01178467\n",
            "Epoch [1/1], Batch [2446/3134], Loss: 0.01176691\n",
            "Epoch [1/1], Batch [2447/3134], Loss: 0.01174979\n",
            "Epoch [1/1], Batch [2448/3134], Loss: 0.01180281\n",
            "Epoch [1/1], Batch [2449/3134], Loss: 0.01175448\n",
            "Epoch [1/1], Batch [2450/3134], Loss: 0.01176641\n",
            "Epoch [1/1], Batch [2451/3134], Loss: 0.01179802\n",
            "Epoch [1/1], Batch [2452/3134], Loss: 0.01181333\n",
            "Epoch [1/1], Batch [2453/3134], Loss: 0.01178198\n",
            "Epoch [1/1], Batch [2454/3134], Loss: 0.01174727\n",
            "Epoch [1/1], Batch [2455/3134], Loss: 0.01180851\n",
            "Epoch [1/1], Batch [2456/3134], Loss: 0.01176066\n",
            "Epoch [1/1], Batch [2457/3134], Loss: 0.01183472\n",
            "Epoch [1/1], Batch [2458/3134], Loss: 0.01179558\n",
            "Epoch [1/1], Batch [2459/3134], Loss: 0.01180035\n",
            "Epoch [1/1], Batch [2460/3134], Loss: 0.01176835\n",
            "Epoch [1/1], Batch [2461/3134], Loss: 0.01181300\n",
            "Epoch [1/1], Batch [2462/3134], Loss: 0.01176670\n",
            "Epoch [1/1], Batch [2463/3134], Loss: 0.01176242\n",
            "Epoch [1/1], Batch [2464/3134], Loss: 0.01177506\n",
            "Epoch [1/1], Batch [2465/3134], Loss: 0.01179014\n",
            "Epoch [1/1], Batch [2466/3134], Loss: 0.01180571\n",
            "Epoch [1/1], Batch [2467/3134], Loss: 0.01180326\n",
            "Epoch [1/1], Batch [2468/3134], Loss: 0.01170671\n",
            "Epoch [1/1], Batch [2469/3134], Loss: 0.01177169\n",
            "Epoch [1/1], Batch [2470/3134], Loss: 0.01175696\n",
            "Epoch [1/1], Batch [2471/3134], Loss: 0.01176087\n",
            "Epoch [1/1], Batch [2472/3134], Loss: 0.01184033\n",
            "Epoch [1/1], Batch [2473/3134], Loss: 0.01179036\n",
            "Epoch [1/1], Batch [2474/3134], Loss: 0.01177783\n",
            "Epoch [1/1], Batch [2475/3134], Loss: 0.01177548\n",
            "Epoch [1/1], Batch [2476/3134], Loss: 0.01178220\n",
            "Epoch [1/1], Batch [2477/3134], Loss: 0.01175231\n",
            "Epoch [1/1], Batch [2478/3134], Loss: 0.01178830\n",
            "Epoch [1/1], Batch [2479/3134], Loss: 0.01178979\n",
            "Epoch [1/1], Batch [2480/3134], Loss: 0.01180272\n",
            "Epoch [1/1], Batch [2481/3134], Loss: 0.01182183\n",
            "Epoch [1/1], Batch [2482/3134], Loss: 0.01172638\n",
            "Epoch [1/1], Batch [2483/3134], Loss: 0.01178664\n",
            "Epoch [1/1], Batch [2484/3134], Loss: 0.01183920\n",
            "Epoch [1/1], Batch [2485/3134], Loss: 0.01173460\n",
            "Epoch [1/1], Batch [2486/3134], Loss: 0.01178274\n",
            "Epoch [1/1], Batch [2487/3134], Loss: 0.01183957\n",
            "Epoch [1/1], Batch [2488/3134], Loss: 0.01178550\n",
            "Epoch [1/1], Batch [2489/3134], Loss: 0.01181322\n",
            "Epoch [1/1], Batch [2490/3134], Loss: 0.01176685\n",
            "Epoch [1/1], Batch [2491/3134], Loss: 0.01179778\n",
            "Epoch [1/1], Batch [2492/3134], Loss: 0.01178333\n",
            "Epoch [1/1], Batch [2493/3134], Loss: 0.01175425\n",
            "Epoch [1/1], Batch [2494/3134], Loss: 0.01180790\n",
            "Epoch [1/1], Batch [2495/3134], Loss: 0.01174090\n",
            "Epoch [1/1], Batch [2496/3134], Loss: 0.01181185\n",
            "Epoch [1/1], Batch [2497/3134], Loss: 0.01176777\n",
            "Epoch [1/1], Batch [2498/3134], Loss: 0.01175184\n",
            "Epoch [1/1], Batch [2499/3134], Loss: 0.01177991\n",
            "Epoch [1/1], Batch [2500/3134], Loss: 0.01175220\n",
            "Epoch [1/1], Batch [2501/3134], Loss: 0.01174208\n",
            "Epoch [1/1], Batch [2502/3134], Loss: 0.01175667\n",
            "Epoch [1/1], Batch [2503/3134], Loss: 0.01173835\n",
            "Epoch [1/1], Batch [2504/3134], Loss: 0.01176118\n",
            "Epoch [1/1], Batch [2505/3134], Loss: 0.01180026\n",
            "Epoch [1/1], Batch [2506/3134], Loss: 0.01177327\n",
            "Epoch [1/1], Batch [2507/3134], Loss: 0.01179344\n",
            "Epoch [1/1], Batch [2508/3134], Loss: 0.01178804\n",
            "Epoch [1/1], Batch [2509/3134], Loss: 0.01180411\n",
            "Epoch [1/1], Batch [2510/3134], Loss: 0.01182448\n",
            "Epoch [1/1], Batch [2511/3134], Loss: 0.01180755\n",
            "Epoch [1/1], Batch [2512/3134], Loss: 0.01176594\n",
            "Epoch [1/1], Batch [2513/3134], Loss: 0.01177399\n",
            "Epoch [1/1], Batch [2514/3134], Loss: 0.01173221\n",
            "Epoch [1/1], Batch [2515/3134], Loss: 0.01175431\n",
            "Epoch [1/1], Batch [2516/3134], Loss: 0.01175491\n",
            "Epoch [1/1], Batch [2517/3134], Loss: 0.01176140\n",
            "Epoch [1/1], Batch [2518/3134], Loss: 0.01174824\n",
            "Epoch [1/1], Batch [2519/3134], Loss: 0.01180922\n",
            "Epoch [1/1], Batch [2520/3134], Loss: 0.01174711\n",
            "Epoch [1/1], Batch [2521/3134], Loss: 0.01180594\n",
            "Epoch [1/1], Batch [2522/3134], Loss: 0.01173933\n",
            "Epoch [1/1], Batch [2523/3134], Loss: 0.01175047\n",
            "Epoch [1/1], Batch [2524/3134], Loss: 0.01176572\n",
            "Epoch [1/1], Batch [2525/3134], Loss: 0.01175101\n",
            "Epoch [1/1], Batch [2526/3134], Loss: 0.01177535\n",
            "Epoch [1/1], Batch [2527/3134], Loss: 0.01182117\n",
            "Epoch [1/1], Batch [2528/3134], Loss: 0.01175797\n",
            "Epoch [1/1], Batch [2529/3134], Loss: 0.01181348\n",
            "Epoch [1/1], Batch [2530/3134], Loss: 0.01180427\n",
            "Epoch [1/1], Batch [2531/3134], Loss: 0.01179381\n",
            "Epoch [1/1], Batch [2532/3134], Loss: 0.01179660\n",
            "Epoch [1/1], Batch [2533/3134], Loss: 0.01180534\n",
            "Epoch [1/1], Batch [2534/3134], Loss: 0.01181231\n",
            "Epoch [1/1], Batch [2535/3134], Loss: 0.01179395\n",
            "Epoch [1/1], Batch [2536/3134], Loss: 0.01177246\n",
            "Epoch [1/1], Batch [2537/3134], Loss: 0.01173723\n",
            "Epoch [1/1], Batch [2538/3134], Loss: 0.01174402\n",
            "Epoch [1/1], Batch [2539/3134], Loss: 0.01172601\n",
            "Epoch [1/1], Batch [2540/3134], Loss: 0.01183256\n",
            "Epoch [1/1], Batch [2541/3134], Loss: 0.01173820\n",
            "Epoch [1/1], Batch [2542/3134], Loss: 0.01181764\n",
            "Epoch [1/1], Batch [2543/3134], Loss: 0.01173531\n",
            "Epoch [1/1], Batch [2544/3134], Loss: 0.01180144\n",
            "Epoch [1/1], Batch [2545/3134], Loss: 0.01176409\n",
            "Epoch [1/1], Batch [2546/3134], Loss: 0.01172386\n",
            "Epoch [1/1], Batch [2547/3134], Loss: 0.01175199\n",
            "Epoch [1/1], Batch [2548/3134], Loss: 0.01187390\n",
            "Epoch [1/1], Batch [2549/3134], Loss: 0.01178055\n",
            "Epoch [1/1], Batch [2550/3134], Loss: 0.01179727\n",
            "Epoch [1/1], Batch [2551/3134], Loss: 0.01171406\n",
            "Epoch [1/1], Batch [2552/3134], Loss: 0.01175603\n",
            "Epoch [1/1], Batch [2553/3134], Loss: 0.01174744\n",
            "Epoch [1/1], Batch [2554/3134], Loss: 0.01178813\n",
            "Epoch [1/1], Batch [2555/3134], Loss: 0.01182700\n",
            "Epoch [1/1], Batch [2556/3134], Loss: 0.01172843\n",
            "Epoch [1/1], Batch [2557/3134], Loss: 0.01176522\n",
            "Epoch [1/1], Batch [2558/3134], Loss: 0.01178075\n",
            "Epoch [1/1], Batch [2559/3134], Loss: 0.01176675\n",
            "Epoch [1/1], Batch [2560/3134], Loss: 0.01173868\n",
            "Epoch [1/1], Batch [2561/3134], Loss: 0.01176182\n",
            "Epoch [1/1], Batch [2562/3134], Loss: 0.01176904\n",
            "Epoch [1/1], Batch [2563/3134], Loss: 0.01173469\n",
            "Epoch [1/1], Batch [2564/3134], Loss: 0.01179384\n",
            "Epoch [1/1], Batch [2565/3134], Loss: 0.01178494\n",
            "Epoch [1/1], Batch [2566/3134], Loss: 0.01181274\n",
            "Epoch [1/1], Batch [2567/3134], Loss: 0.01172351\n",
            "Epoch [1/1], Batch [2568/3134], Loss: 0.01177905\n",
            "Epoch [1/1], Batch [2569/3134], Loss: 0.01180706\n",
            "Epoch [1/1], Batch [2570/3134], Loss: 0.01175346\n",
            "Epoch [1/1], Batch [2571/3134], Loss: 0.01180944\n",
            "Epoch [1/1], Batch [2572/3134], Loss: 0.01176690\n",
            "Epoch [1/1], Batch [2573/3134], Loss: 0.01182939\n",
            "Epoch [1/1], Batch [2574/3134], Loss: 0.01183131\n",
            "Epoch [1/1], Batch [2575/3134], Loss: 0.01178544\n",
            "Epoch [1/1], Batch [2576/3134], Loss: 0.01176755\n",
            "Epoch [1/1], Batch [2577/3134], Loss: 0.01180808\n",
            "Epoch [1/1], Batch [2578/3134], Loss: 0.01180908\n",
            "Epoch [1/1], Batch [2579/3134], Loss: 0.01175854\n",
            "Epoch [1/1], Batch [2580/3134], Loss: 0.01178986\n",
            "Epoch [1/1], Batch [2581/3134], Loss: 0.01178386\n",
            "Epoch [1/1], Batch [2582/3134], Loss: 0.01180581\n",
            "Epoch [1/1], Batch [2583/3134], Loss: 0.01179252\n",
            "Epoch [1/1], Batch [2584/3134], Loss: 0.01180085\n",
            "Epoch [1/1], Batch [2585/3134], Loss: 0.01181677\n",
            "Epoch [1/1], Batch [2586/3134], Loss: 0.01178022\n",
            "Epoch [1/1], Batch [2587/3134], Loss: 0.01173870\n",
            "Epoch [1/1], Batch [2588/3134], Loss: 0.01180458\n",
            "Epoch [1/1], Batch [2589/3134], Loss: 0.01174497\n",
            "Epoch [1/1], Batch [2590/3134], Loss: 0.01177186\n",
            "Epoch [1/1], Batch [2591/3134], Loss: 0.01177667\n",
            "Epoch [1/1], Batch [2592/3134], Loss: 0.01178267\n",
            "Epoch [1/1], Batch [2593/3134], Loss: 0.01182427\n",
            "Epoch [1/1], Batch [2594/3134], Loss: 0.01182111\n",
            "Epoch [1/1], Batch [2595/3134], Loss: 0.01180927\n",
            "Epoch [1/1], Batch [2596/3134], Loss: 0.01176314\n",
            "Epoch [1/1], Batch [2597/3134], Loss: 0.01176958\n",
            "Epoch [1/1], Batch [2598/3134], Loss: 0.01177965\n",
            "Epoch [1/1], Batch [2599/3134], Loss: 0.01177434\n",
            "Epoch [1/1], Batch [2600/3134], Loss: 0.01178460\n",
            "Epoch [1/1], Batch [2601/3134], Loss: 0.01181595\n",
            "Epoch [1/1], Batch [2602/3134], Loss: 0.01177885\n",
            "Epoch [1/1], Batch [2603/3134], Loss: 0.01175258\n",
            "Epoch [1/1], Batch [2604/3134], Loss: 0.01180344\n",
            "Epoch [1/1], Batch [2605/3134], Loss: 0.01179170\n",
            "Epoch [1/1], Batch [2606/3134], Loss: 0.01174627\n",
            "Epoch [1/1], Batch [2607/3134], Loss: 0.01173337\n",
            "Epoch [1/1], Batch [2608/3134], Loss: 0.01179199\n",
            "Epoch [1/1], Batch [2609/3134], Loss: 0.01179188\n",
            "Epoch [1/1], Batch [2610/3134], Loss: 0.01174796\n",
            "Epoch [1/1], Batch [2611/3134], Loss: 0.01176523\n",
            "Epoch [1/1], Batch [2612/3134], Loss: 0.01172440\n",
            "Epoch [1/1], Batch [2613/3134], Loss: 0.01178371\n",
            "Epoch [1/1], Batch [2614/3134], Loss: 0.01177871\n",
            "Epoch [1/1], Batch [2615/3134], Loss: 0.01170868\n",
            "Epoch [1/1], Batch [2616/3134], Loss: 0.01183765\n",
            "Epoch [1/1], Batch [2617/3134], Loss: 0.01177998\n",
            "Epoch [1/1], Batch [2618/3134], Loss: 0.01182275\n",
            "Epoch [1/1], Batch [2619/3134], Loss: 0.01179758\n",
            "Epoch [1/1], Batch [2620/3134], Loss: 0.01175082\n",
            "Epoch [1/1], Batch [2621/3134], Loss: 0.01175247\n",
            "Epoch [1/1], Batch [2622/3134], Loss: 0.01177931\n",
            "Epoch [1/1], Batch [2623/3134], Loss: 0.01180363\n",
            "Epoch [1/1], Batch [2624/3134], Loss: 0.01176760\n",
            "Epoch [1/1], Batch [2625/3134], Loss: 0.01175720\n",
            "Epoch [1/1], Batch [2626/3134], Loss: 0.01178487\n",
            "Epoch [1/1], Batch [2627/3134], Loss: 0.01179048\n",
            "Epoch [1/1], Batch [2628/3134], Loss: 0.01178436\n",
            "Epoch [1/1], Batch [2629/3134], Loss: 0.01181833\n",
            "Epoch [1/1], Batch [2630/3134], Loss: 0.01181025\n",
            "Epoch [1/1], Batch [2631/3134], Loss: 0.01179837\n",
            "Epoch [1/1], Batch [2632/3134], Loss: 0.01181427\n",
            "Epoch [1/1], Batch [2633/3134], Loss: 0.01177467\n",
            "Epoch [1/1], Batch [2634/3134], Loss: 0.01178610\n",
            "Epoch [1/1], Batch [2635/3134], Loss: 0.01171963\n",
            "Epoch [1/1], Batch [2636/3134], Loss: 0.01178095\n",
            "Epoch [1/1], Batch [2637/3134], Loss: 0.01179736\n",
            "Epoch [1/1], Batch [2638/3134], Loss: 0.01185173\n",
            "Epoch [1/1], Batch [2639/3134], Loss: 0.01176398\n",
            "Epoch [1/1], Batch [2640/3134], Loss: 0.01179891\n",
            "Epoch [1/1], Batch [2641/3134], Loss: 0.01178913\n",
            "Epoch [1/1], Batch [2642/3134], Loss: 0.01175440\n",
            "Epoch [1/1], Batch [2643/3134], Loss: 0.01179982\n",
            "Epoch [1/1], Batch [2644/3134], Loss: 0.01168787\n",
            "Epoch [1/1], Batch [2645/3134], Loss: 0.01178378\n",
            "Epoch [1/1], Batch [2646/3134], Loss: 0.01173001\n",
            "Epoch [1/1], Batch [2647/3134], Loss: 0.01177511\n",
            "Epoch [1/1], Batch [2648/3134], Loss: 0.01175948\n",
            "Epoch [1/1], Batch [2649/3134], Loss: 0.01179645\n",
            "Epoch [1/1], Batch [2650/3134], Loss: 0.01175816\n",
            "Epoch [1/1], Batch [2651/3134], Loss: 0.01176624\n",
            "Epoch [1/1], Batch [2652/3134], Loss: 0.01174407\n",
            "Epoch [1/1], Batch [2653/3134], Loss: 0.01171208\n",
            "Epoch [1/1], Batch [2654/3134], Loss: 0.01172612\n",
            "Epoch [1/1], Batch [2655/3134], Loss: 0.01178546\n",
            "Epoch [1/1], Batch [2656/3134], Loss: 0.01178460\n",
            "Epoch [1/1], Batch [2657/3134], Loss: 0.01168541\n",
            "Epoch [1/1], Batch [2658/3134], Loss: 0.01178795\n",
            "Epoch [1/1], Batch [2659/3134], Loss: 0.01172014\n",
            "Epoch [1/1], Batch [2660/3134], Loss: 0.01173457\n",
            "Epoch [1/1], Batch [2661/3134], Loss: 0.01179317\n",
            "Epoch [1/1], Batch [2662/3134], Loss: 0.01178216\n",
            "Epoch [1/1], Batch [2663/3134], Loss: 0.01170060\n",
            "Epoch [1/1], Batch [2664/3134], Loss: 0.01174890\n",
            "Epoch [1/1], Batch [2665/3134], Loss: 0.01176556\n",
            "Epoch [1/1], Batch [2666/3134], Loss: 0.01175882\n",
            "Epoch [1/1], Batch [2667/3134], Loss: 0.01177299\n",
            "Epoch [1/1], Batch [2668/3134], Loss: 0.01171118\n",
            "Epoch [1/1], Batch [2669/3134], Loss: 0.01183059\n",
            "Epoch [1/1], Batch [2670/3134], Loss: 0.01178860\n",
            "Epoch [1/1], Batch [2671/3134], Loss: 0.01179549\n",
            "Epoch [1/1], Batch [2672/3134], Loss: 0.01177214\n",
            "Epoch [1/1], Batch [2673/3134], Loss: 0.01182851\n",
            "Epoch [1/1], Batch [2674/3134], Loss: 0.01176814\n",
            "Epoch [1/1], Batch [2675/3134], Loss: 0.01178307\n",
            "Epoch [1/1], Batch [2676/3134], Loss: 0.01173326\n",
            "Epoch [1/1], Batch [2677/3134], Loss: 0.01180381\n",
            "Epoch [1/1], Batch [2678/3134], Loss: 0.01178239\n",
            "Epoch [1/1], Batch [2679/3134], Loss: 0.01176856\n",
            "Epoch [1/1], Batch [2680/3134], Loss: 0.01172983\n",
            "Epoch [1/1], Batch [2681/3134], Loss: 0.01174626\n",
            "Epoch [1/1], Batch [2682/3134], Loss: 0.01179067\n",
            "Epoch [1/1], Batch [2683/3134], Loss: 0.01174486\n",
            "Epoch [1/1], Batch [2684/3134], Loss: 0.01179457\n",
            "Epoch [1/1], Batch [2685/3134], Loss: 0.01178068\n",
            "Epoch [1/1], Batch [2686/3134], Loss: 0.01179830\n",
            "Epoch [1/1], Batch [2687/3134], Loss: 0.01176654\n",
            "Epoch [1/1], Batch [2688/3134], Loss: 0.01172349\n",
            "Epoch [1/1], Batch [2689/3134], Loss: 0.01181342\n",
            "Epoch [1/1], Batch [2690/3134], Loss: 0.01176014\n",
            "Epoch [1/1], Batch [2691/3134], Loss: 0.01178573\n",
            "Epoch [1/1], Batch [2692/3134], Loss: 0.01175873\n",
            "Epoch [1/1], Batch [2693/3134], Loss: 0.01175441\n",
            "Epoch [1/1], Batch [2694/3134], Loss: 0.01178552\n",
            "Epoch [1/1], Batch [2695/3134], Loss: 0.01173606\n",
            "Epoch [1/1], Batch [2696/3134], Loss: 0.01175608\n",
            "Epoch [1/1], Batch [2697/3134], Loss: 0.01180584\n",
            "Epoch [1/1], Batch [2698/3134], Loss: 0.01178345\n",
            "Epoch [1/1], Batch [2699/3134], Loss: 0.01182269\n",
            "Epoch [1/1], Batch [2700/3134], Loss: 0.01175675\n",
            "Epoch [1/1], Batch [2701/3134], Loss: 0.01172834\n",
            "Epoch [1/1], Batch [2702/3134], Loss: 0.01179560\n",
            "Epoch [1/1], Batch [2703/3134], Loss: 0.01172694\n",
            "Epoch [1/1], Batch [2704/3134], Loss: 0.01175679\n",
            "Epoch [1/1], Batch [2705/3134], Loss: 0.01174662\n",
            "Epoch [1/1], Batch [2706/3134], Loss: 0.01180029\n",
            "Epoch [1/1], Batch [2707/3134], Loss: 0.01179670\n",
            "Epoch [1/1], Batch [2708/3134], Loss: 0.01175888\n",
            "Epoch [1/1], Batch [2709/3134], Loss: 0.01173955\n",
            "Epoch [1/1], Batch [2710/3134], Loss: 0.01174504\n",
            "Epoch [1/1], Batch [2711/3134], Loss: 0.01176162\n",
            "Epoch [1/1], Batch [2712/3134], Loss: 0.01177931\n",
            "Epoch [1/1], Batch [2713/3134], Loss: 0.01180365\n",
            "Epoch [1/1], Batch [2714/3134], Loss: 0.01179650\n",
            "Epoch [1/1], Batch [2715/3134], Loss: 0.01175099\n",
            "Epoch [1/1], Batch [2716/3134], Loss: 0.01171667\n",
            "Epoch [1/1], Batch [2717/3134], Loss: 0.01177151\n",
            "Epoch [1/1], Batch [2718/3134], Loss: 0.01178833\n",
            "Epoch [1/1], Batch [2719/3134], Loss: 0.01178815\n",
            "Epoch [1/1], Batch [2720/3134], Loss: 0.01174567\n",
            "Epoch [1/1], Batch [2721/3134], Loss: 0.01174029\n",
            "Epoch [1/1], Batch [2722/3134], Loss: 0.01182151\n",
            "Epoch [1/1], Batch [2723/3134], Loss: 0.01171801\n",
            "Epoch [1/1], Batch [2724/3134], Loss: 0.01183303\n",
            "Epoch [1/1], Batch [2725/3134], Loss: 0.01176099\n",
            "Epoch [1/1], Batch [2726/3134], Loss: 0.01175505\n",
            "Epoch [1/1], Batch [2727/3134], Loss: 0.01177282\n",
            "Epoch [1/1], Batch [2728/3134], Loss: 0.01177289\n",
            "Epoch [1/1], Batch [2729/3134], Loss: 0.01176703\n",
            "Epoch [1/1], Batch [2730/3134], Loss: 0.01176475\n",
            "Epoch [1/1], Batch [2731/3134], Loss: 0.01179533\n",
            "Epoch [1/1], Batch [2732/3134], Loss: 0.01174606\n",
            "Epoch [1/1], Batch [2733/3134], Loss: 0.01174600\n",
            "Epoch [1/1], Batch [2734/3134], Loss: 0.01179288\n",
            "Epoch [1/1], Batch [2735/3134], Loss: 0.01176317\n",
            "Epoch [1/1], Batch [2736/3134], Loss: 0.01178196\n",
            "Epoch [1/1], Batch [2737/3134], Loss: 0.01172537\n",
            "Epoch [1/1], Batch [2738/3134], Loss: 0.01178111\n",
            "Epoch [1/1], Batch [2739/3134], Loss: 0.01178078\n",
            "Epoch [1/1], Batch [2740/3134], Loss: 0.01174009\n",
            "Epoch [1/1], Batch [2741/3134], Loss: 0.01178313\n",
            "Epoch [1/1], Batch [2742/3134], Loss: 0.01164636\n",
            "Epoch [1/1], Batch [2743/3134], Loss: 0.01175843\n",
            "Epoch [1/1], Batch [2744/3134], Loss: 0.01176871\n",
            "Epoch [1/1], Batch [2745/3134], Loss: 0.01180410\n",
            "Epoch [1/1], Batch [2746/3134], Loss: 0.01178376\n",
            "Epoch [1/1], Batch [2747/3134], Loss: 0.01181932\n",
            "Epoch [1/1], Batch [2748/3134], Loss: 0.01180516\n",
            "Epoch [1/1], Batch [2749/3134], Loss: 0.01175348\n",
            "Epoch [1/1], Batch [2750/3134], Loss: 0.01177213\n",
            "Epoch [1/1], Batch [2751/3134], Loss: 0.01177863\n",
            "Epoch [1/1], Batch [2752/3134], Loss: 0.01175671\n",
            "Epoch [1/1], Batch [2753/3134], Loss: 0.01178538\n",
            "Epoch [1/1], Batch [2754/3134], Loss: 0.01180675\n",
            "Epoch [1/1], Batch [2755/3134], Loss: 0.01173977\n",
            "Epoch [1/1], Batch [2756/3134], Loss: 0.01174867\n",
            "Epoch [1/1], Batch [2757/3134], Loss: 0.01177482\n",
            "Epoch [1/1], Batch [2758/3134], Loss: 0.01172020\n",
            "Epoch [1/1], Batch [2759/3134], Loss: 0.01173664\n",
            "Epoch [1/1], Batch [2760/3134], Loss: 0.01177541\n",
            "Epoch [1/1], Batch [2761/3134], Loss: 0.01180490\n",
            "Epoch [1/1], Batch [2762/3134], Loss: 0.01172901\n",
            "Epoch [1/1], Batch [2763/3134], Loss: 0.01178183\n",
            "Epoch [1/1], Batch [2764/3134], Loss: 0.01174769\n",
            "Epoch [1/1], Batch [2765/3134], Loss: 0.01174601\n",
            "Epoch [1/1], Batch [2766/3134], Loss: 0.01177652\n",
            "Epoch [1/1], Batch [2767/3134], Loss: 0.01170541\n",
            "Epoch [1/1], Batch [2768/3134], Loss: 0.01169107\n",
            "Epoch [1/1], Batch [2769/3134], Loss: 0.01177651\n",
            "Epoch [1/1], Batch [2770/3134], Loss: 0.01175288\n",
            "Epoch [1/1], Batch [2771/3134], Loss: 0.01177116\n",
            "Epoch [1/1], Batch [2772/3134], Loss: 0.01177859\n",
            "Epoch [1/1], Batch [2773/3134], Loss: 0.01181918\n",
            "Epoch [1/1], Batch [2774/3134], Loss: 0.01185270\n",
            "Epoch [1/1], Batch [2775/3134], Loss: 0.01175210\n",
            "Epoch [1/1], Batch [2776/3134], Loss: 0.01175370\n",
            "Epoch [1/1], Batch [2777/3134], Loss: 0.01177737\n",
            "Epoch [1/1], Batch [2778/3134], Loss: 0.01172553\n",
            "Epoch [1/1], Batch [2779/3134], Loss: 0.01177164\n",
            "Epoch [1/1], Batch [2780/3134], Loss: 0.01180026\n",
            "Epoch [1/1], Batch [2781/3134], Loss: 0.01174011\n",
            "Epoch [1/1], Batch [2782/3134], Loss: 0.01173700\n",
            "Epoch [1/1], Batch [2783/3134], Loss: 0.01172984\n",
            "Epoch [1/1], Batch [2784/3134], Loss: 0.01178849\n",
            "Epoch [1/1], Batch [2785/3134], Loss: 0.01178327\n",
            "Epoch [1/1], Batch [2786/3134], Loss: 0.01176496\n",
            "Epoch [1/1], Batch [2787/3134], Loss: 0.01174658\n",
            "Epoch [1/1], Batch [2788/3134], Loss: 0.01171260\n",
            "Epoch [1/1], Batch [2789/3134], Loss: 0.01176312\n",
            "Epoch [1/1], Batch [2790/3134], Loss: 0.01174446\n",
            "Epoch [1/1], Batch [2791/3134], Loss: 0.01179694\n",
            "Epoch [1/1], Batch [2792/3134], Loss: 0.01174580\n",
            "Epoch [1/1], Batch [2793/3134], Loss: 0.01180001\n",
            "Epoch [1/1], Batch [2794/3134], Loss: 0.01181515\n",
            "Epoch [1/1], Batch [2795/3134], Loss: 0.01182568\n",
            "Epoch [1/1], Batch [2796/3134], Loss: 0.01186928\n",
            "Epoch [1/1], Batch [2797/3134], Loss: 0.01183366\n",
            "Epoch [1/1], Batch [2798/3134], Loss: 0.01179315\n",
            "Epoch [1/1], Batch [2799/3134], Loss: 0.01174985\n",
            "Epoch [1/1], Batch [2800/3134], Loss: 0.01174788\n",
            "Epoch [1/1], Batch [2801/3134], Loss: 0.01176092\n",
            "Epoch [1/1], Batch [2802/3134], Loss: 0.01183024\n",
            "Epoch [1/1], Batch [2803/3134], Loss: 0.01171346\n",
            "Epoch [1/1], Batch [2804/3134], Loss: 0.01176639\n",
            "Epoch [1/1], Batch [2805/3134], Loss: 0.01173811\n",
            "Epoch [1/1], Batch [2806/3134], Loss: 0.01181812\n",
            "Epoch [1/1], Batch [2807/3134], Loss: 0.01174228\n",
            "Epoch [1/1], Batch [2808/3134], Loss: 0.01181399\n",
            "Epoch [1/1], Batch [2809/3134], Loss: 0.01175520\n",
            "Epoch [1/1], Batch [2810/3134], Loss: 0.01180630\n",
            "Epoch [1/1], Batch [2811/3134], Loss: 0.01178007\n",
            "Epoch [1/1], Batch [2812/3134], Loss: 0.01179452\n",
            "Epoch [1/1], Batch [2813/3134], Loss: 0.01183593\n",
            "Epoch [1/1], Batch [2814/3134], Loss: 0.01175874\n",
            "Epoch [1/1], Batch [2815/3134], Loss: 0.01174947\n",
            "Epoch [1/1], Batch [2816/3134], Loss: 0.01173916\n",
            "Epoch [1/1], Batch [2817/3134], Loss: 0.01176254\n",
            "Epoch [1/1], Batch [2818/3134], Loss: 0.01177061\n",
            "Epoch [1/1], Batch [2819/3134], Loss: 0.01177018\n",
            "Epoch [1/1], Batch [2820/3134], Loss: 0.01177524\n",
            "Epoch [1/1], Batch [2821/3134], Loss: 0.01175059\n",
            "Epoch [1/1], Batch [2822/3134], Loss: 0.01171369\n",
            "Epoch [1/1], Batch [2823/3134], Loss: 0.01171833\n",
            "Epoch [1/1], Batch [2824/3134], Loss: 0.01182140\n",
            "Epoch [1/1], Batch [2825/3134], Loss: 0.01178432\n",
            "Epoch [1/1], Batch [2826/3134], Loss: 0.01177420\n",
            "Epoch [1/1], Batch [2827/3134], Loss: 0.01173305\n",
            "Epoch [1/1], Batch [2828/3134], Loss: 0.01179995\n",
            "Epoch [1/1], Batch [2829/3134], Loss: 0.01178571\n",
            "Epoch [1/1], Batch [2830/3134], Loss: 0.01180828\n",
            "Epoch [1/1], Batch [2831/3134], Loss: 0.01174004\n",
            "Epoch [1/1], Batch [2832/3134], Loss: 0.01175432\n",
            "Epoch [1/1], Batch [2833/3134], Loss: 0.01174989\n",
            "Epoch [1/1], Batch [2834/3134], Loss: 0.01180756\n",
            "Epoch [1/1], Batch [2835/3134], Loss: 0.01174975\n",
            "Epoch [1/1], Batch [2836/3134], Loss: 0.01168363\n",
            "Epoch [1/1], Batch [2837/3134], Loss: 0.01174906\n",
            "Epoch [1/1], Batch [2838/3134], Loss: 0.01178969\n",
            "Epoch [1/1], Batch [2839/3134], Loss: 0.01172665\n",
            "Epoch [1/1], Batch [2840/3134], Loss: 0.01175482\n",
            "Epoch [1/1], Batch [2841/3134], Loss: 0.01177973\n",
            "Epoch [1/1], Batch [2842/3134], Loss: 0.01172990\n",
            "Epoch [1/1], Batch [2843/3134], Loss: 0.01178723\n",
            "Epoch [1/1], Batch [2844/3134], Loss: 0.01174792\n",
            "Epoch [1/1], Batch [2845/3134], Loss: 0.01174106\n",
            "Epoch [1/1], Batch [2846/3134], Loss: 0.01173592\n",
            "Epoch [1/1], Batch [2847/3134], Loss: 0.01175016\n",
            "Epoch [1/1], Batch [2848/3134], Loss: 0.01170516\n",
            "Epoch [1/1], Batch [2849/3134], Loss: 0.01178616\n",
            "Epoch [1/1], Batch [2850/3134], Loss: 0.01175192\n",
            "Epoch [1/1], Batch [2851/3134], Loss: 0.01177666\n",
            "Epoch [1/1], Batch [2852/3134], Loss: 0.01172851\n",
            "Epoch [1/1], Batch [2853/3134], Loss: 0.01175177\n",
            "Epoch [1/1], Batch [2854/3134], Loss: 0.01175480\n",
            "Epoch [1/1], Batch [2855/3134], Loss: 0.01175831\n",
            "Epoch [1/1], Batch [2856/3134], Loss: 0.01179613\n",
            "Epoch [1/1], Batch [2857/3134], Loss: 0.01176459\n",
            "Epoch [1/1], Batch [2858/3134], Loss: 0.01175053\n",
            "Epoch [1/1], Batch [2859/3134], Loss: 0.01174236\n",
            "Epoch [1/1], Batch [2860/3134], Loss: 0.01177076\n",
            "Epoch [1/1], Batch [2861/3134], Loss: 0.01179347\n",
            "Epoch [1/1], Batch [2862/3134], Loss: 0.01180070\n",
            "Epoch [1/1], Batch [2863/3134], Loss: 0.01176460\n",
            "Epoch [1/1], Batch [2864/3134], Loss: 0.01173903\n",
            "Epoch [1/1], Batch [2865/3134], Loss: 0.01174546\n",
            "Epoch [1/1], Batch [2866/3134], Loss: 0.01173869\n",
            "Epoch [1/1], Batch [2867/3134], Loss: 0.01173983\n",
            "Epoch [1/1], Batch [2868/3134], Loss: 0.01178562\n",
            "Epoch [1/1], Batch [2869/3134], Loss: 0.01179193\n",
            "Epoch [1/1], Batch [2870/3134], Loss: 0.01175514\n",
            "Epoch [1/1], Batch [2871/3134], Loss: 0.01175697\n",
            "Epoch [1/1], Batch [2872/3134], Loss: 0.01172253\n",
            "Epoch [1/1], Batch [2873/3134], Loss: 0.01181393\n",
            "Epoch [1/1], Batch [2874/3134], Loss: 0.01179398\n",
            "Epoch [1/1], Batch [2875/3134], Loss: 0.01171908\n",
            "Epoch [1/1], Batch [2876/3134], Loss: 0.01177214\n",
            "Epoch [1/1], Batch [2877/3134], Loss: 0.01175861\n",
            "Epoch [1/1], Batch [2878/3134], Loss: 0.01173549\n",
            "Epoch [1/1], Batch [2879/3134], Loss: 0.01172585\n",
            "Epoch [1/1], Batch [2880/3134], Loss: 0.01178204\n",
            "Epoch [1/1], Batch [2881/3134], Loss: 0.01172132\n",
            "Epoch [1/1], Batch [2882/3134], Loss: 0.01180023\n",
            "Epoch [1/1], Batch [2883/3134], Loss: 0.01174941\n",
            "Epoch [1/1], Batch [2884/3134], Loss: 0.01179941\n",
            "Epoch [1/1], Batch [2885/3134], Loss: 0.01172168\n",
            "Epoch [1/1], Batch [2886/3134], Loss: 0.01178141\n",
            "Epoch [1/1], Batch [2887/3134], Loss: 0.01171038\n",
            "Epoch [1/1], Batch [2888/3134], Loss: 0.01175245\n",
            "Epoch [1/1], Batch [2889/3134], Loss: 0.01181162\n",
            "Epoch [1/1], Batch [2890/3134], Loss: 0.01174464\n",
            "Epoch [1/1], Batch [2891/3134], Loss: 0.01178067\n",
            "Epoch [1/1], Batch [2892/3134], Loss: 0.01174750\n",
            "Epoch [1/1], Batch [2893/3134], Loss: 0.01177337\n",
            "Epoch [1/1], Batch [2894/3134], Loss: 0.01174147\n",
            "Epoch [1/1], Batch [2895/3134], Loss: 0.01177515\n",
            "Epoch [1/1], Batch [2896/3134], Loss: 0.01178375\n",
            "Epoch [1/1], Batch [2897/3134], Loss: 0.01169131\n",
            "Epoch [1/1], Batch [2898/3134], Loss: 0.01173496\n",
            "Epoch [1/1], Batch [2899/3134], Loss: 0.01176694\n",
            "Epoch [1/1], Batch [2900/3134], Loss: 0.01180658\n",
            "Epoch [1/1], Batch [2901/3134], Loss: 0.01175985\n",
            "Epoch [1/1], Batch [2902/3134], Loss: 0.01178576\n",
            "Epoch [1/1], Batch [2903/3134], Loss: 0.01176022\n",
            "Epoch [1/1], Batch [2904/3134], Loss: 0.01176364\n",
            "Epoch [1/1], Batch [2905/3134], Loss: 0.01178724\n",
            "Epoch [1/1], Batch [2906/3134], Loss: 0.01173407\n",
            "Epoch [1/1], Batch [2907/3134], Loss: 0.01175124\n",
            "Epoch [1/1], Batch [2908/3134], Loss: 0.01173675\n",
            "Epoch [1/1], Batch [2909/3134], Loss: 0.01179768\n",
            "Epoch [1/1], Batch [2910/3134], Loss: 0.01175716\n",
            "Epoch [1/1], Batch [2911/3134], Loss: 0.01176339\n",
            "Epoch [1/1], Batch [2912/3134], Loss: 0.01171631\n",
            "Epoch [1/1], Batch [2913/3134], Loss: 0.01179902\n",
            "Epoch [1/1], Batch [2914/3134], Loss: 0.01171308\n",
            "Epoch [1/1], Batch [2915/3134], Loss: 0.01172014\n",
            "Epoch [1/1], Batch [2916/3134], Loss: 0.01174847\n",
            "Epoch [1/1], Batch [2917/3134], Loss: 0.01176179\n",
            "Epoch [1/1], Batch [2918/3134], Loss: 0.01178988\n",
            "Epoch [1/1], Batch [2919/3134], Loss: 0.01176559\n",
            "Epoch [1/1], Batch [2920/3134], Loss: 0.01180671\n",
            "Epoch [1/1], Batch [2921/3134], Loss: 0.01176325\n",
            "Epoch [1/1], Batch [2922/3134], Loss: 0.01176872\n",
            "Epoch [1/1], Batch [2923/3134], Loss: 0.01172561\n",
            "Epoch [1/1], Batch [2924/3134], Loss: 0.01175329\n",
            "Epoch [1/1], Batch [2925/3134], Loss: 0.01178597\n",
            "Epoch [1/1], Batch [2926/3134], Loss: 0.01173382\n",
            "Epoch [1/1], Batch [2927/3134], Loss: 0.01177634\n",
            "Epoch [1/1], Batch [2928/3134], Loss: 0.01175917\n",
            "Epoch [1/1], Batch [2929/3134], Loss: 0.01174166\n",
            "Epoch [1/1], Batch [2930/3134], Loss: 0.01177942\n",
            "Epoch [1/1], Batch [2931/3134], Loss: 0.01174903\n",
            "Epoch [1/1], Batch [2932/3134], Loss: 0.01173668\n",
            "Epoch [1/1], Batch [2933/3134], Loss: 0.01170022\n",
            "Epoch [1/1], Batch [2934/3134], Loss: 0.01171801\n",
            "Epoch [1/1], Batch [2935/3134], Loss: 0.01175929\n",
            "Epoch [1/1], Batch [2936/3134], Loss: 0.01179373\n",
            "Epoch [1/1], Batch [2937/3134], Loss: 0.01177717\n",
            "Epoch [1/1], Batch [2938/3134], Loss: 0.01176428\n",
            "Epoch [1/1], Batch [2939/3134], Loss: 0.01183505\n",
            "Epoch [1/1], Batch [2940/3134], Loss: 0.01174738\n",
            "Epoch [1/1], Batch [2941/3134], Loss: 0.01179918\n",
            "Epoch [1/1], Batch [2942/3134], Loss: 0.01175150\n",
            "Epoch [1/1], Batch [2943/3134], Loss: 0.01180063\n",
            "Epoch [1/1], Batch [2944/3134], Loss: 0.01179847\n",
            "Epoch [1/1], Batch [2945/3134], Loss: 0.01175524\n",
            "Epoch [1/1], Batch [2946/3134], Loss: 0.01175138\n",
            "Epoch [1/1], Batch [2947/3134], Loss: 0.01176984\n",
            "Epoch [1/1], Batch [2948/3134], Loss: 0.01176616\n",
            "Epoch [1/1], Batch [2949/3134], Loss: 0.01173844\n",
            "Epoch [1/1], Batch [2950/3134], Loss: 0.01176376\n",
            "Epoch [1/1], Batch [2951/3134], Loss: 0.01178632\n",
            "Epoch [1/1], Batch [2952/3134], Loss: 0.01182007\n",
            "Epoch [1/1], Batch [2953/3134], Loss: 0.01176945\n",
            "Epoch [1/1], Batch [2954/3134], Loss: 0.01177180\n",
            "Epoch [1/1], Batch [2955/3134], Loss: 0.01180175\n",
            "Epoch [1/1], Batch [2956/3134], Loss: 0.01179458\n",
            "Epoch [1/1], Batch [2957/3134], Loss: 0.01176867\n",
            "Epoch [1/1], Batch [2958/3134], Loss: 0.01178289\n",
            "Epoch [1/1], Batch [2959/3134], Loss: 0.01172696\n",
            "Epoch [1/1], Batch [2960/3134], Loss: 0.01178540\n",
            "Epoch [1/1], Batch [2961/3134], Loss: 0.01177930\n",
            "Epoch [1/1], Batch [2962/3134], Loss: 0.01172561\n",
            "Epoch [1/1], Batch [2963/3134], Loss: 0.01174702\n",
            "Epoch [1/1], Batch [2964/3134], Loss: 0.01176599\n",
            "Epoch [1/1], Batch [2965/3134], Loss: 0.01180107\n",
            "Epoch [1/1], Batch [2966/3134], Loss: 0.01176549\n",
            "Epoch [1/1], Batch [2967/3134], Loss: 0.01172173\n",
            "Epoch [1/1], Batch [2968/3134], Loss: 0.01173800\n",
            "Epoch [1/1], Batch [2969/3134], Loss: 0.01180378\n",
            "Epoch [1/1], Batch [2970/3134], Loss: 0.01178327\n",
            "Epoch [1/1], Batch [2971/3134], Loss: 0.01178153\n",
            "Epoch [1/1], Batch [2972/3134], Loss: 0.01172754\n",
            "Epoch [1/1], Batch [2973/3134], Loss: 0.01174595\n",
            "Epoch [1/1], Batch [2974/3134], Loss: 0.01174390\n",
            "Epoch [1/1], Batch [2975/3134], Loss: 0.01180069\n",
            "Epoch [1/1], Batch [2976/3134], Loss: 0.01177682\n",
            "Epoch [1/1], Batch [2977/3134], Loss: 0.01180063\n",
            "Epoch [1/1], Batch [2978/3134], Loss: 0.01176486\n",
            "Epoch [1/1], Batch [2979/3134], Loss: 0.01176694\n",
            "Epoch [1/1], Batch [2980/3134], Loss: 0.01176213\n",
            "Epoch [1/1], Batch [2981/3134], Loss: 0.01177324\n",
            "Epoch [1/1], Batch [2982/3134], Loss: 0.01172730\n",
            "Epoch [1/1], Batch [2983/3134], Loss: 0.01180633\n",
            "Epoch [1/1], Batch [2984/3134], Loss: 0.01183960\n",
            "Epoch [1/1], Batch [2985/3134], Loss: 0.01177738\n",
            "Epoch [1/1], Batch [2986/3134], Loss: 0.01177464\n",
            "Epoch [1/1], Batch [2987/3134], Loss: 0.01176578\n",
            "Epoch [1/1], Batch [2988/3134], Loss: 0.01176338\n",
            "Epoch [1/1], Batch [2989/3134], Loss: 0.01180158\n",
            "Epoch [1/1], Batch [2990/3134], Loss: 0.01179107\n",
            "Epoch [1/1], Batch [2991/3134], Loss: 0.01176079\n",
            "Epoch [1/1], Batch [2992/3134], Loss: 0.01176380\n",
            "Epoch [1/1], Batch [2993/3134], Loss: 0.01178158\n",
            "Epoch [1/1], Batch [2994/3134], Loss: 0.01175665\n",
            "Epoch [1/1], Batch [2995/3134], Loss: 0.01179102\n",
            "Epoch [1/1], Batch [2996/3134], Loss: 0.01178230\n",
            "Epoch [1/1], Batch [2997/3134], Loss: 0.01175695\n",
            "Epoch [1/1], Batch [2998/3134], Loss: 0.01177607\n",
            "Epoch [1/1], Batch [2999/3134], Loss: 0.01187294\n",
            "Epoch [1/1], Batch [3000/3134], Loss: 0.01173039\n",
            "Epoch [1/1], Batch [3001/3134], Loss: 0.01171261\n",
            "Epoch [1/1], Batch [3002/3134], Loss: 0.01175946\n",
            "Epoch [1/1], Batch [3003/3134], Loss: 0.01174595\n",
            "Epoch [1/1], Batch [3004/3134], Loss: 0.01175713\n",
            "Epoch [1/1], Batch [3005/3134], Loss: 0.01174895\n",
            "Epoch [1/1], Batch [3006/3134], Loss: 0.01182547\n",
            "Epoch [1/1], Batch [3007/3134], Loss: 0.01173741\n",
            "Epoch [1/1], Batch [3008/3134], Loss: 0.01181067\n",
            "Epoch [1/1], Batch [3009/3134], Loss: 0.01179349\n",
            "Epoch [1/1], Batch [3010/3134], Loss: 0.01179756\n",
            "Epoch [1/1], Batch [3011/3134], Loss: 0.01173629\n",
            "Epoch [1/1], Batch [3012/3134], Loss: 0.01171860\n",
            "Epoch [1/1], Batch [3013/3134], Loss: 0.01174400\n",
            "Epoch [1/1], Batch [3014/3134], Loss: 0.01177774\n",
            "Epoch [1/1], Batch [3015/3134], Loss: 0.01175071\n",
            "Epoch [1/1], Batch [3016/3134], Loss: 0.01178598\n",
            "Epoch [1/1], Batch [3017/3134], Loss: 0.01173842\n",
            "Epoch [1/1], Batch [3018/3134], Loss: 0.01175929\n",
            "Epoch [1/1], Batch [3019/3134], Loss: 0.01181772\n",
            "Epoch [1/1], Batch [3020/3134], Loss: 0.01170109\n",
            "Epoch [1/1], Batch [3021/3134], Loss: 0.01178287\n",
            "Epoch [1/1], Batch [3022/3134], Loss: 0.01176546\n",
            "Epoch [1/1], Batch [3023/3134], Loss: 0.01174260\n",
            "Epoch [1/1], Batch [3024/3134], Loss: 0.01171637\n",
            "Epoch [1/1], Batch [3025/3134], Loss: 0.01175990\n",
            "Epoch [1/1], Batch [3026/3134], Loss: 0.01170945\n",
            "Epoch [1/1], Batch [3027/3134], Loss: 0.01173604\n",
            "Epoch [1/1], Batch [3028/3134], Loss: 0.01179937\n",
            "Epoch [1/1], Batch [3029/3134], Loss: 0.01170799\n",
            "Epoch [1/1], Batch [3030/3134], Loss: 0.01180540\n",
            "Epoch [1/1], Batch [3031/3134], Loss: 0.01181949\n",
            "Epoch [1/1], Batch [3032/3134], Loss: 0.01173505\n",
            "Epoch [1/1], Batch [3033/3134], Loss: 0.01176314\n",
            "Epoch [1/1], Batch [3034/3134], Loss: 0.01177318\n",
            "Epoch [1/1], Batch [3035/3134], Loss: 0.01176431\n",
            "Epoch [1/1], Batch [3036/3134], Loss: 0.01178486\n",
            "Epoch [1/1], Batch [3037/3134], Loss: 0.01172871\n",
            "Epoch [1/1], Batch [3038/3134], Loss: 0.01179359\n",
            "Epoch [1/1], Batch [3039/3134], Loss: 0.01180612\n",
            "Epoch [1/1], Batch [3040/3134], Loss: 0.01170501\n",
            "Epoch [1/1], Batch [3041/3134], Loss: 0.01177591\n",
            "Epoch [1/1], Batch [3042/3134], Loss: 0.01176850\n",
            "Epoch [1/1], Batch [3043/3134], Loss: 0.01174580\n",
            "Epoch [1/1], Batch [3044/3134], Loss: 0.01180321\n",
            "Epoch [1/1], Batch [3045/3134], Loss: 0.01178369\n",
            "Epoch [1/1], Batch [3046/3134], Loss: 0.01182003\n",
            "Epoch [1/1], Batch [3047/3134], Loss: 0.01175540\n",
            "Epoch [1/1], Batch [3048/3134], Loss: 0.01175168\n",
            "Epoch [1/1], Batch [3049/3134], Loss: 0.01173578\n",
            "Epoch [1/1], Batch [3050/3134], Loss: 0.01175434\n",
            "Epoch [1/1], Batch [3051/3134], Loss: 0.01173197\n",
            "Epoch [1/1], Batch [3052/3134], Loss: 0.01174966\n",
            "Epoch [1/1], Batch [3053/3134], Loss: 0.01175799\n",
            "Epoch [1/1], Batch [3054/3134], Loss: 0.01177698\n",
            "Epoch [1/1], Batch [3055/3134], Loss: 0.01169689\n",
            "Epoch [1/1], Batch [3056/3134], Loss: 0.01173383\n",
            "Epoch [1/1], Batch [3057/3134], Loss: 0.01178042\n",
            "Epoch [1/1], Batch [3058/3134], Loss: 0.01172943\n",
            "Epoch [1/1], Batch [3059/3134], Loss: 0.01180314\n",
            "Epoch [1/1], Batch [3060/3134], Loss: 0.01175773\n",
            "Epoch [1/1], Batch [3061/3134], Loss: 0.01179523\n",
            "Epoch [1/1], Batch [3062/3134], Loss: 0.01181747\n",
            "Epoch [1/1], Batch [3063/3134], Loss: 0.01176418\n",
            "Epoch [1/1], Batch [3064/3134], Loss: 0.01178901\n",
            "Epoch [1/1], Batch [3065/3134], Loss: 0.01173426\n",
            "Epoch [1/1], Batch [3066/3134], Loss: 0.01178328\n",
            "Epoch [1/1], Batch [3067/3134], Loss: 0.01181546\n",
            "Epoch [1/1], Batch [3068/3134], Loss: 0.01179282\n",
            "Epoch [1/1], Batch [3069/3134], Loss: 0.01172433\n",
            "Epoch [1/1], Batch [3070/3134], Loss: 0.01176536\n",
            "Epoch [1/1], Batch [3071/3134], Loss: 0.01173729\n",
            "Epoch [1/1], Batch [3072/3134], Loss: 0.01180807\n",
            "Epoch [1/1], Batch [3073/3134], Loss: 0.01175857\n",
            "Epoch [1/1], Batch [3074/3134], Loss: 0.01170205\n",
            "Epoch [1/1], Batch [3075/3134], Loss: 0.01167426\n",
            "Epoch [1/1], Batch [3076/3134], Loss: 0.01169210\n",
            "Epoch [1/1], Batch [3077/3134], Loss: 0.01173467\n",
            "Epoch [1/1], Batch [3078/3134], Loss: 0.01171866\n",
            "Epoch [1/1], Batch [3079/3134], Loss: 0.01177507\n",
            "Epoch [1/1], Batch [3080/3134], Loss: 0.01181835\n",
            "Epoch [1/1], Batch [3081/3134], Loss: 0.01173047\n",
            "Epoch [1/1], Batch [3082/3134], Loss: 0.01174640\n",
            "Epoch [1/1], Batch [3083/3134], Loss: 0.01181060\n",
            "Epoch [1/1], Batch [3084/3134], Loss: 0.01172669\n",
            "Epoch [1/1], Batch [3085/3134], Loss: 0.01177119\n",
            "Epoch [1/1], Batch [3086/3134], Loss: 0.01176047\n",
            "Epoch [1/1], Batch [3087/3134], Loss: 0.01180673\n",
            "Epoch [1/1], Batch [3088/3134], Loss: 0.01179563\n",
            "Epoch [1/1], Batch [3089/3134], Loss: 0.01176589\n",
            "Epoch [1/1], Batch [3090/3134], Loss: 0.01167928\n",
            "Epoch [1/1], Batch [3091/3134], Loss: 0.01176205\n",
            "Epoch [1/1], Batch [3092/3134], Loss: 0.01173563\n",
            "Epoch [1/1], Batch [3093/3134], Loss: 0.01179918\n",
            "Epoch [1/1], Batch [3094/3134], Loss: 0.01174727\n",
            "Epoch [1/1], Batch [3095/3134], Loss: 0.01180411\n",
            "Epoch [1/1], Batch [3096/3134], Loss: 0.01174246\n",
            "Epoch [1/1], Batch [3097/3134], Loss: 0.01180780\n",
            "Epoch [1/1], Batch [3098/3134], Loss: 0.01177986\n",
            "Epoch [1/1], Batch [3099/3134], Loss: 0.01178690\n",
            "Epoch [1/1], Batch [3100/3134], Loss: 0.01179043\n",
            "Epoch [1/1], Batch [3101/3134], Loss: 0.01177546\n",
            "Epoch [1/1], Batch [3102/3134], Loss: 0.01171799\n",
            "Epoch [1/1], Batch [3103/3134], Loss: 0.01176287\n",
            "Epoch [1/1], Batch [3104/3134], Loss: 0.01174210\n",
            "Epoch [1/1], Batch [3105/3134], Loss: 0.01173263\n",
            "Epoch [1/1], Batch [3106/3134], Loss: 0.01173402\n",
            "Epoch [1/1], Batch [3107/3134], Loss: 0.01177108\n",
            "Epoch [1/1], Batch [3108/3134], Loss: 0.01176254\n",
            "Epoch [1/1], Batch [3109/3134], Loss: 0.01174032\n",
            "Epoch [1/1], Batch [3110/3134], Loss: 0.01175072\n",
            "Epoch [1/1], Batch [3111/3134], Loss: 0.01177642\n",
            "Epoch [1/1], Batch [3112/3134], Loss: 0.01178684\n",
            "Epoch [1/1], Batch [3113/3134], Loss: 0.01177136\n",
            "Epoch [1/1], Batch [3114/3134], Loss: 0.01172969\n",
            "Epoch [1/1], Batch [3115/3134], Loss: 0.01178554\n",
            "Epoch [1/1], Batch [3116/3134], Loss: 0.01173732\n",
            "Epoch [1/1], Batch [3117/3134], Loss: 0.01180491\n",
            "Epoch [1/1], Batch [3118/3134], Loss: 0.01178305\n",
            "Epoch [1/1], Batch [3119/3134], Loss: 0.01177216\n",
            "Epoch [1/1], Batch [3120/3134], Loss: 0.01176559\n",
            "Epoch [1/1], Batch [3121/3134], Loss: 0.01177347\n",
            "Epoch [1/1], Batch [3122/3134], Loss: 0.01174568\n",
            "Epoch [1/1], Batch [3123/3134], Loss: 0.01170558\n",
            "Epoch [1/1], Batch [3124/3134], Loss: 0.01178242\n",
            "Epoch [1/1], Batch [3125/3134], Loss: 0.01177889\n",
            "Epoch [1/1], Batch [3126/3134], Loss: 0.01176774\n",
            "Epoch [1/1], Batch [3127/3134], Loss: 0.01174007\n",
            "Epoch [1/1], Batch [3128/3134], Loss: 0.01169774\n",
            "Epoch [1/1], Batch [3129/3134], Loss: 0.01175155\n",
            "Epoch [1/1], Batch [3130/3134], Loss: 0.01172989\n",
            "Epoch [1/1], Batch [3131/3134], Loss: 0.01177028\n",
            "Epoch [1/1], Batch [3132/3134], Loss: 0.01171230\n",
            "Epoch [1/1], Batch [3133/3134], Loss: 0.01169649\n",
            "Epoch [1/1], Batch [3134/3134], Loss: 0.01181639\n",
            "Epoch [1/1], Average Loss: 0.01180841\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 1 # Replace with the desired number of epochs\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch_idx, x in enumerate(dataloader):\n",
        "        moves = x.get('moves')\n",
        "        frames = x.get('frames')\n",
        "        target = x.get('target_frames')\n",
        "\n",
        "        if len(frames) > 0:\n",
        "          # Forward pass\n",
        "          output = model(moves, frames)\n",
        "\n",
        "          # Compute the loss\n",
        "          loss = criterion(output, target)\n",
        "\n",
        "          # Backward pass and optimization\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # Print batch loss\n",
        "          print(f\"Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_idx + 1}/{len(dataloader)}], Loss: {loss.item():.8f}\")\n",
        "\n",
        "          total_loss += loss.item()\n",
        "          torch.cuda.empty_cache()\n",
        "          gc.collect()\n",
        "\n",
        "          # Save the model every 50 batches\n",
        "          if (batch_idx + 1) % 250 == 0:\n",
        "              torch.save(model.state_dict(), f\"drive/MyDrive/Colab Notebooks/GameGPT/model_checkpoint_epoch{epoch + 1}_batch{batch_idx + 1}.pth\")\n",
        "\n",
        "    # Print average loss for the epoch\n",
        "    average_loss = total_loss / len(dataloader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Average Loss: {average_loss:.8f}\")\n",
        "\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Play Game"
      ],
      "metadata": {
        "id": "Fb8VREqYt_J_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PlayDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.current = Image.open(os.path.join(f\"{datasetnames[0]}/frame_0.png\"))\n",
        "        self.moves = [2, 2, 2, 2, 2]\n",
        "        self.frames = [self.current, self.current, self.current, self.current, self.current]\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1000  # We subtract 5 for the sequence length\n",
        "\n",
        "    def __getitem__(self):\n",
        "\n",
        "        frames = [data_transform_p(frame) for frame in self.frames]\n",
        "        frames = torch.stack(frames).unsqueeze(0).to('cuda')\n",
        "        moves = torch.tensor(self.moves).unsqueeze(0).to('cuda')\n",
        "\n",
        "        return {'frames': frames, 'moves': moves }\n",
        "\n",
        "    def move(self, move, frame):\n",
        "        self.moves = self.moves[1:] + [value_to_int_mapping[move]]\n",
        "        self.frames = self.frames[1:] + [frame]\n",
        "\n",
        "data_transform_p = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "w7QW_5J3kaQb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "play_dataset = PlayDataset()\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "qzlxf8SjibTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47c630c7-efeb-494f-f07c-b3719d2927a3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GameModel(\n",
              "  (input_token_embedding): Embedding(10, 768)\n",
              "  (image_to_vector): ImageToVector(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "    (fc): Linear(in_features=262144, out_features=768, bias=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (positional_encoding): PositionalEncoding()\n",
              "  (att): Attention(\n",
              "    (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
              "    (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "  )\n",
              "  (linear_a): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (dropout_a): Dropout(p=0.2, inplace=False)\n",
              "  (layer_n): LayerNorm((5, 768), eps=1e-05, elementwise_affine=True)\n",
              "  (linear_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (dropout_k): Dropout(p=0.2, inplace=False)\n",
              "  (vector_to_image): VectorToImage(\n",
              "    (fc): Linear(in_features=768, out_features=49152, bias=True)\n",
              "    (deconv1): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (deconv2): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (deconv3): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = play_dataset.__getitem__()\n",
        "\n",
        "moves = x.get('moves')\n",
        "frames = x.get('frames')\n",
        "target = x.get('target_frames')\n",
        "\n",
        "# Forward pass\n",
        "output = model(moves, frames)\n",
        "\n",
        "predicted_frames = output.squeeze(0).permute(0, 2, 3, 1)\n",
        "predicted_np = (predicted_frames.cpu().detach().numpy() * 255).astype('uint8')\n",
        "predicted = predicted_np[0]\n",
        "image_pil = Image.fromarray(predicted)\n",
        "display(image_pil)\n",
        "play_dataset.move(\"N\", image_pil)"
      ],
      "metadata": {
        "id": "jlRjqE-0m0di",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "ecea28e3-762b-4b72-b66e-31d5557ab8b6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x128>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = play_dataset.__getitem__()\n",
        "\n",
        "moves = x.get('moves')\n",
        "frames = x.get('frames')\n",
        "target = x.get('target_frames')\n",
        "\n",
        "# Forward pass\n",
        "output = model(moves, frames)\n",
        "\n",
        "predicted_frames = output.squeeze(0).permute(0, 2, 3, 1)\n",
        "predicted_np = (predicted_frames.cpu().detach().numpy() * 255).astype('uint8')\n",
        "predicted = predicted_np[0]\n",
        "image_pil = Image.fromarray(predicted)\n",
        "display(image_pil)\n",
        "play_dataset.move(\"D\", image_pil)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "62ivlf6Ju7uH",
        "outputId": "d1219dfa-2baf-452a-a0f0-5759508fa6b6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x128>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}